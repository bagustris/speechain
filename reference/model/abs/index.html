
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Documentation for Speechain Toolkit">
      
      
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../ar_asr/">
      
      
      <link rel="icon" href="../../../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.49">
    
    
      
        <title>abs - Speechain</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../css/code_select.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#model.abs" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Speechain" class="md-header__button md-logo" aria-label="Speechain" data-md-component="logo">
      
  <img src="../../../img/speechain_inverted.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Speechain
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              abs
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/bagustris/speechain" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Speechain" class="md-nav__button md-logo" aria-label="Speechain" data-md-component="logo">
      
  <img src="../../../img/speechain_inverted.png" alt="logo">

    </a>
    Speechain
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/bagustris/speechain" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets (Directory)
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../recipes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recipes
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ASR
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TTS
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Criterion
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dataset (Module)
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../iterator/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Iterator
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../module/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Module
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../optim_sche/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    OptimScheduler
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tokenizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tokenizer
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../handbook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Handbook
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14" checked>
        
          
          <label class="md-nav__link" for="__nav_14" id="__nav_14_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_14_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_14">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../criterion/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    criterion
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_1" id="__nav_14_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_14_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_1">
            <span class="md-nav__icon md-icon"></span>
            criterion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/accuracy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    accuracy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/att_guid/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    att_guid
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/bce_logits/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bce_logits
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/cross_entropy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cross_entropy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/ctc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctc
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/error_rate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    error_rate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/fbeta_score/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    fbeta_score
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/least_error/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    least_error
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/perplexity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    perplexity
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../dataset/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    dataset
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_2" id="__nav_14_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_14_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_2">
            <span class="md-nav__icon md-icon"></span>
            dataset
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/speech_text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_text
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../infer_func/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    infer_func
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_3" id="__nav_14_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_14_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_3">
            <span class="md-nav__icon md-icon"></span>
            infer_func
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../infer_func/beam_search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam_search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../infer_func/ctc_decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctc_decoding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../infer_func/tts_decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tts_decoding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../iterator/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    iterator
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_4" id="__nav_14_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_14_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_4">
            <span class="md-nav__icon md-icon"></span>
            iterator
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../iterator/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../iterator/block/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    block
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_5" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    model
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_5" id="__nav_14_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_14_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_14_5">
            <span class="md-nav__icon md-icon"></span>
            model
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    abs
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#model.abs" class="md-nav__link">
    <span class="md-ellipsis">
      abs
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model.abs.Model" class="md-nav__link">
    <span class="md-ellipsis">
      Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.attention_reshape" class="md-nav__link">
    <span class="md-ellipsis">
      attention_reshape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.aver_metrics_across_procs" class="md-nav__link">
    <span class="md-ellipsis">
      aver_metrics_across_procs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.bad_cases_selection_init_fn" class="md-nav__link">
    <span class="md-ellipsis">
      bad_cases_selection_init_fn
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.batch_preprocess_fn" class="md-nav__link">
    <span class="md-ellipsis">
      batch_preprocess_fn
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.batch_to_cuda" class="md-nav__link">
    <span class="md-ellipsis">
      batch_to_cuda
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.criterion_forward" class="md-nav__link">
    <span class="md-ellipsis">
      criterion_forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.criterion_init" class="md-nav__link">
    <span class="md-ellipsis">
      criterion_init
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.get_recordable_para" class="md-nav__link">
    <span class="md-ellipsis">
      get_recordable_para
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.inference" class="md-nav__link">
    <span class="md-ellipsis">
      inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.matrix_snapshot" class="md-nav__link">
    <span class="md-ellipsis">
      matrix_snapshot
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.module_forward" class="md-nav__link">
    <span class="md-ellipsis">
      module_forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.module_init" class="md-nav__link">
    <span class="md-ellipsis">
      module_init
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.register_instance_reports" class="md-nav__link">
    <span class="md-ellipsis">
      register_instance_reports
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.visualize" class="md-nav__link">
    <span class="md-ellipsis">
      visualize
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ar_asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_tts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    lm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nar_tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    module
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_6" id="__nav_14_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_14_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_6">
            <span class="md-nav__icon md-icon"></span>
            module
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_6_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/augment/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    augment
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_6_2" id="__nav_14_6_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_14_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_6_2">
            <span class="md-nav__icon md-icon"></span>
            augment
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/augment/specaug/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    specaug
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_6_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/conformer/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    conformer
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_6_3" id="__nav_14_6_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_14_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_6_3">
            <span class="md-nav__icon md-icon"></span>
            conformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/conformer/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/conformer/encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/conformer/pos_enc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pos_enc
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_6_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/decoder/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    decoder
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_6_4" id="__nav_14_6_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_14_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_6_4">
            <span class="md-nav__icon md-icon"></span>
            decoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/decoder/ar_asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/decoder/ar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_tts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/decoder/nar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nar_tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_6_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/encoder/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    encoder
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_6_5" id="__nav_14_6_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_14_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_6_5">
            <span class="md-nav__icon md-icon"></span>
            encoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/speaker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speaker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/test_speaker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    test_speaker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_6_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/frontend/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    frontend
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_6_6" id="__nav_14_6_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_14_6_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_6_6">
            <span class="md-nav__icon md-icon"></span>
            frontend
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/delta_feat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    delta_feat
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/linear2mel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear2mel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/speech2linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech2linear
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/speech2mel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech2mel
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_6_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/norm/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    norm
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_6_7" id="__nav_14_6_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_14_6_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_6_7">
            <span class="md-nav__icon md-icon"></span>
            norm
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/norm/feat_norm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feat_norm
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_6_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/postnet/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    postnet
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_6_8" id="__nav_14_6_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_14_6_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_6_8">
            <span class="md-nav__icon md-icon"></span>
            postnet
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/postnet/conv1d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv1d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/postnet/token/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    token
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_6_9" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/prenet/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    prenet
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_6_9" id="__nav_14_6_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_14_6_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_6_9">
            <span class="md-nav__icon md-icon"></span>
            prenet
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/conv1d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv1d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/conv2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv2d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/embed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    embed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/spk_embed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    spk_embed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/var_pred/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    var_pred
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_6_10" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/standalone/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    standalone
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_6_10" id="__nav_14_6_10_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_14_6_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_6_10">
            <span class="md-nav__icon md-icon"></span>
            standalone
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/standalone/lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    lm
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_6_11" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/transformer/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    transformer
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_6_11" id="__nav_14_6_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_14_6_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_6_11">
            <span class="md-nav__icon md-icon"></span>
            transformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    decoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/feed_forward/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feed_forward
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/pos_enc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pos_enc
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_6_12" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/vocoder/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    vocoder
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_6_12" id="__nav_14_6_12_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_14_6_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_6_12">
            <span class="md-nav__icon md-icon"></span>
            vocoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/vocoder/hifigan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hifigan
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/vocoder/test_hifigan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    test_hifigan
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../monitor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    monitor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../optim_sche/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    optim_sche
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_8" id="__nav_14_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_14_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_8">
            <span class="md-nav__icon md-icon"></span>
            optim_sche
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optim_sche/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optim_sche/exp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    exp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optim_sche/noam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    noam
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_9" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../pyscripts/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    pyscripts
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_9" id="__nav_14_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_14_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_9">
            <span class="md-nav__icon md-icon"></span>
            pyscripts
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/empty_file_checker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    empty_file_checker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/folder_summarizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    folder_summarizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/model_para_renamer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    model_para_renamer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/phn_duaration_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phn_duaration_visualizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/text_dist_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_dist_visualizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/wavlen_dist_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wavlen_dist_visualizer
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../runner/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    runner
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../snapshooter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    snapshooter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_12" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../tokenizer/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    tokenizer
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_12" id="__nav_14_12_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_14_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_12">
            <span class="md-nav__icon md-icon"></span>
            tokenizer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/char/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    char
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/g2p/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    g2p
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/sp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sp
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_14_13" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../utilbox/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    utilbox
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_14_13" id="__nav_14_13_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_14_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14_13">
            <span class="md-nav__icon md-icon"></span>
            utilbox
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/data_loading_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_loading_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/data_saving_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_saving_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/dump_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    dump_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/eval_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    eval_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/feat_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feat_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/humanfriendly/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    humanfriendly
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/import_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    import_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/log_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    log_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/md_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    md_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/regex_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    regex_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/sb_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sb_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/spk_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    spk_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/tensor_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tensor_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/test_humanfriendly/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    test_humanfriendly
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/text_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/train_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    train_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/type_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    type_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/yaml_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    yaml_util
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#model.abs" class="md-nav__link">
    <span class="md-ellipsis">
      abs
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model.abs.Model" class="md-nav__link">
    <span class="md-ellipsis">
      Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.attention_reshape" class="md-nav__link">
    <span class="md-ellipsis">
      attention_reshape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.aver_metrics_across_procs" class="md-nav__link">
    <span class="md-ellipsis">
      aver_metrics_across_procs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.bad_cases_selection_init_fn" class="md-nav__link">
    <span class="md-ellipsis">
      bad_cases_selection_init_fn
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.batch_preprocess_fn" class="md-nav__link">
    <span class="md-ellipsis">
      batch_preprocess_fn
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.batch_to_cuda" class="md-nav__link">
    <span class="md-ellipsis">
      batch_to_cuda
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.criterion_forward" class="md-nav__link">
    <span class="md-ellipsis">
      criterion_forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.criterion_init" class="md-nav__link">
    <span class="md-ellipsis">
      criterion_init
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.evaluate" class="md-nav__link">
    <span class="md-ellipsis">
      evaluate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.get_recordable_para" class="md-nav__link">
    <span class="md-ellipsis">
      get_recordable_para
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.inference" class="md-nav__link">
    <span class="md-ellipsis">
      inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.matrix_snapshot" class="md-nav__link">
    <span class="md-ellipsis">
      matrix_snapshot
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.module_forward" class="md-nav__link">
    <span class="md-ellipsis">
      module_forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.module_init" class="md-nav__link">
    <span class="md-ellipsis">
      module_init
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.register_instance_reports" class="md-nav__link">
    <span class="md-ellipsis">
      register_instance_reports
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.abs.Model.visualize" class="md-nav__link">
    <span class="md-ellipsis">
      visualize
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>abs</h1>

<div class="doc doc-object doc-module">



<a id="model.abs"></a>
    <div class="doc doc-contents first">

        <p>Abstract base class for all models.</p>
<p>Author: Heli Qi
Affiliation: NAIST
Date: 2022.07</p>








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="model.abs.Model" class="doc doc-heading">
            <code>Model</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code>, <code><span title="abc.ABC">ABC</span></code></p>


        <p>Model is the base class for all models in this toolkit. The main job of a model includes:
    1. (optional) preprocess the input batch data to the trainable format
    2. calculate the model prediction results by the Module members
    3. evaluate the prediction results by the Criterion members</p>
<p>Each model has several built-in Module members that make up the neural network structure of the model. These Module
members will be initialized by the <code>module_conf</code> given in your configuration.</p>
<p>There are a built-in dictionary named <code>init_class_dict</code> and a built-in list named <code>default_init_modules</code> in the
base class. init_class_dict<code>contains all the available initialization functions of the model parameters while</code>default_init_modules` includes the network layers that have their own initialization functions.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="model.abs.Model.init_class_dict">init_class_dict</span></code></td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Available parameter initialization functions</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="model.abs.Model.default_init_modules">default_init_modules</span></code></td>
            <td>
                  <code><span title="typing.List">List</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Network layers with own initialization functions</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>speechain/model/abs.py</code></summary>
                <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Model is the base class for all models in this toolkit. The main job of a model includes:</span>
<span class="sd">        1. (optional) preprocess the input batch data to the trainable format</span>
<span class="sd">        2. calculate the model prediction results by the Module members</span>
<span class="sd">        3. evaluate the prediction results by the Criterion members</span>

<span class="sd">    Each model has several built-in Module members that make up the neural network structure of the model. These Module</span>
<span class="sd">    members will be initialized by the `module_conf` given in your configuration.</span>

<span class="sd">    There are a built-in dictionary named `init_class_dict` and a built-in list named `default_init_modules` in the</span>
<span class="sd">    base class. init_class_dict` contains all the available initialization functions of the model parameters while</span>
<span class="sd">    `default_init_modules` includes the network layers that have their own initialization functions.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        init_class_dict (Dict): Available parameter initialization functions</span>
<span class="sd">        default_init_modules (List): Network layers with own initialization functions</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># available parameter initialization functions</span>
    <span class="n">init_class_dict</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;xavier&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">,</span>
        <span class="s2">&quot;xavier_normal&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">,</span>
        <span class="s2">&quot;xavier_uniform&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">,</span>
        <span class="s2">&quot;kaiming&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">,</span>
        <span class="s2">&quot;kaiming_normal&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">,</span>
        <span class="s2">&quot;kaiming_uniform&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">,</span>
        <span class="s2">&quot;uniform&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">,</span>
        <span class="s2">&quot;normal&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">,</span>
        <span class="s2">&quot;zeros&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="c1"># some modules have their own parameter initialization methods</span>
    <span class="n">default_init_modules</span><span class="p">:</span> <span class="n">List</span> <span class="o">=</span> <span class="p">[</span>  <span class="c1"># explicitely defined</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">,</span>
        <span class="n">PositionalEncoding</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">module_conf</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">result_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">model_conf</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">criterion_conf</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">non_blocking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;In this initialization function, there are two parts of</span>
<span class="sd">        initialization: model-specific customized initialization and model-</span>
<span class="sd">        independent general initialization.</span>

<span class="sd">        Model-specific customized initialization is done by two interface functions: module_init() and criterion_init().</span>
<span class="sd">        module_init() initializes the neural network structure of the model while criterion_init() initializes the</span>
<span class="sd">        criteria used to optimize (loss functions) and evaluate (validation metrics) the model.</span>

<span class="sd">        After the customized initialization, there are 3 steps for general initialization:</span>
<span class="sd">            1. Pretrained parameters will be loaded into your model if the key `pretrained_model` is given. Multiple</span>
<span class="sd">            pretrained models can be specified and each of them can be loaded into different parts of your model. The</span>
<span class="sd">            mismatch between the names of pretrained parameters and the parameters of your model is handled by the key</span>
<span class="sd">            &#39;mapping&#39;. The value of the key `mapping` is a dictionary where each key-value item corresponds to a mapping</span>
<span class="sd">            of parameter names. The key is the parameter name in the pretrained parameters while the value is the</span>
<span class="sd">            parameter name of your model.</span>

<span class="sd">            2. If `pretrained_model` is not given, the parameters of your model will be initialized by the function that</span>
<span class="sd">            matches your input query &#39;init&#39;. Please refer to the built-in dictionary `init_class_dict` for the available</span>
<span class="sd">            initialization functions. If `init` is not given, the default initialization function</span>
<span class="sd">            `torch.nn.init.xavier_normal_` will be used to initialize your model.</span>

<span class="sd">            3. Finally, the specified parts of your model will be frozen if &#39;frozen_modules&#39; is given. If there is only</span>
<span class="sd">            one frozen module, you can directly give the string of its name to &#39;frozen_modules&#39; like</span>
<span class="sd">            &#39;frozen_modules: {module_name}&#39;; if there are multiple modules you want to freeze, you can give their names</span>
<span class="sd">            in a list as</span>
<span class="sd">            ```</span>
<span class="sd">            frozen_modules:</span>
<span class="sd">              - {module_name1}</span>
<span class="sd">              - {module_name2}</span>
<span class="sd">              - ...</span>
<span class="sd">            ```</span>
<span class="sd">            Moreover, the frozen granularity depends on your input `frozen_modules`.</span>
<span class="sd">            For example,</span>
<span class="sd">                1. If you give &#39;frozen_modules: encoder_prenet&#39;, all parameters of the prenet of your encoder will be</span>
<span class="sd">                frozen</span>
<span class="sd">                2. If you give &#39;frozen_modules: encoder_prenet.conv&#39;, only the convolution layers of the prenet of your</span>
<span class="sd">                encoder will be frozen</span>
<span class="sd">                3. If you give &#39;frozen_modules: encoder_prenet.conv.0&#39;, only the first convolution layer of the prenet</span>
<span class="sd">                of your encoder will be frozen</span>
<span class="sd">                4. If you give &#39;frozen_modules: encoder_prenet.conv.0.bias&#39;, only the bias vector of the first</span>
<span class="sd">                convolution layer of the prenet of your encoder will be frozen</span>

<span class="sd">        Args:</span>
<span class="sd">            device (torch.device):</span>
<span class="sd">                The computational device used for model calculation in the current GPU process.</span>
<span class="sd">            model_conf (Dict):</span>
<span class="sd">                The model configuration used for general model initialization.</span>
<span class="sd">            module_conf (Dict):</span>
<span class="sd">                The module configuration used for network structure initialization.</span>
<span class="sd">            criterion_conf (Dict):</span>
<span class="sd">                The criterion configuration used for criterion (loss functions and evaluation metrics) initialization.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># input argument checking</span>
        <span class="k">assert</span> <span class="n">module_conf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;module_conf cannot be None!&quot;</span>
        <span class="c1"># model_conf is default to be an empty dictionary</span>
        <span class="n">model_conf</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span> <span class="k">if</span> <span class="n">model_conf</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">model_conf</span>
        <span class="c1"># criterion_conf is default to be an empty dictionary</span>
        <span class="n">criterion_conf</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span> <span class="k">if</span> <span class="n">criterion_conf</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">criterion_conf</span>
        <span class="c1"># customize_conf is default to be an empty dictionary</span>
        <span class="k">if</span> <span class="s2">&quot;customize_conf&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">model_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;customize_conf&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="c1"># general argument registration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">non_blocking</span> <span class="o">=</span> <span class="n">non_blocking</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span> <span class="o">=</span> <span class="n">distributed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>

        <span class="c1"># snapshotting-related argument registration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">result_path</span> <span class="o">=</span> <span class="n">result_path</span>
        <span class="k">if</span> <span class="s2">&quot;visual_infer_conf&quot;</span> <span class="ow">in</span> <span class="n">model_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="c1"># configuration is given as a .yaml file</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;visual_infer_conf&quot;</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">visual_infer_conf</span> <span class="o">=</span> <span class="n">load_yaml</span><span class="p">(</span>
                    <span class="nb">open</span><span class="p">(</span><span class="n">parse_path_args</span><span class="p">(</span><span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;visual_infer_conf&quot;</span><span class="p">]))</span>
                <span class="p">)</span>
            <span class="c1"># configuration is explicitly given</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;visual_infer_conf&quot;</span><span class="p">],</span> <span class="n">Dict</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">visual_infer_conf</span> <span class="o">=</span> <span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;visual_infer_conf&quot;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;model_conf[&#39;visual_infer_conf&#39;] must be given as either a string or a Dict.&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">visual_infer_conf</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="c1"># --- 1. Model Construction --- #</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module_init</span><span class="p">(</span><span class="o">**</span><span class="n">module_conf</span><span class="p">,</span> <span class="o">**</span><span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;customize_conf&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion_init</span><span class="p">(</span><span class="o">**</span><span class="n">criterion_conf</span><span class="p">)</span>
        <span class="c1"># initialize the bad case selection methods by the hook function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bad_cases_selection</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_cases_selection_init_fn</span><span class="p">()</span>

        <span class="c1"># --- 2.1. Pretrained Model Loading --- #</span>
        <span class="n">pretrained_model</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;pretrained_model&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="s2">&quot;pretrained_model&quot;</span> <span class="ow">in</span> <span class="n">model_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">pretrained_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pretrained_model</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">pretrained_model</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pretrained_model</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
                <span class="k">else</span> <span class="p">[</span><span class="n">pretrained_model</span><span class="p">]</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">ptm</span> <span class="ow">in</span> <span class="n">pretrained_model</span><span class="p">:</span>
                <span class="c1"># argument checking</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ptm</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">ptm</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">parse_path_args</span><span class="p">(</span><span class="n">ptm</span><span class="p">))</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ptm</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
                    <span class="k">assert</span> <span class="s2">&quot;path&quot;</span> <span class="ow">in</span> <span class="n">ptm</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="p">(</span>
                        <span class="s2">&quot;If model[&#39;model_conf&#39;][&#39;pretrained_model&#39;] is given as a Dict, &quot;</span>
                        <span class="s2">&quot;please give a key named &#39;path&#39; to specify where your pretrained model is placed.&quot;</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">ptm</span><span class="p">[</span><span class="s2">&quot;path&quot;</span><span class="p">]):</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;The specified path of your pretrained model </span><span class="si">{</span><span class="n">ptm</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> doesn&#39;t exist! &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;Please check the input path.&quot;</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;The elements in model[&#39;model_conf&#39;][&#39;pretrained_model&#39;] must be either a string &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;or a Dict, but got </span><span class="si">{</span><span class="n">ptm</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

                <span class="n">_pt_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
                    <span class="n">parse_path_args</span><span class="p">(</span><span class="n">ptm</span><span class="p">[</span><span class="s2">&quot;path&quot;</span><span class="p">]),</span> <span class="n">map_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span>
                <span class="n">mapping</span> <span class="o">=</span> <span class="n">ptm</span><span class="p">[</span><span class="s2">&quot;mapping&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;mapping&quot;</span> <span class="ow">in</span> <span class="n">ptm</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span>
                <span class="k">if</span> <span class="n">mapping</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                        <span class="n">_pt_model</span><span class="p">,</span>
                        <span class="n">strict</span><span class="o">=</span><span class="kc">True</span> <span class="k">if</span> <span class="s2">&quot;strict&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ptm</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="n">ptm</span><span class="p">[</span><span class="s2">&quot;strict&quot;</span><span class="p">],</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mapping</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;mapping must be given as a dict and cannot be empty! &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Got type(mapping)=</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span><span class="si">}</span><span class="s2"> and len(mapping)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

                    <span class="n">_src_modules</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
                    <span class="c1"># loop each name-parameter pair in the model</span>
                    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">para</span> <span class="ow">in</span> <span class="n">_pt_model</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="c1"># loop each source-target mapping pair</span>
                        <span class="k">for</span> <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span> <span class="ow">in</span> <span class="n">mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                            <span class="c1"># attach &#39;.&#39; to the end is for making the name unique</span>
                            <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">=</span> <span class="n">src</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span>
                            <span class="c1"># change the parameter name in the middle</span>
                            <span class="k">if</span> <span class="n">src</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                                <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="p">)</span>
                        <span class="c1"># record the parameter no matter whether its name is modified or not</span>
                        <span class="n">_src_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">para</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                        <span class="n">_src_modules</span><span class="p">,</span>
                        <span class="n">strict</span><span class="o">=</span><span class="kc">True</span> <span class="k">if</span> <span class="s2">&quot;strict&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ptm</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="n">ptm</span><span class="p">[</span><span class="s2">&quot;strict&quot;</span><span class="p">],</span>
                    <span class="p">)</span>

        <span class="c1"># --- 2.2. Model Parameter Initialization --- #</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># the default initialization method is xavier (i.e. xavier_normal)</span>
            <span class="n">init</span> <span class="o">=</span> <span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;init&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;init&quot;</span> <span class="ow">in</span> <span class="n">model_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;xavier&quot;</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">init</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_class_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Only the initialization methods </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">init_class_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2"> are supported, but got init=</span><span class="si">{</span><span class="n">init</span><span class="si">}</span><span class="s2">.&quot;</span>

            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">para</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
                <span class="c1"># initialize all the bias vectors to zero</span>
                <span class="k">if</span> <span class="s2">&quot;.bias&quot;</span> <span class="ow">in</span> <span class="n">name</span> <span class="ow">and</span> <span class="n">para</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">para</span><span class="p">)</span>
                <span class="c1"># initialize all the weight vectors except for those of normalization layers (BatchNorm &amp; LayerNorm)</span>
                <span class="k">elif</span> <span class="n">para</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">init_class_dict</span><span class="p">[</span><span class="n">init</span><span class="p">](</span><span class="n">para</span><span class="p">)</span>

            <span class="c1"># initialize the modules that have their own default init methods</span>
            <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">default_init_modules</span><span class="p">)):</span>
                    <span class="n">module</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>

        <span class="c1"># --- 3. Model Parameter Freezing --- #</span>
        <span class="n">frozen_modules</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;frozen_modules&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="s2">&quot;frozen_modules&quot;</span> <span class="ow">in</span> <span class="n">model_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">frozen_modules</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">frozen_modules</span> <span class="o">!=</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
                <span class="n">frozen_modules</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">frozen_modules</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">frozen_modules</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
                    <span class="k">else</span> <span class="p">[</span><span class="n">frozen_modules</span><span class="p">]</span>
                <span class="p">)</span>

            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">para</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
                <span class="n">frozen_flag</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">if</span> <span class="n">frozen_modules</span> <span class="o">!=</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">frozen_modules</span><span class="p">:</span>
                        <span class="n">frozen_flag</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">module</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">frozen_flag</span> <span class="o">=</span> <span class="kc">True</span>

                <span class="k">if</span> <span class="n">frozen_flag</span><span class="p">:</span>
                    <span class="n">para</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;frozen_modules: Parameters of </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> are not found in the model!&quot;</span>
                    <span class="p">)</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">module_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The interface function that initializes the Module members of the model.</span>
<span class="sd">        These Module members make up the neural network structure of the model. Some</span>
<span class="sd">        models have their customized part that also needs to be initialization in this</span>
<span class="sd">        function, e.g. the tokenizer of ASR and TTS models.</span>

<span class="sd">        Note: This interface function must be overridden for each Model subclass.</span>

<span class="sd">        Args:</span>
<span class="sd">            **kwargs:</span>
<span class="sd">                The combination of the arguments in your given `module_conf` and `model_conf[&#39;customize_conf&#39;]`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># raise NotImplementedError</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">criterion_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">criterion_conf</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The interface function that initializes the Criterion members of the model. These Criterion members can be</span>
<span class="sd">        divided into two parts: the loss functions used for training and the evaluation metrics used for validation.</span>

<span class="sd">        Args:</span>
<span class="sd">            **criterion_conf:</span>
<span class="sd">                The arguments in your given `criterion_conf`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># raise NotImplementedError</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">bad_cases_selection_init_fn</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span> <span class="ow">or</span> <span class="nb">int</span><span class="p">]]</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;This hook function returns the default bad case selection method of each</span>
<span class="sd">        Model object. This default value will be referred by the _Runner_ to present the</span>
<span class="sd">        top-N bad cases.</span>

<span class="sd">        The original hook implementation in the base Model class returns None which means no default value.</span>

<span class="sd">        Returns: List[List[str or int]]</span>
<span class="sd">            The returned default value should be a list of tri-list where each tri-list is in the form of</span>
<span class="sd">            [`selection_metric`, `selection_mode`, `case_number`]. For example, [&#39;wer&#39;, &#39;max&#39;, 50] means 50 testing</span>
<span class="sd">            waveforms with the largest WER will be selected.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">batch_to_cuda</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The recursive function that transfers the batch data to the specified device</span>
<span class="sd">        in the current process.</span>

<span class="sd">        Args:</span>
<span class="sd">            data: Dict or torch.Tensor</span>
<span class="sd">                The input batch data. It should be either a Tensor or a Dict of Tensors. For the Dict input, the</span>
<span class="sd">                function itself will be called once by each Tensor element.</span>

<span class="sd">        Returns: Dict or torch.Tensor</span>
<span class="sd">            If the input is a Dict, the returned output will also be a Dict of Tensors transferred to the target device;</span>
<span class="sd">            If the input is a Tensor, the returned output will be its copy on the target device.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># if the data is in the form of Dict, recursively process each key-value pair</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_to_cuda</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="c1"># if the data is in the form of tensor, put it on GPUs by .cuda()</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">non_blocking</span><span class="p">)</span>
        <span class="c1"># do nothing for other types of data</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">data</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The general model forward function shared by all the _Model_ subclasses. This forward function has 3 steps:</span>
<span class="sd">            1. preprocess and transfer the batch data to GPUs</span>
<span class="sd">            2. obtain the model prediction results</span>
<span class="sd">            3. calculate the loss function and evaluate the prediction results</span>

<span class="sd">        For each step above, we provide interface functions for you to override and make your own implementation.</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_data: Dict</span>
<span class="sd">                The input batch data received from the `train` or `valid` dataloader object in the experimental</span>
<span class="sd">                pipeline.</span>
<span class="sd">            epoch: int = None</span>
<span class="sd">                The number of the current epoch. Used for real-time model visualization and model prediction.</span>
<span class="sd">            **kwargs:</span>
<span class="sd">                The additional arguments for real-time model visualization. If given, the code will go through the model</span>
<span class="sd">                visualization branch.</span>

<span class="sd">        Returns:</span>
<span class="sd">            In the training branch, the loss functions and evaluation metrics will be returned each of which is in the</span>
<span class="sd">            form of a Dict.</span>
<span class="sd">            In the validation branch, only the evaluation metrics will be returned.</span>
<span class="sd">            In the visualization branch, the model snapshots on the given validation instance will be returned.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># --- 1. Batch Data Preprocessing and GPU transferring --- #</span>
        <span class="c1"># --- data preparation below is shared by all the three branches: training, validation, and visualization --- #</span>
        <span class="c1"># preprocess the batch data if needed</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_preprocess_fn</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>

        <span class="c1"># put the batch data onto GPUs</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_to_cuda</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>

        <span class="c1"># --- 2.1. Model Visualization Branch --- #</span>
        <span class="c1"># if there are additional arguments other than batch_data and epoch, the visualization branch is activated</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="o">**</span><span class="n">batch_data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># --- 2.2. Model Forward Calculation --- #</span>
        <span class="c1"># --- model forward is shared by both the training and validation branches --- #</span>
        <span class="c1"># context function used when doing the loss backward for efficient gradient accumulation in the DDP mode</span>
        <span class="n">forward_context</span> <span class="o">=</span> <span class="n">nullcontext</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span>
        <span class="k">with</span> <span class="n">forward_context</span><span class="p">():</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Feed the input batch into the model and get the outputs, copy.deepcopy() here is for the data safety</span>
                <span class="n">model_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_forward</span><span class="p">(</span>
                    <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="o">**</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">e</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">skip_flag_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span>
                        <span class="p">[</span><span class="kc">False</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">())]</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">skip_flag</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="kc">True</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="c1"># as long as one node meets an error, all nodes will skip the current step at the same time</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather_into_tensor</span><span class="p">(</span><span class="n">skip_flag_list</span><span class="p">,</span> <span class="n">skip_flag</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">skip_flag_list</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="n">e</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
                    <span class="n">skip_flag_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span>
                        <span class="p">[</span><span class="kc">False</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">())]</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">skip_flag</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="kc">False</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="c1"># as long as one node meets an error, all nodes will skip the current step at the same time</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather_into_tensor</span><span class="p">(</span><span class="n">skip_flag_list</span><span class="p">,</span> <span class="n">skip_flag</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">skip_flag_list</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                            <span class="s2">&quot;Other ranks meet errors during model forwarding, &quot;</span>
                            <span class="s2">&quot;so this rank will also skip the current step!&quot;</span>
                        <span class="p">)</span>

        <span class="c1"># copy.deepcopy() cannot receive the non-leaf nodes in the computation graph (model_outputs). Since</span>
        <span class="c1"># model_outputs cannot be detached from the graph (gradients necessary), copy.deepcopy() is not used below.</span>
        <span class="k">def</span> <span class="nf">combine_input_output</span><span class="p">(</span><span class="n">_batch_data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">_model_outputs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">):</span>
            <span class="n">combination</span><span class="p">,</span> <span class="n">batch_keys</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(),</span> <span class="nb">list</span><span class="p">(</span><span class="n">_batch_data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="c1"># if the input batch data is in the form of Dict, it means there are multiple dataloaders</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">_batch_data</span><span class="p">[</span><span class="n">batch_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">Dict</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">batch_keys</span><span class="p">:</span>
                    <span class="n">combination</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="o">**</span><span class="n">_batch_data</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="o">**</span><span class="n">_model_outputs</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
            <span class="c1"># if the input batch data is in the form of Tensor, it means there is only one dataloader.</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">combination</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_batch_data</span><span class="p">)</span>
                <span class="n">combination</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_model_outputs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">combination</span>

        <span class="c1"># --- 3.1. Model Training Branch --- #</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="c1"># In the training stage, both the trainable losses and non-trainable metrics will be returned</span>
            <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span>
                <span class="o">**</span><span class="n">combine_input_output</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">model_outputs</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_recordable_para</span><span class="p">())</span>

            <span class="c1"># post-checking for training losses, they must be trainable tensors</span>
            <span class="k">assert</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">loss</span><span class="o">.</span><span class="n">requires_grad</span>
                    <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">losses</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                <span class="p">]</span>
            <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">),</span> <span class="s2">&quot;Training losses must be trainable tensors!&quot;</span>
            <span class="c1"># post-checking for validation metrics, they must be either non-trainable tensors or other datatypes</span>
            <span class="k">assert</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">metric</span><span class="o">.</span><span class="n">requires_grad</span>
                    <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                <span class="p">]</span>
            <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                <span class="n">metrics</span>
            <span class="p">),</span> <span class="s2">&quot;Validation metrics must be either non-trainable tensors or other datatypes!&quot;</span>

            <span class="c1"># the non-trainable metrics will be averaged across all the processes in the distributed mode</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
                <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aver_metrics_across_procs</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span>

        <span class="c1"># --- 3.2. Model Validation Branch --- #</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># In the validation stage, only the non-trainable metrics will be returned</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
                <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span>
                    <span class="o">**</span><span class="n">combine_input_output</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">model_outputs</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_recordable_para</span><span class="p">())</span>

            <span class="c1"># post-checking for validation metrics, they must be either non-trainable tensors or other datatypes</span>
            <span class="k">assert</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">metric</span><span class="o">.</span><span class="n">requires_grad</span>
                    <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                <span class="p">]</span>
            <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                <span class="n">metrics</span>
            <span class="p">),</span> <span class="s2">&quot;Validation metrics must be either non-trainable tensors or other datatypes!&quot;</span>

            <span class="c1"># the non-trainable metrics will be averaged across all the processes in the distributed mode</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
                <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aver_metrics_across_procs</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">metrics</span>

    <span class="k">def</span> <span class="nf">batch_preprocess_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;This hook function does the preprocessing for the input batch data before</span>
<span class="sd">        using them in self.model_forward(). This function is not mandatory to be</span>
<span class="sd">        overridden and the original implementation in the base Model class does the</span>
<span class="sd">        tensor transformation for the string-like data in batch_data (i.e., text and</span>
<span class="sd">        spk_ids).</span>

<span class="sd">        Note: the key names in the returned Dict should match the argument names in self.model_forward().</span>

<span class="sd">        Args:</span>
<span class="sd">            batch_data: Dict</span>
<span class="sd">                The raw data of the input batch to be preprocessed in this hook function.</span>

<span class="sd">        Returns: Dict</span>
<span class="sd">            The processed data of the input batch that is ready to be used in `self.model_forward()`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">process_strings</span><span class="p">(</span><span class="n">data_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">):</span>
<span class="w">            </span><span class="sd">&quot;&quot;&quot;Turn the text and speaker strings into tensors and get their lengths.&quot;&quot;&quot;</span>
            <span class="c1"># --- Process the Text String and its Length --- #</span>
            <span class="k">if</span> <span class="s2">&quot;text&quot;</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">List</span><span class="p">):</span>
                    <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;text_len&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text2tensor_and_len</span><span class="p">(</span>
                        <span class="n">text_list</span><span class="o">=</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span>
                        <span class="n">text2tensor_func</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">text2tensor</span><span class="p">,</span>
                        <span class="n">ignore_idx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>

            <span class="c1"># --- Process the Speaker ID String --- #</span>
            <span class="k">if</span> <span class="s2">&quot;spk_ids&quot;</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;spk_ids&quot;</span><span class="p">],</span> <span class="n">List</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;spk2idx&quot;</span><span class="p">):</span>
                        <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;spk_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">spk2tensor</span><span class="p">(</span>
                            <span class="n">spk_list</span><span class="o">=</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;spk_ids&quot;</span><span class="p">],</span> <span class="n">spk2idx_dict</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">spk2idx</span>
                        <span class="p">)</span>
                <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;spk_ids&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span>

            <span class="k">return</span> <span class="n">data_dict</span>

        <span class="c1"># check whether the batch_data is made by multiple dataloaders</span>
        <span class="n">leaf_flags</span> <span class="o">=</span> <span class="p">[</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
        <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">leaf_flags</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">process_strings</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">elif</span> <span class="nb">sum</span><span class="p">(</span><span class="n">leaf_flags</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_data</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">process_strings</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Wrong composition of batch_data!&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">aver_metrics_across_procs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">batch_data</span><span class="p">:</span> <span class="n">Dict</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;This function averages the evaluation metrics across all GPU processes in the</span>
<span class="sd">        DDP mode for model distribution.</span>

<span class="sd">        Args:</span>
<span class="sd">            metrics: Dict[str, torch.Tensor]</span>
<span class="sd">                The evaluation metrics to be averaged across all GPU processes.</span>
<span class="sd">            batch_data: Dict</span>
<span class="sd">                The input batch data used to calculate the batch size for averaging evaluation metrics.</span>

<span class="sd">        Returns: Dict[str, torch.Tensor]</span>
<span class="sd">            The evaluation metrics _Dict_ after averaging. The key names remain the same.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">get_batch_size</span><span class="p">(</span><span class="n">input_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">):</span>
            <span class="n">_batch_size</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">input_dict</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="c1"># len() considers all types of array: torch.Tensor, np.ndarray, List, ...</span>
                <span class="k">if</span> <span class="n">_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="n">_batch_size</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">_batch_size</span>

        <span class="c1"># check the batch size</span>
        <span class="n">multi_flag</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
        <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="c1"># we take the summation of all data-labels pairs in a single batch made by multiple dataloaders</span>
        <span class="k">if</span> <span class="n">multi_flag</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">get_batch_size</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">get_batch_size</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># sum up all the weighed metrics at rank no.0</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="c1"># each metric should be one-dimensional scalar</span>
            <span class="k">if</span> <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="kc">None</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Each metric value must be one-dimensional scalar, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but got metrics[</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">]=</span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="si">}</span><span class="s2">!&quot;</span>
                <span class="p">)</span>

            <span class="c1"># batch_size acts as the weight for each metric value in the current process</span>
            <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">*=</span> <span class="n">batch_size</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="c1"># sum up the weighted metric values at rank no.0</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span>
                <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">dst</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span>
            <span class="p">)</span>

        <span class="c1"># sum up the batch size across at rank no.0 to get the overall batch size</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="c1"># turn the object value to the overall batch-level</span>
                <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">/=</span> <span class="n">batch_size</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">metrics</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">module_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">batch_data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function forwards the input batch data by all _Module_ members.</span>
<span class="sd">        Note:</span>
<span class="sd">            1. This interface function must be overridden for each Model subclass.</span>
<span class="sd">            2. The argument names should match the key names in the returned Dict of `self.batch_preprocess_fn()`.</span>
<span class="sd">            3. The key names in the returned Dict should match the argument names of `self.loss_calculation()` and</span>
<span class="sd">            `self.metrics_calculation()`.</span>

<span class="sd">        Args:</span>
<span class="sd">            epoch:</span>
<span class="sd">            **batch_data:</span>
<span class="sd">                Processed data of the input batch received from `self.batch_preprocess_fn()`.</span>

<span class="sd">        Returns: Dict</span>
<span class="sd">            Prediction results (logits) of the model on the input batch data.</span>
<span class="sd">            Some intermediate results (e.g., attention matrices) can also be returned for later use.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># raise NotImplementedError</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">criterion_forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="ow">or</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;This interface function is activated after `self.model_forward()`. It</span>
<span class="sd">        receives the model prediction results from `self.model_forward()` and input</span>
<span class="sd">        batch data from `self.batch_preprocess_fn()`.</span>

<span class="sd">        Args:</span>
<span class="sd">            **kwargs:</span>
<span class="sd">                The combination of the returned arguments from `self.batch_preprocess_fn()` and `self.model_forward()`.</span>

<span class="sd">        Returns: (Dict[str, torch.Tensor], Dict[str, torch.Tensor]) or Dict[str, torch.Tensor]</span>
<span class="sd">            The returned values should be different for the training and validation branches.</span>
<span class="sd">            1. For training, two Dict[str, torch.Tensor] should be returned where the first one contains all the</span>
<span class="sd">            trainable training losses for optimization and the second one contains all the non-trainable evaluation</span>
<span class="sd">            metrics used to record the training status.</span>
<span class="sd">            2. For validation, only one Dict[str, torch.Tensor] should be returned which contains all the non-trainable</span>
<span class="sd">            evaluation metrics used to record the validation status.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># raise NotImplementedError</span>

    <span class="k">def</span> <span class="nf">get_recordable_para</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Recursively retrieves the recordable parameters from the module&#39;s sub-</span>
<span class="sd">        modules.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dict[str, torch.Tensor]: A dictionary mapping the parameter names to their corresponding tensor values.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">recur_get_module_recordable_para</span><span class="p">(</span><span class="n">curr_node</span><span class="p">,</span> <span class="n">prefix_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">prefix_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">prefix_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">curr_node</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
                <span class="n">_output</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">_key</span><span class="p">,</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">curr_node</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">_output</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="n">recur_get_module_recordable_para</span><span class="p">(</span><span class="n">_value</span><span class="p">,</span> <span class="n">prefix_list</span> <span class="o">+</span> <span class="p">[</span><span class="n">_key</span><span class="p">])</span>
                    <span class="p">)</span>
                <span class="k">return</span> <span class="n">_output</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">curr_node</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">return</span> <span class="p">{}</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">curr_node</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">prefix_list</span><span class="p">):</span> <span class="n">curr_node</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()}</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span>

        <span class="n">output</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Module</span><span class="p">):</span>
                <span class="n">output</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="n">recur_get_module_recordable_para</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">get_recordable_para</span><span class="p">(),</span> <span class="p">[</span><span class="n">key</span><span class="p">])</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span> <span class="nf">matrix_snapshot</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">vis_logs</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span>
        <span class="n">hypo_attention</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">subfolder_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="ow">or</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Used by the abstract function visualize() to make the snapshot materials for</span>
<span class="sd">        attention matrices.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">subfolder_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">subfolder_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">subfolder_names</span><span class="p">]</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">hypo_attention</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="c1"># process the input data by different data types</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">Dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">matrix_snapshot</span><span class="p">(</span>
                    <span class="n">vis_logs</span><span class="o">=</span><span class="n">vis_logs</span><span class="p">,</span>
                    <span class="n">hypo_attention</span><span class="o">=</span><span class="n">value</span><span class="p">,</span>
                    <span class="n">subfolder_names</span><span class="o">=</span><span class="n">subfolder_names</span> <span class="o">+</span> <span class="p">[</span><span class="n">key</span><span class="p">],</span>
                    <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># snapshot the information in the materials</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">vis_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="nb">dict</span><span class="p">(</span>
                    <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;matrix&quot;</span><span class="p">,</span>
                    <span class="n">materials</span><span class="o">=</span><span class="n">hypo_attention</span><span class="p">,</span>
                    <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                    <span class="n">sep_save</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">data_save</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">subfolder_names</span><span class="o">=</span><span class="n">subfolder_names</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">attention_reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hypo_attention</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">prefix_list</span><span class="p">:</span> <span class="n">List</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Used by the abstract function visualize() to reshape the attention matrices</span>
<span class="sd">        before matrix_snapshot().&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">prefix_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prefix_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># process the input data by different data types</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="n">key</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_reshape</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">prefix_list</span> <span class="o">+</span> <span class="p">[</span><span class="n">key</span><span class="p">])</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">,</span> <span class="n">List</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="nb">str</span><span class="p">(</span><span class="n">index</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">)):</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_reshape</span><span class="p">(</span>
                    <span class="n">hypo_attention</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
                    <span class="n">prefix_list</span> <span class="o">+</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">index</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">))],</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">}</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">hypo_attention</span> <span class="o">=</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">:</span>
                <span class="n">hypo_attention</span> <span class="o">=</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">prefix_list</span> <span class="o">+</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="mi">0</span><span class="p">)]):</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">numpy</span><span class="p">()}</span>
            <span class="k">elif</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">{</span>
                    <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">prefix_list</span> <span class="o">+</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">index</span><span class="p">)]):</span> <span class="n">element</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">element</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">)</span>
                <span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">visualize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">sample_index</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">valid_sample</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            epoch:</span>
<span class="sd">            sample_index:</span>
<span class="sd">            **valid_sample:</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># raise NotImplementedError</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">infer_conf</span><span class="p">:</span> <span class="n">Dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The shared evaluation function by all _Model_ subclasses. This evaluation function has 2 steps:</span>
<span class="sd">            1. preprocess and transfer the batch data to GPUs</span>
<span class="sd">            2. calculate the inference results</span>

<span class="sd">        For each step above, we provide interface functions for you to override and make your own implementation.</span>

<span class="sd">        Args:</span>
<span class="sd">            test_batch: Dict</span>
<span class="sd">                The input batch data received from the `test` dataloader object in the experimental pipeline.</span>
<span class="sd">            infer_conf: Dict</span>
<span class="sd">                The configuration used for model inference.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A Dict of the inference results where each key-value item corresponds to one evaluation metric you want to</span>
<span class="sd">            save to the disk.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># preprocess the batch data if needed</span>
        <span class="n">test_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_preprocess_fn</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span>

        <span class="c1"># put the batch data onto GPUs</span>
        <span class="n">test_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_to_cuda</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span>

        <span class="c1"># get the inference results</span>
        <span class="n">evaluate_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">infer_conf</span><span class="o">=</span><span class="n">infer_conf</span><span class="p">,</span> <span class="o">**</span><span class="n">test_batch</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;instance_report_cache&quot;</span><span class="p">)</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">instance_report_cache</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">):</span>
            <span class="n">evaluate_results</span><span class="p">[</span><span class="s2">&quot;instance_reports.md&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">instance_report_cache</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">instance_report_cache</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># post-check the format of evaluate_results</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">evaluate_results</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">evaluate_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="s2">&quot;format&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">or</span> <span class="s2">&quot;content&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;Each element of the returned value of self.inference() must contain the keys &quot;</span>
                        <span class="s2">&quot;named both &#39;format&#39; and &#39;content&#39;!&quot;</span>
                    <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The returned value of self.inference() must be a Dict, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">evaluate_results</span><span class="p">)</span><span class="si">}</span><span class="s2">!&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">evaluate_results</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">infer_conf</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span> <span class="ow">or</span> <span class="n">List</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;This function receives the test data and test configuration. The inference</span>
<span class="sd">        results will be packaged into a Dict[str, Dict] which is passed to TestMonitor</span>
<span class="sd">        for disk storage. The returned Dict should be in the form of ``` dict(</span>
<span class="sd">        {file_name}=dict( format={file_format},</span>

<span class="sd">                content={file_content}</span>
<span class="sd">            )</span>
<span class="sd">        )</span>
<span class="sd">        ```</span>
<span class="sd">        The first-level key is used to decide the name of the meta file as `idx2{file_name}`. Its value is also a Dict</span>
<span class="sd">        and there must be two keys in this sub-Dict: &#39;format&#39; and &#39;content&#39;. The configuration of the sub-Dict is</span>
<span class="sd">        different for different file formats:</span>

<span class="sd">            1. For pure text metadata files, the value of &#39;format&#39; must be &#39;txt&#39; and the value of &#39;content&#39; must be a</span>
<span class="sd">            list of Python built-in data type (i.e.,. int, float, str, bool, ...).</span>
<span class="sd">            Each line of the file `idx2{file_name}` will be made up of the index of a test data instance and its</span>
<span class="sd">            metadata value in the `content` List which are separated by a blank.</span>
<span class="sd">            For example,</span>
<span class="sd">            `dict(cer=dict(format=&#39;txt&#39;, content=[0.1, 0.2, 0.3]))` will create a pure text file named &#39;idx2cer&#39; which</span>
<span class="sd">            looks like</span>
<span class="sd">            ```</span>
<span class="sd">            {test_index1} 0.1</span>
<span class="sd">            {test_index2} 0.2</span>
<span class="sd">            {test_index3} 0.3</span>
<span class="sd">            ```</span>
<span class="sd">            Note: if the first-level key ends with &#39;.md&#39;, there will not be &#39;idx2&#39; attached at the beginning of the</span>
<span class="sd">            file name.</span>

<span class="sd">            2. For audio files, the value of &#39;format&#39; must be either &#39;wav&#39; or &#39;flac&#39; and the value of &#39;content&#39; must be</span>
<span class="sd">            a list of array-like data type (e.g. numpy.ndarry, torch.Tensor, ...).</span>
<span class="sd">            Moreover, there must be an additional key named &#39;sample_rate&#39; to indicate the sampling rate of the waveforms</span>
<span class="sd">            to be saved in audio files.</span>
<span class="sd">            There will be a folder named `{file_name}` that contains all the audio files and a pure text file named</span>
<span class="sd">            `idx2{file_name}` that contains the absolute paths of all the saved audio files.</span>
<span class="sd">            For example,</span>
<span class="sd">            `dict(wav=dict(format=&#39;flac&#39;, content=[np_arr1, np_arr2, np_arr3]))` will create a folder named &#39;wav&#39; and</span>
<span class="sd">            a pure text file named &#39;idx2wav&#39; in the same directory. The file &#39;idx2wav&#39; looks like:</span>
<span class="sd">            ```</span>
<span class="sd">            {test_index1} /x/xx/wav/{test_index1}.flac</span>
<span class="sd">            {test_index2} /x/xx/wav/{test_index2}.flac</span>
<span class="sd">            {test_index3} /x/xx/wav/{test_index3}.flac</span>
<span class="sd">            ```</span>
<span class="sd">            where `/x/xx/` is your result path given in your `exp_cfg`.</span>

<span class="sd">            3. For binary files, the value of &#39;format&#39; in the sub-Dict must be &#39;npy&#39; and the value of &#39;content&#39; must be</span>
<span class="sd">            a list of numpy.ndarry (torch.Tensor is not supported).</span>
<span class="sd">            There will be a folder named `{file_name}` that contains all the .npy files and a pure text file</span>
<span class="sd">            named `idx2{file_name}` that contains the absolute paths of all the saved binary files.</span>
<span class="sd">            For example,</span>
<span class="sd">            `dict(feat=dict(format=&#39;npy&#39;, content=[np_arr1, np_arr2, np_arr3]))`</span>
<span class="sd">            will create a folder named &#39;feat&#39; and a pure text file named &#39;idx2feat&#39;. The &#39;idx2feat&#39; file is like:</span>
<span class="sd">            ```</span>
<span class="sd">            {test_index1} /x/xx/feat/{test_index1}.npy</span>
<span class="sd">            {test_index2} /x/xx/feat/{test_index2}.npy</span>
<span class="sd">            {test_index3} /x/xx/feat/{test_index3}.npy</span>
<span class="sd">            ```</span>
<span class="sd">            where `/x/xx/` is your result path given in your `exp_cfg`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span>  <span class="c1"># raise NotImplementedError</span>

    <span class="k">def</span> <span class="nf">register_instance_reports</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">md_list_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">],</span> <span class="n">extra_string_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            md_list_dict:</span>
<span class="sd">            extra_string_list:</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># --- 1. Arguments Checking --- #</span>
        <span class="k">if</span> <span class="n">extra_string_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">extra_string_list</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span>

        <span class="n">ele_len</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">md_list_dict</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">extra_string_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">extra_string_list</span><span class="p">)</span>
            <span class="n">ele_len</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">ele_len</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">ele_len</span> <span class="o">=</span> <span class="n">ele_len</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span>

        <span class="c1"># --- 2. Generate .md Instance Report for the current step --- #</span>
        <span class="n">instance_reports</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ele_len</span><span class="p">):</span>
            <span class="n">ele_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">md_list_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
            <span class="n">_curr_report</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">get_list_strings</span><span class="p">(</span><span class="n">ele_dict</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

            <span class="k">if</span> <span class="n">extra_string_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_curr_report</span> <span class="o">+=</span> <span class="n">extra_string_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">instance_reports</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_curr_report</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">instance_report_cache</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">instance_reports</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">module_conf</span><span class="p">,</span> <span class="n">result_path</span><span class="p">,</span> <span class="n">model_conf</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">criterion_conf</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">distributed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>In this initialization function, there are two parts of
initialization: model-specific customized initialization and model-
independent general initialization.</p>
<p>Model-specific customized initialization is done by two interface functions: module_init() and criterion_init().
module_init() initializes the neural network structure of the model while criterion_init() initializes the
criteria used to optimize (loss functions) and evaluate (validation metrics) the model.</p>
<p>After the customized initialization, there are 3 steps for general initialization:
    1. Pretrained parameters will be loaded into your model if the key <code>pretrained_model</code> is given. Multiple
    pretrained models can be specified and each of them can be loaded into different parts of your model. The
    mismatch between the names of pretrained parameters and the parameters of your model is handled by the key
    'mapping'. The value of the key <code>mapping</code> is a dictionary where each key-value item corresponds to a mapping
    of parameter names. The key is the parameter name in the pretrained parameters while the value is the
    parameter name of your model.</p>
<div class="language-text highlight"><pre><span></span><code>2. If `pretrained_model` is not given, the parameters of your model will be initialized by the function that
matches your input query &#39;init&#39;. Please refer to the built-in dictionary `init_class_dict` for the available
initialization functions. If `init` is not given, the default initialization function
`torch.nn.init.xavier_normal_` will be used to initialize your model.

3. Finally, the specified parts of your model will be frozen if &#39;frozen_modules&#39; is given. If there is only
one frozen module, you can directly give the string of its name to &#39;frozen_modules&#39; like
&#39;frozen_modules: {module_name}&#39;; if there are multiple modules you want to freeze, you can give their names
in a list as
```
frozen_modules:
  - {module_name1}
  - {module_name2}
  - ...
```
Moreover, the frozen granularity depends on your input `frozen_modules`.
For example,
    1. If you give &#39;frozen_modules: encoder_prenet&#39;, all parameters of the prenet of your encoder will be
    frozen
    2. If you give &#39;frozen_modules: encoder_prenet.conv&#39;, only the convolution layers of the prenet of your
    encoder will be frozen
    3. If you give &#39;frozen_modules: encoder_prenet.conv.0&#39;, only the first convolution layer of the prenet
    of your encoder will be frozen
    4. If you give &#39;frozen_modules: encoder_prenet.conv.0.bias&#39;, only the bias vector of the first
    convolution layer of the prenet of your encoder will be frozen
</code></pre></div>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>device</code>
            </td>
            <td>
                  <code><span title="torch.device">device</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The computational device used for model calculation in the current GPU process.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>model_conf</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The model configuration used for general model initialization.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>module_conf</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The module configuration used for network structure initialization.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>criterion_conf</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The criterion configuration used for criterion (loss functions and evaluation metrics) initialization.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="n">module_conf</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">result_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model_conf</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">criterion_conf</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">non_blocking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">distributed</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;In this initialization function, there are two parts of</span>
<span class="sd">    initialization: model-specific customized initialization and model-</span>
<span class="sd">    independent general initialization.</span>

<span class="sd">    Model-specific customized initialization is done by two interface functions: module_init() and criterion_init().</span>
<span class="sd">    module_init() initializes the neural network structure of the model while criterion_init() initializes the</span>
<span class="sd">    criteria used to optimize (loss functions) and evaluate (validation metrics) the model.</span>

<span class="sd">    After the customized initialization, there are 3 steps for general initialization:</span>
<span class="sd">        1. Pretrained parameters will be loaded into your model if the key `pretrained_model` is given. Multiple</span>
<span class="sd">        pretrained models can be specified and each of them can be loaded into different parts of your model. The</span>
<span class="sd">        mismatch between the names of pretrained parameters and the parameters of your model is handled by the key</span>
<span class="sd">        &#39;mapping&#39;. The value of the key `mapping` is a dictionary where each key-value item corresponds to a mapping</span>
<span class="sd">        of parameter names. The key is the parameter name in the pretrained parameters while the value is the</span>
<span class="sd">        parameter name of your model.</span>

<span class="sd">        2. If `pretrained_model` is not given, the parameters of your model will be initialized by the function that</span>
<span class="sd">        matches your input query &#39;init&#39;. Please refer to the built-in dictionary `init_class_dict` for the available</span>
<span class="sd">        initialization functions. If `init` is not given, the default initialization function</span>
<span class="sd">        `torch.nn.init.xavier_normal_` will be used to initialize your model.</span>

<span class="sd">        3. Finally, the specified parts of your model will be frozen if &#39;frozen_modules&#39; is given. If there is only</span>
<span class="sd">        one frozen module, you can directly give the string of its name to &#39;frozen_modules&#39; like</span>
<span class="sd">        &#39;frozen_modules: {module_name}&#39;; if there are multiple modules you want to freeze, you can give their names</span>
<span class="sd">        in a list as</span>
<span class="sd">        ```</span>
<span class="sd">        frozen_modules:</span>
<span class="sd">          - {module_name1}</span>
<span class="sd">          - {module_name2}</span>
<span class="sd">          - ...</span>
<span class="sd">        ```</span>
<span class="sd">        Moreover, the frozen granularity depends on your input `frozen_modules`.</span>
<span class="sd">        For example,</span>
<span class="sd">            1. If you give &#39;frozen_modules: encoder_prenet&#39;, all parameters of the prenet of your encoder will be</span>
<span class="sd">            frozen</span>
<span class="sd">            2. If you give &#39;frozen_modules: encoder_prenet.conv&#39;, only the convolution layers of the prenet of your</span>
<span class="sd">            encoder will be frozen</span>
<span class="sd">            3. If you give &#39;frozen_modules: encoder_prenet.conv.0&#39;, only the first convolution layer of the prenet</span>
<span class="sd">            of your encoder will be frozen</span>
<span class="sd">            4. If you give &#39;frozen_modules: encoder_prenet.conv.0.bias&#39;, only the bias vector of the first</span>
<span class="sd">            convolution layer of the prenet of your encoder will be frozen</span>

<span class="sd">    Args:</span>
<span class="sd">        device (torch.device):</span>
<span class="sd">            The computational device used for model calculation in the current GPU process.</span>
<span class="sd">        model_conf (Dict):</span>
<span class="sd">            The model configuration used for general model initialization.</span>
<span class="sd">        module_conf (Dict):</span>
<span class="sd">            The module configuration used for network structure initialization.</span>
<span class="sd">        criterion_conf (Dict):</span>
<span class="sd">            The criterion configuration used for criterion (loss functions and evaluation metrics) initialization.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># input argument checking</span>
    <span class="k">assert</span> <span class="n">module_conf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;module_conf cannot be None!&quot;</span>
    <span class="c1"># model_conf is default to be an empty dictionary</span>
    <span class="n">model_conf</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span> <span class="k">if</span> <span class="n">model_conf</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">model_conf</span>
    <span class="c1"># criterion_conf is default to be an empty dictionary</span>
    <span class="n">criterion_conf</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span> <span class="k">if</span> <span class="n">criterion_conf</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">criterion_conf</span>
    <span class="c1"># customize_conf is default to be an empty dictionary</span>
    <span class="k">if</span> <span class="s2">&quot;customize_conf&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">model_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;customize_conf&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

    <span class="c1"># general argument registration</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">non_blocking</span> <span class="o">=</span> <span class="n">non_blocking</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span> <span class="o">=</span> <span class="n">distributed</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>

    <span class="c1"># snapshotting-related argument registration</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">result_path</span> <span class="o">=</span> <span class="n">result_path</span>
    <span class="k">if</span> <span class="s2">&quot;visual_infer_conf&quot;</span> <span class="ow">in</span> <span class="n">model_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="c1"># configuration is given as a .yaml file</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;visual_infer_conf&quot;</span><span class="p">],</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">visual_infer_conf</span> <span class="o">=</span> <span class="n">load_yaml</span><span class="p">(</span>
                <span class="nb">open</span><span class="p">(</span><span class="n">parse_path_args</span><span class="p">(</span><span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;visual_infer_conf&quot;</span><span class="p">]))</span>
            <span class="p">)</span>
        <span class="c1"># configuration is explicitly given</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;visual_infer_conf&quot;</span><span class="p">],</span> <span class="n">Dict</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">visual_infer_conf</span> <span class="o">=</span> <span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;visual_infer_conf&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;model_conf[&#39;visual_infer_conf&#39;] must be given as either a string or a Dict.&quot;</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">visual_infer_conf</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

    <span class="c1"># --- 1. Model Construction --- #</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">module_init</span><span class="p">(</span><span class="o">**</span><span class="n">module_conf</span><span class="p">,</span> <span class="o">**</span><span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;customize_conf&quot;</span><span class="p">])</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">criterion_init</span><span class="p">(</span><span class="o">**</span><span class="n">criterion_conf</span><span class="p">)</span>
    <span class="c1"># initialize the bad case selection methods by the hook function</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bad_cases_selection</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bad_cases_selection_init_fn</span><span class="p">()</span>

    <span class="c1"># --- 2.1. Pretrained Model Loading --- #</span>
    <span class="n">pretrained_model</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;pretrained_model&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s2">&quot;pretrained_model&quot;</span> <span class="ow">in</span> <span class="n">model_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
        <span class="k">else</span> <span class="kc">None</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">pretrained_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">pretrained_model</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">pretrained_model</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pretrained_model</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
            <span class="k">else</span> <span class="p">[</span><span class="n">pretrained_model</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">ptm</span> <span class="ow">in</span> <span class="n">pretrained_model</span><span class="p">:</span>
            <span class="c1"># argument checking</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ptm</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">ptm</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="n">parse_path_args</span><span class="p">(</span><span class="n">ptm</span><span class="p">))</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ptm</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
                <span class="k">assert</span> <span class="s2">&quot;path&quot;</span> <span class="ow">in</span> <span class="n">ptm</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="p">(</span>
                    <span class="s2">&quot;If model[&#39;model_conf&#39;][&#39;pretrained_model&#39;] is given as a Dict, &quot;</span>
                    <span class="s2">&quot;please give a key named &#39;path&#39; to specify where your pretrained model is placed.&quot;</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">ptm</span><span class="p">[</span><span class="s2">&quot;path&quot;</span><span class="p">]):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;The specified path of your pretrained model </span><span class="si">{</span><span class="n">ptm</span><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> doesn&#39;t exist! &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Please check the input path.&quot;</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;The elements in model[&#39;model_conf&#39;][&#39;pretrained_model&#39;] must be either a string &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;or a Dict, but got </span><span class="si">{</span><span class="n">ptm</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="n">_pt_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
                <span class="n">parse_path_args</span><span class="p">(</span><span class="n">ptm</span><span class="p">[</span><span class="s2">&quot;path&quot;</span><span class="p">]),</span> <span class="n">map_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="n">mapping</span> <span class="o">=</span> <span class="n">ptm</span><span class="p">[</span><span class="s2">&quot;mapping&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;mapping&quot;</span> <span class="ow">in</span> <span class="n">ptm</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">mapping</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                    <span class="n">_pt_model</span><span class="p">,</span>
                    <span class="n">strict</span><span class="o">=</span><span class="kc">True</span> <span class="k">if</span> <span class="s2">&quot;strict&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ptm</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="n">ptm</span><span class="p">[</span><span class="s2">&quot;strict&quot;</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mapping</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;mapping must be given as a dict and cannot be empty! &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Got type(mapping)=</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span><span class="si">}</span><span class="s2"> and len(mapping)=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

                <span class="n">_src_modules</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
                <span class="c1"># loop each name-parameter pair in the model</span>
                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">para</span> <span class="ow">in</span> <span class="n">_pt_model</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="c1"># loop each source-target mapping pair</span>
                    <span class="k">for</span> <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span> <span class="ow">in</span> <span class="n">mapping</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="c1"># attach &#39;.&#39; to the end is for making the name unique</span>
                        <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">=</span> <span class="n">src</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span>
                        <span class="c1"># change the parameter name in the middle</span>
                        <span class="k">if</span> <span class="n">src</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                            <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="p">)</span>
                    <span class="c1"># record the parameter no matter whether its name is modified or not</span>
                    <span class="n">_src_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">para</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                    <span class="n">_src_modules</span><span class="p">,</span>
                    <span class="n">strict</span><span class="o">=</span><span class="kc">True</span> <span class="k">if</span> <span class="s2">&quot;strict&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ptm</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="n">ptm</span><span class="p">[</span><span class="s2">&quot;strict&quot;</span><span class="p">],</span>
                <span class="p">)</span>

    <span class="c1"># --- 2.2. Model Parameter Initialization --- #</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># the default initialization method is xavier (i.e. xavier_normal)</span>
        <span class="n">init</span> <span class="o">=</span> <span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;init&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="s2">&quot;init&quot;</span> <span class="ow">in</span> <span class="n">model_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;xavier&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">init</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_class_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Only the initialization methods </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">init_class_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2"> are supported, but got init=</span><span class="si">{</span><span class="n">init</span><span class="si">}</span><span class="s2">.&quot;</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">para</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="c1"># initialize all the bias vectors to zero</span>
            <span class="k">if</span> <span class="s2">&quot;.bias&quot;</span> <span class="ow">in</span> <span class="n">name</span> <span class="ow">and</span> <span class="n">para</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">para</span><span class="p">)</span>
            <span class="c1"># initialize all the weight vectors except for those of normalization layers (BatchNorm &amp; LayerNorm)</span>
            <span class="k">elif</span> <span class="n">para</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">init_class_dict</span><span class="p">[</span><span class="n">init</span><span class="p">](</span><span class="n">para</span><span class="p">)</span>

        <span class="c1"># initialize the modules that have their own default init methods</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">default_init_modules</span><span class="p">)):</span>
                <span class="n">module</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>

    <span class="c1"># --- 3. Model Parameter Freezing --- #</span>
    <span class="n">frozen_modules</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">model_conf</span><span class="p">[</span><span class="s2">&quot;frozen_modules&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s2">&quot;frozen_modules&quot;</span> <span class="ow">in</span> <span class="n">model_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
        <span class="k">else</span> <span class="kc">None</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">frozen_modules</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">frozen_modules</span> <span class="o">!=</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
            <span class="n">frozen_modules</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">frozen_modules</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">frozen_modules</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
                <span class="k">else</span> <span class="p">[</span><span class="n">frozen_modules</span><span class="p">]</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">para</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="n">frozen_flag</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="n">frozen_modules</span> <span class="o">!=</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">frozen_modules</span><span class="p">:</span>
                    <span class="n">frozen_flag</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">module</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">frozen_flag</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="k">if</span> <span class="n">frozen_flag</span><span class="p">:</span>
                <span class="n">para</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;frozen_modules: Parameters of </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> are not found in the model!&quot;</span>
                <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.attention_reshape" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">attention_reshape</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">,</span> <span class="n">prefix_list</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Used by the abstract function visualize() to reshape the attention matrices
before matrix_snapshot().</p>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">attention_reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hypo_attention</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">prefix_list</span><span class="p">:</span> <span class="n">List</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Used by the abstract function visualize() to reshape the attention matrices</span>
<span class="sd">    before matrix_snapshot().&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">prefix_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">prefix_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># process the input data by different data types</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_reshape</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">prefix_list</span> <span class="o">+</span> <span class="p">[</span><span class="n">key</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">,</span> <span class="n">List</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="nb">str</span><span class="p">(</span><span class="n">index</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">)):</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_reshape</span><span class="p">(</span>
                <span class="n">hypo_attention</span><span class="p">[</span><span class="n">index</span><span class="p">],</span>
                <span class="n">prefix_list</span> <span class="o">+</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">index</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">))],</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">hypo_attention</span> <span class="o">=</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">:</span>
            <span class="n">hypo_attention</span> <span class="o">=</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">prefix_list</span> <span class="o">+</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="mi">0</span><span class="p">)]):</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">numpy</span><span class="p">()}</span>
        <span class="k">elif</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">prefix_list</span> <span class="o">+</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">index</span><span class="p">)]):</span> <span class="n">element</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">element</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">)</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.aver_metrics_across_procs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">aver_metrics_across_procs</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>This function averages the evaluation metrics across all GPU processes in the
DDP mode for model distribution.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>metrics</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict[str, torch.Tensor]
The evaluation metrics to be averaged across all GPU processes.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>batch_data</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict
The input batch data used to calculate the batch size for averaging evaluation metrics.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Dict[str, torch.Tensor]</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The evaluation metrics <em>Dict</em> after averaging. The key names remain the same.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">aver_metrics_across_procs</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">batch_data</span><span class="p">:</span> <span class="n">Dict</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This function averages the evaluation metrics across all GPU processes in the</span>
<span class="sd">    DDP mode for model distribution.</span>

<span class="sd">    Args:</span>
<span class="sd">        metrics: Dict[str, torch.Tensor]</span>
<span class="sd">            The evaluation metrics to be averaged across all GPU processes.</span>
<span class="sd">        batch_data: Dict</span>
<span class="sd">            The input batch data used to calculate the batch size for averaging evaluation metrics.</span>

<span class="sd">    Returns: Dict[str, torch.Tensor]</span>
<span class="sd">        The evaluation metrics _Dict_ after averaging. The key names remain the same.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">get_batch_size</span><span class="p">(</span><span class="n">input_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">):</span>
        <span class="n">_batch_size</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">input_dict</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="c1"># len() considers all types of array: torch.Tensor, np.ndarray, List, ...</span>
            <span class="k">if</span> <span class="n">_batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">_batch_size</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_batch_size</span>

    <span class="c1"># check the batch size</span>
    <span class="n">multi_flag</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
        <span class="p">[</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
    <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
    <span class="c1"># we take the summation of all data-labels pairs in a single batch made by multiple dataloaders</span>
    <span class="k">if</span> <span class="n">multi_flag</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">get_batch_size</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">get_batch_size</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">batch_size</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># sum up all the weighed metrics at rank no.0</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="c1"># each metric should be one-dimensional scalar</span>
        <span class="k">if</span> <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="kc">None</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Each metric value must be one-dimensional scalar, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but got metrics[</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">]=</span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="si">}</span><span class="s2">!&quot;</span>
            <span class="p">)</span>

        <span class="c1"># batch_size acts as the weight for each metric value in the current process</span>
        <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">*=</span> <span class="n">batch_size</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="c1"># sum up the weighted metric values at rank no.0</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span>
            <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">dst</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span>
        <span class="p">)</span>

    <span class="c1"># sum up the batch size across at rank no.0 to get the overall batch size</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="c1"># turn the object value to the overall batch-level</span>
            <span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">/=</span> <span class="n">batch_size</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">metrics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.bad_cases_selection_init_fn" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">bad_cases_selection_init_fn</span><span class="p">()</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">

        <p>This hook function returns the default bad case selection method of each
Model object. This default value will be referred by the <em>Runner</em> to present the
top-N bad cases.</p>
<p>The original hook implementation in the base Model class returns None which means no default value.</p>


    <p><span class="doc-section-title">List[List[str or int]]</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="typing.List">List</span>[str or int]] or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The returned default value should be a list of tri-list where each tri-list is in the form of</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="typing.List">List</span>[str or int]] or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>[<code>selection_metric</code>, <code>selection_mode</code>, <code>case_number</code>]. For example, ['wer', 'max', 50] means 50 testing</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.List">List</span>[<span title="typing.List">List</span>[str or int]] or None</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>waveforms with the largest WER will be selected.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">bad_cases_selection_init_fn</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span> <span class="ow">or</span> <span class="nb">int</span><span class="p">]]</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This hook function returns the default bad case selection method of each</span>
<span class="sd">    Model object. This default value will be referred by the _Runner_ to present the</span>
<span class="sd">    top-N bad cases.</span>

<span class="sd">    The original hook implementation in the base Model class returns None which means no default value.</span>

<span class="sd">    Returns: List[List[str or int]]</span>
<span class="sd">        The returned default value should be a list of tri-list where each tri-list is in the form of</span>
<span class="sd">        [`selection_metric`, `selection_mode`, `case_number`]. For example, [&#39;wer&#39;, &#39;max&#39;, 50] means 50 testing</span>
<span class="sd">        waveforms with the largest WER will be selected.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.batch_preprocess_fn" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">batch_preprocess_fn</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>This hook function does the preprocessing for the input batch data before
using them in self.model_forward(). This function is not mandatory to be
overridden and the original implementation in the base Model class does the
tensor transformation for the string-like data in batch_data (i.e., text and
spk_ids).</p>
<p>Note: the key names in the returned Dict should match the argument names in self.model_forward().</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>batch_data</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict
The raw data of the input batch to be preprocessed in this hook function.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Dict</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The processed data of the input batch that is ready to be used in <code>self.model_forward()</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">batch_preprocess_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This hook function does the preprocessing for the input batch data before</span>
<span class="sd">    using them in self.model_forward(). This function is not mandatory to be</span>
<span class="sd">    overridden and the original implementation in the base Model class does the</span>
<span class="sd">    tensor transformation for the string-like data in batch_data (i.e., text and</span>
<span class="sd">    spk_ids).</span>

<span class="sd">    Note: the key names in the returned Dict should match the argument names in self.model_forward().</span>

<span class="sd">    Args:</span>
<span class="sd">        batch_data: Dict</span>
<span class="sd">            The raw data of the input batch to be preprocessed in this hook function.</span>

<span class="sd">    Returns: Dict</span>
<span class="sd">        The processed data of the input batch that is ready to be used in `self.model_forward()`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">process_strings</span><span class="p">(</span><span class="n">data_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Turn the text and speaker strings into tensors and get their lengths.&quot;&quot;&quot;</span>
        <span class="c1"># --- Process the Text String and its Length --- #</span>
        <span class="k">if</span> <span class="s2">&quot;text&quot;</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">List</span><span class="p">):</span>
                <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;text_len&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text2tensor_and_len</span><span class="p">(</span>
                    <span class="n">text_list</span><span class="o">=</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span>
                    <span class="n">text2tensor_func</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">text2tensor</span><span class="p">,</span>
                    <span class="n">ignore_idx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>

        <span class="c1"># --- Process the Speaker ID String --- #</span>
        <span class="k">if</span> <span class="s2">&quot;spk_ids&quot;</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;spk_ids&quot;</span><span class="p">],</span> <span class="n">List</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;spk2idx&quot;</span><span class="p">):</span>
                    <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;spk_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">spk2tensor</span><span class="p">(</span>
                        <span class="n">spk_list</span><span class="o">=</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;spk_ids&quot;</span><span class="p">],</span> <span class="n">spk2idx_dict</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">spk2idx</span>
                    <span class="p">)</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;spk_ids&quot;</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span>

        <span class="k">return</span> <span class="n">data_dict</span>

    <span class="c1"># check whether the batch_data is made by multiple dataloaders</span>
    <span class="n">leaf_flags</span> <span class="o">=</span> <span class="p">[</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
    <span class="k">if</span> <span class="nb">sum</span><span class="p">(</span><span class="n">leaf_flags</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">process_strings</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">elif</span> <span class="nb">sum</span><span class="p">(</span><span class="n">leaf_flags</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_data</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">process_strings</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Wrong composition of batch_data!&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.batch_to_cuda" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">batch_to_cuda</span><span class="p">(</span><span class="n">data</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>The recursive function that transfers the batch data to the specified device
in the current process.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>data</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>] or <span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict or torch.Tensor
The input batch data. It should be either a Tensor or a Dict of Tensors. For the Dict input, the
function itself will be called once by each Tensor element.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Dict or torch.Tensor</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>] or <span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the input is a Dict, the returned output will also be a Dict of Tensors transferred to the target device;</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>] or <span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If the input is a Tensor, the returned output will be its copy on the target device.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">batch_to_cuda</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The recursive function that transfers the batch data to the specified device</span>
<span class="sd">    in the current process.</span>

<span class="sd">    Args:</span>
<span class="sd">        data: Dict or torch.Tensor</span>
<span class="sd">            The input batch data. It should be either a Tensor or a Dict of Tensors. For the Dict input, the</span>
<span class="sd">            function itself will be called once by each Tensor element.</span>

<span class="sd">    Returns: Dict or torch.Tensor</span>
<span class="sd">        If the input is a Dict, the returned output will also be a Dict of Tensors transferred to the target device;</span>
<span class="sd">        If the input is a Tensor, the returned output will be its copy on the target device.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># if the data is in the form of Dict, recursively process each key-value pair</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_to_cuda</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="c1"># if the data is in the form of tensor, put it on GPUs by .cuda()</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">non_blocking</span><span class="p">)</span>
    <span class="c1"># do nothing for other types of data</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">data</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.criterion_forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">criterion_forward</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">

        <p>This interface function is activated after <code>self.model_forward()</code>. It
receives the model prediction results from <code>self.model_forward()</code> and input
batch data from <code>self.batch_preprocess_fn()</code>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The combination of the returned arguments from <code>self.batch_preprocess_fn()</code> and <code>self.model_forward()</code>.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">(Dict[str, torch.Tensor], Dict[str, torch.Tensor]) or Dict[str, torch.Tensor]</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>(<span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>], <span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]) or <span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The returned values should be different for the training and validation branches.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>(<span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>], <span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]) or <span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <ol>
<li>For training, two Dict[str, torch.Tensor] should be returned where the first one contains all the</li>
</ol>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>(<span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>], <span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]) or <span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>trainable training losses for optimization and the second one contains all the non-trainable evaluation</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>(<span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>], <span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]) or <span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>metrics used to record the training status.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>(<span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>], <span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]) or <span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <ol>
<li>For validation, only one Dict[str, torch.Tensor] should be returned which contains all the non-trainable</li>
</ol>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>(<span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>], <span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]) or <span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>evaluation metrics used to record the validation status.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span> <span class="nf">criterion_forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="ow">or</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This interface function is activated after `self.model_forward()`. It</span>
<span class="sd">    receives the model prediction results from `self.model_forward()` and input</span>
<span class="sd">    batch data from `self.batch_preprocess_fn()`.</span>

<span class="sd">    Args:</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            The combination of the returned arguments from `self.batch_preprocess_fn()` and `self.model_forward()`.</span>

<span class="sd">    Returns: (Dict[str, torch.Tensor], Dict[str, torch.Tensor]) or Dict[str, torch.Tensor]</span>
<span class="sd">        The returned values should be different for the training and validation branches.</span>
<span class="sd">        1. For training, two Dict[str, torch.Tensor] should be returned where the first one contains all the</span>
<span class="sd">        trainable training losses for optimization and the second one contains all the non-trainable evaluation</span>
<span class="sd">        metrics used to record the training status.</span>
<span class="sd">        2. For validation, only one Dict[str, torch.Tensor] should be returned which contains all the non-trainable</span>
<span class="sd">        evaluation metrics used to record the validation status.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span>  <span class="c1"># raise NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.criterion_init" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">criterion_init</span><span class="p">(</span><span class="o">**</span><span class="n">criterion_conf</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">

        <p>The interface function that initializes the Criterion members of the model. These Criterion members can be
divided into two parts: the loss functions used for training and the evaluation metrics used for validation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>**criterion_conf</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The arguments in your given <code>criterion_conf</code>.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span> <span class="nf">criterion_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">criterion_conf</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The interface function that initializes the Criterion members of the model. These Criterion members can be</span>
<span class="sd">    divided into two parts: the loss functions used for training and the evaluation metrics used for validation.</span>

<span class="sd">    Args:</span>
<span class="sd">        **criterion_conf:</span>
<span class="sd">            The arguments in your given `criterion_conf`.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span>  <span class="c1"># raise NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.evaluate" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="n">test_batch</span><span class="p">,</span> <span class="n">infer_conf</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>The shared evaluation function by all <em>Model</em> subclasses. This evaluation function has 2 steps:
    1. preprocess and transfer the batch data to GPUs
    2. calculate the inference results</p>
<p>For each step above, we provide interface functions for you to override and make your own implementation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>test_batch</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict
The input batch data received from the <code>test</code> dataloader object in the experimental pipeline.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>infer_conf</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict
The configuration used for model inference.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A Dict of the inference results where each key-value item corresponds to one evaluation metric you want to</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>save to the disk.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_batch</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">infer_conf</span><span class="p">:</span> <span class="n">Dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The shared evaluation function by all _Model_ subclasses. This evaluation function has 2 steps:</span>
<span class="sd">        1. preprocess and transfer the batch data to GPUs</span>
<span class="sd">        2. calculate the inference results</span>

<span class="sd">    For each step above, we provide interface functions for you to override and make your own implementation.</span>

<span class="sd">    Args:</span>
<span class="sd">        test_batch: Dict</span>
<span class="sd">            The input batch data received from the `test` dataloader object in the experimental pipeline.</span>
<span class="sd">        infer_conf: Dict</span>
<span class="sd">            The configuration used for model inference.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A Dict of the inference results where each key-value item corresponds to one evaluation metric you want to</span>
<span class="sd">        save to the disk.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># preprocess the batch data if needed</span>
    <span class="n">test_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_preprocess_fn</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span>

    <span class="c1"># put the batch data onto GPUs</span>
    <span class="n">test_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_to_cuda</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span>

    <span class="c1"># get the inference results</span>
    <span class="n">evaluate_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">infer_conf</span><span class="o">=</span><span class="n">infer_conf</span><span class="p">,</span> <span class="o">**</span><span class="n">test_batch</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;instance_report_cache&quot;</span><span class="p">)</span>
        <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">instance_report_cache</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="p">):</span>
        <span class="n">evaluate_results</span><span class="p">[</span><span class="s2">&quot;instance_reports.md&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">instance_report_cache</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">instance_report_cache</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># post-check the format of evaluate_results</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">evaluate_results</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">evaluate_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="s2">&quot;format&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">or</span> <span class="s2">&quot;content&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">value</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Each element of the returned value of self.inference() must contain the keys &quot;</span>
                    <span class="s2">&quot;named both &#39;format&#39; and &#39;content&#39;!&quot;</span>
                <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The returned value of self.inference() must be a Dict, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">evaluate_results</span><span class="p">)</span><span class="si">}</span><span class="s2">!&quot;</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">evaluate_results</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>The general model forward function shared by all the <em>Model</em> subclasses. This forward function has 3 steps:
    1. preprocess and transfer the batch data to GPUs
    2. obtain the model prediction results
    3. calculate the loss function and evaluate the prediction results</p>
<p>For each step above, we provide interface functions for you to override and make your own implementation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>batch_data</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict
The input batch data received from the <code>train</code> or <code>valid</code> dataloader object in the experimental
pipeline.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epoch</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int = None
The number of the current epoch. Used for real-time model visualization and model prediction.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The additional arguments for real-time model visualization. If given, the code will go through the model
visualization branch.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>In the training branch, the loss functions and evaluation metrics will be returned each of which is in the</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>form of a Dict.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>In the validation branch, only the evaluation metrics will be returned.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>In the visualization branch, the model snapshots on the given validation instance will be returned.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The general model forward function shared by all the _Model_ subclasses. This forward function has 3 steps:</span>
<span class="sd">        1. preprocess and transfer the batch data to GPUs</span>
<span class="sd">        2. obtain the model prediction results</span>
<span class="sd">        3. calculate the loss function and evaluate the prediction results</span>

<span class="sd">    For each step above, we provide interface functions for you to override and make your own implementation.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch_data: Dict</span>
<span class="sd">            The input batch data received from the `train` or `valid` dataloader object in the experimental</span>
<span class="sd">            pipeline.</span>
<span class="sd">        epoch: int = None</span>
<span class="sd">            The number of the current epoch. Used for real-time model visualization and model prediction.</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            The additional arguments for real-time model visualization. If given, the code will go through the model</span>
<span class="sd">            visualization branch.</span>

<span class="sd">    Returns:</span>
<span class="sd">        In the training branch, the loss functions and evaluation metrics will be returned each of which is in the</span>
<span class="sd">        form of a Dict.</span>
<span class="sd">        In the validation branch, only the evaluation metrics will be returned.</span>
<span class="sd">        In the visualization branch, the model snapshots on the given validation instance will be returned.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># --- 1. Batch Data Preprocessing and GPU transferring --- #</span>
    <span class="c1"># --- data preparation below is shared by all the three branches: training, validation, and visualization --- #</span>
    <span class="c1"># preprocess the batch data if needed</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_preprocess_fn</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>

    <span class="c1"># put the batch data onto GPUs</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_to_cuda</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>

    <span class="c1"># --- 2.1. Model Visualization Branch --- #</span>
    <span class="c1"># if there are additional arguments other than batch_data and epoch, the visualization branch is activated</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">visualize</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="o">**</span><span class="n">batch_data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># --- 2.2. Model Forward Calculation --- #</span>
    <span class="c1"># --- model forward is shared by both the training and validation branches --- #</span>
    <span class="c1"># context function used when doing the loss backward for efficient gradient accumulation in the DDP mode</span>
    <span class="n">forward_context</span> <span class="o">=</span> <span class="n">nullcontext</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span>
    <span class="k">with</span> <span class="n">forward_context</span><span class="p">():</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Feed the input batch into the model and get the outputs, copy.deepcopy() here is for the data safety</span>
            <span class="n">model_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_forward</span><span class="p">(</span>
                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="o">**</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">e</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">skip_flag_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span>
                    <span class="p">[</span><span class="kc">False</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">())]</span>
                <span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">skip_flag</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="kc">True</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="c1"># as long as one node meets an error, all nodes will skip the current step at the same time</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather_into_tensor</span><span class="p">(</span><span class="n">skip_flag_list</span><span class="p">,</span> <span class="n">skip_flag</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">skip_flag_list</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">e</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
                <span class="n">skip_flag_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span>
                    <span class="p">[</span><span class="kc">False</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">())]</span>
                <span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">skip_flag</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="kc">False</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="c1"># as long as one node meets an error, all nodes will skip the current step at the same time</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather_into_tensor</span><span class="p">(</span><span class="n">skip_flag_list</span><span class="p">,</span> <span class="n">skip_flag</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">skip_flag_list</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="s2">&quot;Other ranks meet errors during model forwarding, &quot;</span>
                        <span class="s2">&quot;so this rank will also skip the current step!&quot;</span>
                    <span class="p">)</span>

    <span class="c1"># copy.deepcopy() cannot receive the non-leaf nodes in the computation graph (model_outputs). Since</span>
    <span class="c1"># model_outputs cannot be detached from the graph (gradients necessary), copy.deepcopy() is not used below.</span>
    <span class="k">def</span> <span class="nf">combine_input_output</span><span class="p">(</span><span class="n">_batch_data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">_model_outputs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">):</span>
        <span class="n">combination</span><span class="p">,</span> <span class="n">batch_keys</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(),</span> <span class="nb">list</span><span class="p">(</span><span class="n">_batch_data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="c1"># if the input batch data is in the form of Dict, it means there are multiple dataloaders</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">_batch_data</span><span class="p">[</span><span class="n">batch_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">Dict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">batch_keys</span><span class="p">:</span>
                <span class="n">combination</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="o">**</span><span class="n">_batch_data</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="o">**</span><span class="n">_model_outputs</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
        <span class="c1"># if the input batch data is in the form of Tensor, it means there is only one dataloader.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">combination</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_batch_data</span><span class="p">)</span>
            <span class="n">combination</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">_model_outputs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">combination</span>

    <span class="c1"># --- 3.1. Model Training Branch --- #</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
        <span class="c1"># In the training stage, both the trainable losses and non-trainable metrics will be returned</span>
        <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span>
            <span class="o">**</span><span class="n">combine_input_output</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">model_outputs</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_recordable_para</span><span class="p">())</span>

        <span class="c1"># post-checking for training losses, they must be trainable tensors</span>
        <span class="k">assert</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">loss</span><span class="o">.</span><span class="n">requires_grad</span>
                <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">losses</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
            <span class="p">]</span>
        <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">),</span> <span class="s2">&quot;Training losses must be trainable tensors!&quot;</span>
        <span class="c1"># post-checking for validation metrics, they must be either non-trainable tensors or other datatypes</span>
        <span class="k">assert</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">metric</span><span class="o">.</span><span class="n">requires_grad</span>
                <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
            <span class="p">]</span>
        <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">metrics</span>
        <span class="p">),</span> <span class="s2">&quot;Validation metrics must be either non-trainable tensors or other datatypes!&quot;</span>

        <span class="c1"># the non-trainable metrics will be averaged across all the processes in the distributed mode</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aver_metrics_across_procs</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span>

    <span class="c1"># --- 3.2. Model Validation Branch --- #</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># In the validation stage, only the non-trainable metrics will be returned</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span>
                <span class="o">**</span><span class="n">combine_input_output</span><span class="p">(</span><span class="n">batch_data</span><span class="p">,</span> <span class="n">model_outputs</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_recordable_para</span><span class="p">())</span>

        <span class="c1"># post-checking for validation metrics, they must be either non-trainable tensors or other datatypes</span>
        <span class="k">assert</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">metric</span><span class="o">.</span><span class="n">requires_grad</span>
                <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
            <span class="p">]</span>
        <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
            <span class="n">metrics</span>
        <span class="p">),</span> <span class="s2">&quot;Validation metrics must be either non-trainable tensors or other datatypes!&quot;</span>

        <span class="c1"># the non-trainable metrics will be averaged across all the processes in the distributed mode</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aver_metrics_across_procs</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">batch_data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">metrics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.get_recordable_para" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_recordable_para</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Recursively retrieves the recordable parameters from the module's sub-
modules.</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict[str, torch.Tensor]: A dictionary mapping the parameter names to their corresponding tensor values.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_recordable_para</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Recursively retrieves the recordable parameters from the module&#39;s sub-</span>
<span class="sd">    modules.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict[str, torch.Tensor]: A dictionary mapping the parameter names to their corresponding tensor values.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">recur_get_module_recordable_para</span><span class="p">(</span><span class="n">curr_node</span><span class="p">,</span> <span class="n">prefix_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">prefix_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prefix_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">curr_node</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
            <span class="n">_output</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">_key</span><span class="p">,</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">curr_node</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">_output</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="n">recur_get_module_recordable_para</span><span class="p">(</span><span class="n">_value</span><span class="p">,</span> <span class="n">prefix_list</span> <span class="o">+</span> <span class="p">[</span><span class="n">_key</span><span class="p">])</span>
                <span class="p">)</span>
            <span class="k">return</span> <span class="n">_output</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">curr_node</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">{}</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">curr_node</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">prefix_list</span><span class="p">):</span> <span class="n">curr_node</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span>

    <span class="n">output</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Module</span><span class="p">):</span>
            <span class="n">output</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="n">recur_get_module_recordable_para</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">get_recordable_para</span><span class="p">(),</span> <span class="p">[</span><span class="n">key</span><span class="p">])</span>
            <span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.inference" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inference</span><span class="p">(</span><span class="n">infer_conf</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">

        <p>This function receives the test data and test configuration. The inference
results will be packaged into a Dict[str, Dict] which is passed to TestMonitor
for disk storage. The returned Dict should be in the form of ``` dict(
{file_name}=dict( format={file_format},</p>
<div class="language-text highlight"><pre><span></span><code>    content={file_content}
)
</code></pre></div>
<p>)
<code>``
The first-level key is used to decide the name of the meta file as</code>idx2{file_name}`. Its value is also a Dict
and there must be two keys in this sub-Dict: 'format' and 'content'. The configuration of the sub-Dict is
different for different file formats:</p>
<div class="language-text highlight"><pre><span></span><code>1. For pure text metadata files, the value of &#39;format&#39; must be &#39;txt&#39; and the value of &#39;content&#39; must be a
list of Python built-in data type (i.e.,. int, float, str, bool, ...).
Each line of the file `idx2{file_name}` will be made up of the index of a test data instance and its
metadata value in the `content` List which are separated by a blank.
For example,
`dict(cer=dict(format=&#39;txt&#39;, content=[0.1, 0.2, 0.3]))` will create a pure text file named &#39;idx2cer&#39; which
looks like
```
{test_index1} 0.1
{test_index2} 0.2
{test_index3} 0.3
```
Note: if the first-level key ends with &#39;.md&#39;, there will not be &#39;idx2&#39; attached at the beginning of the
file name.

2. For audio files, the value of &#39;format&#39; must be either &#39;wav&#39; or &#39;flac&#39; and the value of &#39;content&#39; must be
a list of array-like data type (e.g. numpy.ndarry, torch.Tensor, ...).
Moreover, there must be an additional key named &#39;sample_rate&#39; to indicate the sampling rate of the waveforms
to be saved in audio files.
There will be a folder named `{file_name}` that contains all the audio files and a pure text file named
`idx2{file_name}` that contains the absolute paths of all the saved audio files.
For example,
`dict(wav=dict(format=&#39;flac&#39;, content=[np_arr1, np_arr2, np_arr3]))` will create a folder named &#39;wav&#39; and
a pure text file named &#39;idx2wav&#39; in the same directory. The file &#39;idx2wav&#39; looks like:
```
{test_index1} /x/xx/wav/{test_index1}.flac
{test_index2} /x/xx/wav/{test_index2}.flac
{test_index3} /x/xx/wav/{test_index3}.flac
```
where `/x/xx/` is your result path given in your `exp_cfg`.

3. For binary files, the value of &#39;format&#39; in the sub-Dict must be &#39;npy&#39; and the value of &#39;content&#39; must be
a list of numpy.ndarry (torch.Tensor is not supported).
There will be a folder named `{file_name}` that contains all the .npy files and a pure text file
named `idx2{file_name}` that contains the absolute paths of all the saved binary files.
For example,
`dict(feat=dict(format=&#39;npy&#39;, content=[np_arr1, np_arr2, np_arr3]))`
will create a folder named &#39;feat&#39; and a pure text file named &#39;idx2feat&#39;. The &#39;idx2feat&#39; file is like:
```
{test_index1} /x/xx/feat/{test_index1}.npy
{test_index2} /x/xx/feat/{test_index2}.npy
{test_index3} /x/xx/feat/{test_index3}.npy
```
where `/x/xx/` is your result path given in your `exp_cfg`.
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span> <span class="nf">inference</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">infer_conf</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span> <span class="ow">or</span> <span class="n">List</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This function receives the test data and test configuration. The inference</span>
<span class="sd">    results will be packaged into a Dict[str, Dict] which is passed to TestMonitor</span>
<span class="sd">    for disk storage. The returned Dict should be in the form of ``` dict(</span>
<span class="sd">    {file_name}=dict( format={file_format},</span>

<span class="sd">            content={file_content}</span>
<span class="sd">        )</span>
<span class="sd">    )</span>
<span class="sd">    ```</span>
<span class="sd">    The first-level key is used to decide the name of the meta file as `idx2{file_name}`. Its value is also a Dict</span>
<span class="sd">    and there must be two keys in this sub-Dict: &#39;format&#39; and &#39;content&#39;. The configuration of the sub-Dict is</span>
<span class="sd">    different for different file formats:</span>

<span class="sd">        1. For pure text metadata files, the value of &#39;format&#39; must be &#39;txt&#39; and the value of &#39;content&#39; must be a</span>
<span class="sd">        list of Python built-in data type (i.e.,. int, float, str, bool, ...).</span>
<span class="sd">        Each line of the file `idx2{file_name}` will be made up of the index of a test data instance and its</span>
<span class="sd">        metadata value in the `content` List which are separated by a blank.</span>
<span class="sd">        For example,</span>
<span class="sd">        `dict(cer=dict(format=&#39;txt&#39;, content=[0.1, 0.2, 0.3]))` will create a pure text file named &#39;idx2cer&#39; which</span>
<span class="sd">        looks like</span>
<span class="sd">        ```</span>
<span class="sd">        {test_index1} 0.1</span>
<span class="sd">        {test_index2} 0.2</span>
<span class="sd">        {test_index3} 0.3</span>
<span class="sd">        ```</span>
<span class="sd">        Note: if the first-level key ends with &#39;.md&#39;, there will not be &#39;idx2&#39; attached at the beginning of the</span>
<span class="sd">        file name.</span>

<span class="sd">        2. For audio files, the value of &#39;format&#39; must be either &#39;wav&#39; or &#39;flac&#39; and the value of &#39;content&#39; must be</span>
<span class="sd">        a list of array-like data type (e.g. numpy.ndarry, torch.Tensor, ...).</span>
<span class="sd">        Moreover, there must be an additional key named &#39;sample_rate&#39; to indicate the sampling rate of the waveforms</span>
<span class="sd">        to be saved in audio files.</span>
<span class="sd">        There will be a folder named `{file_name}` that contains all the audio files and a pure text file named</span>
<span class="sd">        `idx2{file_name}` that contains the absolute paths of all the saved audio files.</span>
<span class="sd">        For example,</span>
<span class="sd">        `dict(wav=dict(format=&#39;flac&#39;, content=[np_arr1, np_arr2, np_arr3]))` will create a folder named &#39;wav&#39; and</span>
<span class="sd">        a pure text file named &#39;idx2wav&#39; in the same directory. The file &#39;idx2wav&#39; looks like:</span>
<span class="sd">        ```</span>
<span class="sd">        {test_index1} /x/xx/wav/{test_index1}.flac</span>
<span class="sd">        {test_index2} /x/xx/wav/{test_index2}.flac</span>
<span class="sd">        {test_index3} /x/xx/wav/{test_index3}.flac</span>
<span class="sd">        ```</span>
<span class="sd">        where `/x/xx/` is your result path given in your `exp_cfg`.</span>

<span class="sd">        3. For binary files, the value of &#39;format&#39; in the sub-Dict must be &#39;npy&#39; and the value of &#39;content&#39; must be</span>
<span class="sd">        a list of numpy.ndarry (torch.Tensor is not supported).</span>
<span class="sd">        There will be a folder named `{file_name}` that contains all the .npy files and a pure text file</span>
<span class="sd">        named `idx2{file_name}` that contains the absolute paths of all the saved binary files.</span>
<span class="sd">        For example,</span>
<span class="sd">        `dict(feat=dict(format=&#39;npy&#39;, content=[np_arr1, np_arr2, np_arr3]))`</span>
<span class="sd">        will create a folder named &#39;feat&#39; and a pure text file named &#39;idx2feat&#39;. The &#39;idx2feat&#39; file is like:</span>
<span class="sd">        ```</span>
<span class="sd">        {test_index1} /x/xx/feat/{test_index1}.npy</span>
<span class="sd">        {test_index2} /x/xx/feat/{test_index2}.npy</span>
<span class="sd">        {test_index3} /x/xx/feat/{test_index3}.npy</span>
<span class="sd">        ```</span>
<span class="sd">        where `/x/xx/` is your result path given in your `exp_cfg`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span>  <span class="c1"># raise NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.matrix_snapshot" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">matrix_snapshot</span><span class="p">(</span><span class="n">vis_logs</span><span class="p">,</span> <span class="n">hypo_attention</span><span class="p">,</span> <span class="n">subfolder_names</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Used by the abstract function visualize() to make the snapshot materials for
attention matrices.</p>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">matrix_snapshot</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">vis_logs</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span>
    <span class="n">hypo_attention</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">subfolder_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="ow">or</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Used by the abstract function visualize() to make the snapshot materials for</span>
<span class="sd">    attention matrices.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">subfolder_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">subfolder_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">subfolder_names</span><span class="p">]</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">hypo_attention</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="c1"># process the input data by different data types</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">Dict</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">hypo_attention</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">matrix_snapshot</span><span class="p">(</span>
                <span class="n">vis_logs</span><span class="o">=</span><span class="n">vis_logs</span><span class="p">,</span>
                <span class="n">hypo_attention</span><span class="o">=</span><span class="n">value</span><span class="p">,</span>
                <span class="n">subfolder_names</span><span class="o">=</span><span class="n">subfolder_names</span> <span class="o">+</span> <span class="p">[</span><span class="n">key</span><span class="p">],</span>
                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="c1"># snapshot the information in the materials</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hypo_attention</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">vis_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="nb">dict</span><span class="p">(</span>
                <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;matrix&quot;</span><span class="p">,</span>
                <span class="n">materials</span><span class="o">=</span><span class="n">hypo_attention</span><span class="p">,</span>
                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                <span class="n">sep_save</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">data_save</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">subfolder_names</span><span class="o">=</span><span class="n">subfolder_names</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.module_forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">module_forward</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">batch_data</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">

        <p>This function forwards the input batch data by all <em>Module</em> members.
Note:
    1. This interface function must be overridden for each Model subclass.
    2. The argument names should match the key names in the returned Dict of <code>self.batch_preprocess_fn()</code>.
    3. The key names in the returned Dict should match the argument names of <code>self.loss_calculation()</code> and
    <code>self.metrics_calculation()</code>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>epoch</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**batch_data</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Processed data of the input batch received from <code>self.batch_preprocess_fn()</code>.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Dict</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Prediction results (logits) of the model on the input batch data.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Some intermediate results (e.g., attention matrices) can also be returned for later use.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span> <span class="nf">module_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">batch_data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function forwards the input batch data by all _Module_ members.</span>
<span class="sd">    Note:</span>
<span class="sd">        1. This interface function must be overridden for each Model subclass.</span>
<span class="sd">        2. The argument names should match the key names in the returned Dict of `self.batch_preprocess_fn()`.</span>
<span class="sd">        3. The key names in the returned Dict should match the argument names of `self.loss_calculation()` and</span>
<span class="sd">        `self.metrics_calculation()`.</span>

<span class="sd">    Args:</span>
<span class="sd">        epoch:</span>
<span class="sd">        **batch_data:</span>
<span class="sd">            Processed data of the input batch received from `self.batch_preprocess_fn()`.</span>

<span class="sd">    Returns: Dict</span>
<span class="sd">        Prediction results (logits) of the model on the input batch data.</span>
<span class="sd">        Some intermediate results (e.g., attention matrices) can also be returned for later use.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span>  <span class="c1"># raise NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.module_init" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">module_init</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">

        <p>The interface function that initializes the Module members of the model.
These Module members make up the neural network structure of the model. Some
models have their customized part that also needs to be initialization in this
function, e.g. the tokenizer of ASR and TTS models.</p>
<p>Note: This interface function must be overridden for each Model subclass.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The combination of the arguments in your given <code>module_conf</code> and <code>model_conf['customize_conf']</code>.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span> <span class="nf">module_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The interface function that initializes the Module members of the model.</span>
<span class="sd">    These Module members make up the neural network structure of the model. Some</span>
<span class="sd">    models have their customized part that also needs to be initialization in this</span>
<span class="sd">    function, e.g. the tokenizer of ASR and TTS models.</span>

<span class="sd">    Note: This interface function must be overridden for each Model subclass.</span>

<span class="sd">    Args:</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            The combination of the arguments in your given `module_conf` and `model_conf[&#39;customize_conf&#39;]`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span>  <span class="c1"># raise NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.register_instance_reports" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">register_instance_reports</span><span class="p">(</span><span class="n">md_list_dict</span><span class="p">,</span> <span class="n">extra_string_list</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>md_list_dict</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="typing.List">List</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>extra_string_list</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Returns:</p>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">register_instance_reports</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">md_list_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">],</span> <span class="n">extra_string_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        md_list_dict:</span>
<span class="sd">        extra_string_list:</span>

<span class="sd">    Returns:</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># --- 1. Arguments Checking --- #</span>
    <span class="k">if</span> <span class="n">extra_string_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">extra_string_list</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span>

    <span class="n">ele_len</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">md_list_dict</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">extra_string_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">extra_string_list</span><span class="p">)</span>
        <span class="n">ele_len</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">ele_len</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">ele_len</span> <span class="o">=</span> <span class="n">ele_len</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span>

    <span class="c1"># --- 2. Generate .md Instance Report for the current step --- #</span>
    <span class="n">instance_reports</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ele_len</span><span class="p">):</span>
        <span class="n">ele_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">md_list_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="n">_curr_report</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">get_list_strings</span><span class="p">(</span><span class="n">ele_dict</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="n">extra_string_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_curr_report</span> <span class="o">+=</span> <span class="n">extra_string_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">instance_reports</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_curr_report</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">instance_report_cache</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">instance_reports</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.abs.Model.visualize" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">visualize</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">sample_index</span><span class="p">,</span> <span class="o">**</span><span class="n">valid_sample</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-abstractmethod"><code>abstractmethod</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>epoch</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sample_index</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**valid_sample</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Returns:</p>

            <details class="quote">
              <summary>Source code in <code>speechain/model/abs.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@abstractmethod</span>
<span class="k">def</span> <span class="nf">visualize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">sample_index</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">**</span><span class="n">valid_sample</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        epoch:</span>
<span class="sd">        sample_index:</span>
<span class="sd">        **valid_sample:</span>

<span class="sd">    Returns:</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span>  <span class="c1"># raise NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.88dd0f4e.min.js"></script>
      
    
  </body>
</html>