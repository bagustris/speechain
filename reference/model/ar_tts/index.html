
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Documentation for Speechain Toolkit">
      
      
      
      
        <link rel="prev" href="../ar_asr/">
      
      
        <link rel="next" href="../lm/">
      
      
      <link rel="icon" href="../../../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.48">
    
    
      
        <title>ar_tts - Speechain</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../css/code_select.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#model.ar_tts" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Speechain" class="md-header__button md-logo" aria-label="Speechain" data-md-component="logo">
      
  <img src="../../../img/speechain_inverted.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Speechain
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ar_tts
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/bagustris/speechain" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Speechain" class="md-nav__button md-logo" aria-label="Speechain" data-md-component="logo">
      
  <img src="../../../img/speechain_inverted.png" alt="logo">

    </a>
    Speechain
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/bagustris/speechain" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../recipes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recipes
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ASR
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TTS
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../handbook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Handbook
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../criterion/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    criterion
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_1" id="__nav_7_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_1">
            <span class="md-nav__icon md-icon"></span>
            criterion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/accuracy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    accuracy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/att_guid/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    att_guid
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/bce_logits/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bce_logits
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/cross_entropy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cross_entropy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/ctc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctc
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/error_rate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    error_rate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/fbeta_score/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    fbeta_score
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/least_error/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    least_error
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/perplexity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    perplexity
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../dataset/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    dataset
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_2">
            <span class="md-nav__icon md-icon"></span>
            dataset
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/speech_text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_text
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../infer_func/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    infer_func
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_3" id="__nav_7_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_3">
            <span class="md-nav__icon md-icon"></span>
            infer_func
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../infer_func/beam_search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam_search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../infer_func/ctc_decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctc_decoding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../infer_func/tts_decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tts_decoding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../iterator/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    iterator
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_4" id="__nav_7_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_4">
            <span class="md-nav__icon md-icon"></span>
            iterator
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../iterator/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../iterator/block/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    block
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_5" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    model
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_5" id="__nav_7_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7_5">
            <span class="md-nav__icon md-icon"></span>
            model
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ar_asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    ar_tts
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    ar_tts
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#model.ar_tts" class="md-nav__link">
    <span class="md-ellipsis">
      ar_tts
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model.ar_tts.ARTTS" class="md-nav__link">
    <span class="md-ellipsis">
      ARTTS
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ARTTS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.ARTTS.criterion_forward" class="md-nav__link">
    <span class="md-ellipsis">
      criterion_forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.ARTTS.criterion_init" class="md-nav__link">
    <span class="md-ellipsis">
      criterion_init
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.ARTTS.inference" class="md-nav__link">
    <span class="md-ellipsis">
      inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.ARTTS.module_forward" class="md-nav__link">
    <span class="md-ellipsis">
      module_forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.ARTTS.module_init" class="md-nav__link">
    <span class="md-ellipsis">
      module_init
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model.ar_tts.MultiDomainARTTS" class="md-nav__link">
    <span class="md-ellipsis">
      MultiDomainARTTS
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MultiDomainARTTS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.MultiDomainARTTS.criterion_forward" class="md-nav__link">
    <span class="md-ellipsis">
      criterion_forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.MultiDomainARTTS.inference" class="md-nav__link">
    <span class="md-ellipsis">
      inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.MultiDomainARTTS.module_forward" class="md-nav__link">
    <span class="md-ellipsis">
      module_forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    lm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nar_tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    module
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6" id="__nav_7_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6">
            <span class="md-nav__icon md-icon"></span>
            module
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/augment/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    augment
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_2" id="__nav_7_6_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_2">
            <span class="md-nav__icon md-icon"></span>
            augment
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/augment/specaug/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    specaug
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/conformer/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    conformer
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_3" id="__nav_7_6_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_3">
            <span class="md-nav__icon md-icon"></span>
            conformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/conformer/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/conformer/encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/conformer/pos_enc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pos_enc
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/decoder/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    decoder
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_4" id="__nav_7_6_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_4">
            <span class="md-nav__icon md-icon"></span>
            decoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/decoder/ar_asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/decoder/ar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_tts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/decoder/nar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nar_tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/encoder/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    encoder
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_5" id="__nav_7_6_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_5">
            <span class="md-nav__icon md-icon"></span>
            encoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/frontend/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    frontend
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_6" id="__nav_7_6_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_6">
            <span class="md-nav__icon md-icon"></span>
            frontend
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/delta_feat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    delta_feat
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/linear2mel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear2mel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/speech2linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech2linear
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/speech2mel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech2mel
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/norm/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    norm
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_7" id="__nav_7_6_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_7">
            <span class="md-nav__icon md-icon"></span>
            norm
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/norm/feat_norm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feat_norm
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/postnet/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    postnet
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_8" id="__nav_7_6_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_8">
            <span class="md-nav__icon md-icon"></span>
            postnet
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/postnet/conv1d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv1d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/postnet/token/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    token
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_9" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/prenet/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    prenet
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_9" id="__nav_7_6_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_9">
            <span class="md-nav__icon md-icon"></span>
            prenet
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/conv1d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv1d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/conv2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv2d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/embed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    embed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/spk_embed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    spk_embed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/var_pred/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    var_pred
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_10" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/standalone/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    standalone
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_10" id="__nav_7_6_10_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_10">
            <span class="md-nav__icon md-icon"></span>
            standalone
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/standalone/lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    lm
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_11" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/transformer/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    transformer
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_11" id="__nav_7_6_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_11">
            <span class="md-nav__icon md-icon"></span>
            transformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    decoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/feed_forward/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feed_forward
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/pos_enc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pos_enc
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../monitor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    monitor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../optim_sche/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    optim_sche
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_8" id="__nav_7_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_8">
            <span class="md-nav__icon md-icon"></span>
            optim_sche
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optim_sche/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optim_sche/exp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    exp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optim_sche/noam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    noam
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_9" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../pyscripts/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    pyscripts
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_9" id="__nav_7_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_9">
            <span class="md-nav__icon md-icon"></span>
            pyscripts
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/empty_file_checker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    empty_file_checker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/folder_summarizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    folder_summarizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/model_para_renamer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    model_para_renamer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/phn_duaration_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phn_duaration_visualizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/text_dist_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_dist_visualizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/wavlen_dist_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wavlen_dist_visualizer
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../runner/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    runner
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../snapshooter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    snapshooter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_12" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../tokenizer/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    tokenizer
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_12" id="__nav_7_12_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_12">
            <span class="md-nav__icon md-icon"></span>
            tokenizer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/char/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    char
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/g2p/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    g2p
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/sp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sp
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_13" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../utilbox/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    utilbox
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_13" id="__nav_7_13_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_13">
            <span class="md-nav__icon md-icon"></span>
            utilbox
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/data_loading_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_loading_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/data_saving_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_saving_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/dump_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    dump_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/eval_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    eval_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/feat_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feat_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/humanfriendly/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    humanfriendly
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/import_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    import_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/log_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    log_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/md_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    md_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/regex_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    regex_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/sb_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sb_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/spk_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    spk_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/tensor_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tensor_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/test_humanfriendly/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    test_humanfriendly
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/text_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/train_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    train_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/type_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    type_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/yaml_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    yaml_util
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#model.ar_tts" class="md-nav__link">
    <span class="md-ellipsis">
      ar_tts
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model.ar_tts.ARTTS" class="md-nav__link">
    <span class="md-ellipsis">
      ARTTS
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ARTTS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.ARTTS.criterion_forward" class="md-nav__link">
    <span class="md-ellipsis">
      criterion_forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.ARTTS.criterion_init" class="md-nav__link">
    <span class="md-ellipsis">
      criterion_init
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.ARTTS.inference" class="md-nav__link">
    <span class="md-ellipsis">
      inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.ARTTS.module_forward" class="md-nav__link">
    <span class="md-ellipsis">
      module_forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.ARTTS.module_init" class="md-nav__link">
    <span class="md-ellipsis">
      module_init
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model.ar_tts.MultiDomainARTTS" class="md-nav__link">
    <span class="md-ellipsis">
      MultiDomainARTTS
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MultiDomainARTTS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.MultiDomainARTTS.criterion_forward" class="md-nav__link">
    <span class="md-ellipsis">
      criterion_forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.MultiDomainARTTS.inference" class="md-nav__link">
    <span class="md-ellipsis">
      inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_tts.MultiDomainARTTS.module_forward" class="md-nav__link">
    <span class="md-ellipsis">
      module_forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>ar_tts</h1>

<div class="doc doc-object doc-module">



<a id="model.ar_tts"></a>
    <div class="doc doc-contents first">

        <p>Author: Sashi Novitasari
Affiliation: NAIST
Date: 2022.08</p>
<p>Author: Heli Qi
Affiliation: NAIST
Date: 2022.09</p>








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="model.ar_tts.ARTTS" class="doc doc-heading">
            <code>ARTTS</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="speechain.model.abs.Model">Model</span></code></p>


        <p>Auto-Regressive Attention-based Text-To-Speech Synthesis Model. (single-speaker or multi-speaker)</p>






              <details class="quote">
                <summary>Source code in <code>speechain/model/ar_tts.py</code></summary>
                <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span>
<span class="normal">931</span>
<span class="normal">932</span>
<span class="normal">933</span>
<span class="normal">934</span>
<span class="normal">935</span>
<span class="normal">936</span>
<span class="normal">937</span>
<span class="normal">938</span>
<span class="normal">939</span>
<span class="normal">940</span>
<span class="normal">941</span>
<span class="normal">942</span>
<span class="normal">943</span>
<span class="normal">944</span>
<span class="normal">945</span>
<span class="normal">946</span>
<span class="normal">947</span>
<span class="normal">948</span>
<span class="normal">949</span>
<span class="normal">950</span>
<span class="normal">951</span>
<span class="normal">952</span>
<span class="normal">953</span>
<span class="normal">954</span>
<span class="normal">955</span>
<span class="normal">956</span>
<span class="normal">957</span>
<span class="normal">958</span>
<span class="normal">959</span>
<span class="normal">960</span>
<span class="normal">961</span>
<span class="normal">962</span>
<span class="normal">963</span>
<span class="normal">964</span>
<span class="normal">965</span>
<span class="normal">966</span>
<span class="normal">967</span>
<span class="normal">968</span>
<span class="normal">969</span>
<span class="normal">970</span>
<span class="normal">971</span>
<span class="normal">972</span>
<span class="normal">973</span>
<span class="normal">974</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ARTTS</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Auto-Regressive Attention-based Text-To-Speech Synthesis Model. (single-speaker or multi-speaker)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">module_init</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">token_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">token_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">enc_emb</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">enc_prenet</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">encoder</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">dec_prenet</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">decoder</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">dec_postnet</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">frontend</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">normalize</span><span class="p">:</span> <span class="n">Dict</span> <span class="ow">or</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">spk_list</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">spk_emb</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">22050</span><span class="p">,</span>
        <span class="n">audio_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;wav&quot;</span><span class="p">,</span>
        <span class="n">reduction_factor</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">stop_pos_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5.0</span><span class="p">,</span>
        <span class="n">stop_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">return_att_type</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="ow">or</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_att_head_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">return_att_layer_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            # --- module_conf arguments --- #</span>
<span class="sd">            frontend: Dict (mandatory)</span>
<span class="sd">                The configuration of the acoustic feature extraction frontend in the `ARTTSDecoder` member.</span>
<span class="sd">                This argument must be given since our toolkit doesn&#39;t support time-domain TTS.</span>
<span class="sd">                For more details about how to give `frontend`, please refer to speechain.module.encoder.ar_tts.ARTTSDecoder.</span>
<span class="sd">            normalize: Dict</span>
<span class="sd">                The configuration of the normalization layer in the `ARTTSDecoder` member.</span>
<span class="sd">                This argument can also be given as a bool value.</span>
<span class="sd">                True means the default configuration and False means no normalization.</span>
<span class="sd">                For more details about how to give `normalize`, please refer to</span>
<span class="sd">                    speechain.module.norm.feat_norm.FeatureNormalization.</span>
<span class="sd">            enc_emb: Dict (mandatory)</span>
<span class="sd">                The configuration of the embedding layer in the `TTSEncoder` member.</span>
<span class="sd">                The encoder prenet embeds the input token id into token embeddings before feeding them into</span>
<span class="sd">                the encoder.</span>
<span class="sd">                For more details about how to give `enc_emb`, please refer to speechain.module.encoder.tts.TTSEncoder.</span>
<span class="sd">            enc_prenet: Dict (mandatory)</span>
<span class="sd">                The configuration of the prenet in the `TTSEncoder` member.</span>
<span class="sd">                The encoder prenet embeds the input token embeddings into high-level embeddings before feeding them into</span>
<span class="sd">                the encoder.</span>
<span class="sd">                For more details about how to give `enc_prent`, please refer to speechain.module.encoder.tts.TTSEncoder.</span>
<span class="sd">            encoder: Dict (mandatory)</span>
<span class="sd">                The configuration of the encoder main body in the `TTSEncoder` member.</span>
<span class="sd">                The encoder embeds the input embeddings into the encoder representations at each time steps of the</span>
<span class="sd">                input acoustic features.</span>
<span class="sd">                For more details about how to give `encoder`, please refer to speechain.module.encoder.tts.TTSEncoder.</span>
<span class="sd">            spk_emb: Dict = None (conditionally mandatory)</span>
<span class="sd">                The configuration for the `SPKEmbedPrenet` in the `ARTTSDecoder` member.</span>
<span class="sd">                For more details about how to give `spk_emb`, please refer to</span>
<span class="sd">                    speechain.module.prenet.spk_embed.SpeakerEmbedPrenet.</span>
<span class="sd">            dec_prenet: Dict (mandatory)</span>
<span class="sd">                The configuration of the prenet in the `ARTTSDecoder` member.</span>
<span class="sd">                For more details about how to give `dec_prenet`, please refer to speechain.module.encoder.ar_tts.ARTTSDecoder.</span>
<span class="sd">            decoder: Dict (mandatory)</span>
<span class="sd">                The configuration of the decoder main body in the `ARTTSDecoder` member.</span>
<span class="sd">                For more details about how to give `decoder`, please refer to speechain.module.decoder.ar_tts.ARTTSDecoder.</span>
<span class="sd">            dec_postnet: Dict (mandatory)</span>
<span class="sd">                The configuration of the postnet in the `ARTTSDecoder` member.</span>
<span class="sd">                For more details about how to give `dec_postnet`, please refer to speechain.module.encoder.ar_tts.ARTTSDecoder.</span>
<span class="sd">            # --- customize_conf arguments --- #</span>
<span class="sd">            token_type: (mandatory)</span>
<span class="sd">                The type of the built-in tokenizer.</span>
<span class="sd">                Currently, we support &#39;char&#39; for `CharTokenizer` and &#39;phn&#39; for `PhonemeTokenizer`.</span>
<span class="sd">            token_path: (mandatory)</span>
<span class="sd">                The path of the vocabulary list `vocab` for initializing the built-in tokenizer.</span>
<span class="sd">            spk_list: str = None (conditionally mandatory)</span>
<span class="sd">                The path of the speaker list that contains all the speaker ids in your training set.</span>
<span class="sd">                If you would like to train a close-set multi-speaker TTS, you need to give a spk_list.</span>
<span class="sd">            sample_rate: int = 22050 (optional)</span>
<span class="sd">                The sampling rate of the target speech.</span>
<span class="sd">                Currently it&#39;s used for acoustic feature extraction frontend initialization and tensorboard register of</span>
<span class="sd">                the input speech during model visualization.</span>
<span class="sd">                In the future, this argument will also be used to dynamically downsample the input speech during training.</span>
<span class="sd">            audio_format: str = &#39;wav&#39; (optional)</span>
<span class="sd">                This argument is only used for input speech recording during model visualization.</span>
<span class="sd">            reduction_factor: int = 1 (mandatory)</span>
<span class="sd">                The factor that controls how much the length of output speech feature is reduced.</span>
<span class="sd">            stop_threshold: float = 0.5 (mandatory)</span>
<span class="sd">                The threshold that controls whether the speech synthesis stops or not.</span>
<span class="sd">            return_att_type: List[str] or str = &#39;encdec&#39;</span>
<span class="sd">                The type of attentions you want to return for both attention guidance and attention visualization.</span>
<span class="sd">                It can be given as a string (one type) or a list of strings (multiple types).</span>
<span class="sd">                The type should be one of</span>
<span class="sd">                    1. &#39;encdec&#39;: the encoder-decoder attention, shared by both Transformer and RNN</span>
<span class="sd">                    2. &#39;enc&#39;: the encoder self-attention, only for Transformer</span>
<span class="sd">                    3. &#39;dec&#39;: the decoder self-attention, only for Transformer</span>
<span class="sd">            return_att_head_num: int = -1</span>
<span class="sd">                The number of returned attention heads. If -1, all the heads in an attention layer will be returned.</span>
<span class="sd">                RNN can be considered to one-head attention, so return_att_head_num &gt; 1 is equivalent to 1 for RNN.</span>
<span class="sd">            return_att_layer_num: int = 1</span>
<span class="sd">                The number of returned attention layers. If -1, all the attention layers will be returned.</span>
<span class="sd">                RNN can be considered to one-layer attention, so return_att_layer_num &gt; 1 is equivalent to 1 for RNN.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># --- 1. Model-Customized Part Initialization --- #</span>
        <span class="c1"># initialize the tokenizer</span>
        <span class="k">if</span> <span class="n">token_type</span> <span class="o">==</span> <span class="s2">&quot;char&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">CharTokenizer</span><span class="p">(</span><span class="n">token_path</span><span class="p">,</span> <span class="n">copy_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">token_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;g2p&quot;</span><span class="p">,</span> <span class="s2">&quot;mfa&quot;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GraphemeToPhonemeTokenizer</span><span class="p">(</span>
                <span class="n">token_path</span><span class="p">,</span> <span class="n">copy_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unknown token type </span><span class="si">{</span><span class="n">token_type</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Currently, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> supports one of [&#39;char&#39;, &#39;g2p&#39;].&quot;</span>
            <span class="p">)</span>

        <span class="c1"># initialize the speaker list if given</span>
        <span class="k">if</span> <span class="n">spk_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">spk_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">parse_path_args</span><span class="p">(</span><span class="n">spk_list</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
            <span class="c1"># when the input file is idx2spk, only retain the column of speaker ids</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">spk_list</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">spk_list</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
                <span class="n">spk_list</span> <span class="o">=</span> <span class="n">spk_list</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="c1"># otherwise, the input file must be spk_list which is a single-column file and each row is a speaker id</span>
            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">spk_list</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span>
            <span class="c1"># 1. remove redundant elements; 2. sort up the speaker ids in order</span>
            <span class="n">spk_list</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">spk_list</span><span class="p">))</span>
            <span class="c1"># 3. get the corresponding indices (start from 1 since 0 is reserved for unknown speakers)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">idx2spk</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">spk_list</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">spk_list</span><span class="p">))</span>
            <span class="c1"># 4. exchange the positions of indices and speaker ids</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">spk2idx</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">reversed</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx2spk</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>

        <span class="c1"># initialize the sampling rate, mainly used for visualizing the input audio during training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">audio_format</span> <span class="o">=</span> <span class="n">audio_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">=</span> <span class="n">reduction_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_pos_weight</span> <span class="o">=</span> <span class="n">stop_pos_weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_threshold</span> <span class="o">=</span> <span class="n">stop_threshold</span>

        <span class="k">if</span> <span class="n">return_att_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;encdec&quot;</span><span class="p">,</span> <span class="s2">&quot;enc&quot;</span><span class="p">,</span> <span class="s2">&quot;dec&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">return_att_type</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">return_att_type</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span>
                <span class="k">else</span> <span class="p">[</span><span class="n">return_att_type</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">)):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;enc&quot;</span><span class="p">,</span> <span class="s2">&quot;dec&quot;</span><span class="p">,</span> <span class="s2">&quot;encdec&quot;</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;The elements of your input return_att_type must be one of [&#39;enc&#39;, &#39;dec&#39;, &#39;encdec&#39;], &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">!&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span> <span class="o">=</span> <span class="n">return_att_head_num</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span> <span class="o">=</span> <span class="n">return_att_layer_num</span>

        <span class="c1"># --- 2. Module Part Construction --- #</span>
        <span class="c1"># --- 2.1. Encoder construction --- #</span>
        <span class="c1"># the vocabulary size is given by the built-in tokenizer instead of the input configuration</span>
        <span class="k">if</span> <span class="s2">&quot;vocab_size&quot;</span> <span class="ow">in</span> <span class="n">enc_emb</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">enc_emb</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">][</span><span class="s2">&quot;vocab_size&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Your input vocabulary size is different from the one obtained from the built-in &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;tokenizer (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2">). The latter one will be used to initialize the &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;encoder for correctness.&quot;</span>
                <span class="p">)</span>
            <span class="n">enc_emb</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;vocab_size&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">TTSEncoder</span><span class="p">(</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
            <span class="n">embedding</span><span class="o">=</span><span class="n">enc_emb</span><span class="p">,</span>
            <span class="n">prenet</span><span class="o">=</span><span class="n">enc_prenet</span><span class="p">,</span>
            <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># --- 2.2. Decoder construction --- #</span>
        <span class="c1"># check the sampling rate of the decoder frontend</span>
        <span class="k">if</span> <span class="s2">&quot;sr&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">frontend</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">frontend</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">][</span><span class="s2">&quot;sr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span>
        <span class="c1"># update the sampling rate into the TTS Model object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">frontend</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">][</span><span class="s2">&quot;sr&quot;</span><span class="p">]</span>

        <span class="c1"># check the speaker embedding configuration</span>
        <span class="k">if</span> <span class="n">spk_emb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># speaker number for the close-set multi-speaker TTS</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;spk2idx&quot;</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span>
                    <span class="s2">&quot;spk_num&quot;</span> <span class="ow">in</span> <span class="n">spk_emb</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                    <span class="ow">and</span> <span class="n">spk_emb</span><span class="p">[</span><span class="s2">&quot;spk_num&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spk2idx</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="p">):</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                        <span class="s2">&quot;Your input spk_num is different from the number of speakers in your given spk_list. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;Currently, the spk_num is set to </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spk2idx</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>
                <span class="c1"># all seen speakers plus an unknown speaker (ID: 0)</span>
                <span class="n">spk_emb</span><span class="p">[</span><span class="s2">&quot;spk_num&quot;</span><span class="p">],</span> <span class="n">spk_emb</span><span class="p">[</span><span class="s2">&quot;use_lookup&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spk2idx</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="s2">&quot;use_lookup&quot;</span> <span class="ow">in</span> <span class="n">spk_emb</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">spk_emb</span><span class="p">[</span><span class="s2">&quot;use_lookup&quot;</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Please give spk_list in model[&#39;customize_conf&#39;] if you want to use speaker lookup &quot;</span>
                    <span class="s2">&quot;table for close-set multi-speaker TTS.&quot;</span>
                <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">ARTTSDecoder</span><span class="p">(</span>
            <span class="n">spk_emb</span><span class="o">=</span><span class="n">spk_emb</span><span class="p">,</span>
            <span class="n">frontend</span><span class="o">=</span><span class="n">frontend</span><span class="p">,</span>
            <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span>
            <span class="n">prenet</span><span class="o">=</span><span class="n">dec_prenet</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
            <span class="n">postnet</span><span class="o">=</span><span class="n">dec_postnet</span><span class="p">,</span>
            <span class="n">distributed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span>
            <span class="n">reduction_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">bad_cases_selection_init_fn</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span> <span class="ow">or</span> <span class="nb">int</span><span class="p">]]</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="p">[</span><span class="s2">&quot;feat_token_len_ratio&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
            <span class="p">[</span><span class="s2">&quot;feat_token_len_ratio&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
            <span class="p">[</span><span class="s2">&quot;feat_len&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
            <span class="p">[</span><span class="s2">&quot;feat_len&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">criterion_init</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">feat_loss</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">att_guid_loss</span><span class="p">:</span> <span class="n">Dict</span> <span class="ow">or</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function initializes all the necessary Criterion members for an autoregressive TTS:</span>
<span class="sd">            1. `speechain.criterion.least_error.LeastError` for acoustic feature prediction loss calculation.</span>
<span class="sd">            2. `speechain.criterion.bce_logits.BCELogits` for stop flag prediction loss calculation.</span>
<span class="sd">            3. `speechain.criterion.accuracy.Accuracy` for teacher-forcing stop flag prediction accuracy calculation.</span>
<span class="sd">            4. `speechain.criterion.fbeta_score.FBetaScore` for teacher-forcing stop flag prediction f-score calculation.</span>

<span class="sd">        Args:</span>
<span class="sd">            feat_loss: Dict[str, Any]</span>
<span class="sd">                The arguments for LeastError(). If not given, the default setting of LeastError() will be used.</span>
<span class="sd">                Please refer to speechain.criterion.least_error.LeastError for more details.</span>
<span class="sd">            att_guid_loss: Dict[str, Any] or bool</span>
<span class="sd">                The arguments for AttentionGuidance(). If not given, self.att_guid_loss won&#39;t be initialized.</span>
<span class="sd">                This argument can also be set to a bool value &#39;True&#39;. If True, the default setting of AttentionGuidance()</span>
<span class="sd">                will be used.</span>
<span class="sd">                Please refer to speechain.criterion.att_guid.AttentionGuidance for more details.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># --- Criterion Part Initialization --- #</span>
        <span class="c1"># feature prediction loss</span>
        <span class="k">if</span> <span class="n">feat_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">feat_loss</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feat_loss</span> <span class="o">=</span> <span class="n">LeastError</span><span class="p">(</span><span class="o">**</span><span class="n">feat_loss</span><span class="p">)</span>

        <span class="c1"># synthesis stop loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_loss</span> <span class="o">=</span> <span class="n">BCELogits</span><span class="p">(</span><span class="n">pos_weight</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stop_pos_weight</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">att_guid_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># if att_guid_loss is given as True, the default arguments of AttentionGuidance will be used</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="n">att_guid_loss</span>
                <span class="p">),</span> <span class="s2">&quot;If you want to use the default setting of AttentionGuidance, please give att_guid_loss as True.&quot;</span>
                <span class="n">att_guid_loss</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="k">assert</span> <span class="p">(</span>
                <span class="s2">&quot;encdec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span>
            <span class="p">),</span> <span class="s2">&quot;If you want to enable attention guidance for ASR training, please include &#39;encdec&#39; in return_att_type.&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span> <span class="o">=</span> <span class="n">AttentionGuidance</span><span class="p">(</span><span class="o">**</span><span class="n">att_guid_loss</span><span class="p">)</span>

        <span class="c1"># validation metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_accuracy</span> <span class="o">=</span> <span class="n">Accuracy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_fbeta</span> <span class="o">=</span> <span class="n">FBetaScore</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">module_forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">text_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">spk_feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">spk_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_att</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            feat: (batch, feat_maxlen, feat_dim)</span>
<span class="sd">                The input speech data (grouped or downsampled and edge-padded).</span>
<span class="sd">            feat_len: (batch,)</span>
<span class="sd">                The lengths of input speech data</span>
<span class="sd">            text: (batch, text_maxlen)</span>
<span class="sd">                The input text data with &lt;sos/eos&gt; at the beginning and end</span>
<span class="sd">            text_len: (batch,)</span>
<span class="sd">                The lengths of input text data</span>
<span class="sd">            spk_feat: (batch, 1, speaker embedding dim)</span>
<span class="sd">                Pre-extracted speaker embedding. (None means single-speaker TTS)</span>
<span class="sd">            spk_ids: (batch,)</span>
<span class="sd">                The speaker ids of each speech data. In the form of integer values.</span>
<span class="sd">            epoch: int</span>
<span class="sd">                The number of the current training epoch.</span>
<span class="sd">                Mainly used for mean&amp;std calculation in the feature normalization</span>
<span class="sd">            return_att: bool</span>
<span class="sd">                Controls whether the attention matrices of each layer in the encoder and decoder will be returned.</span>
<span class="sd">            kwargs:</span>
<span class="sd">                Temporary register used to store the redundant arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A dictionary containing all the TTS model outputs (feature, eos bernouli prediction) necessary to calculate the losses</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># para checking</span>
        <span class="k">assert</span> <span class="n">text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">text_len</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">assert</span> <span class="n">feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">text</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="n">feat_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">text_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span>
            <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;The amounts of utterances and sentences are not equal to each other.&quot;</span>
        <span class="k">assert</span> <span class="n">feat_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span>
            <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;The amounts of utterances and their lengths are not equal to each other.&quot;</span>
        <span class="k">assert</span> <span class="n">text_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">text</span><span class="o">.</span><span class="n">size</span><span class="p">(</span>
            <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;The amounts of sentences and their lengths are not equal to each other.&quot;</span>

        <span class="c1"># Encoding, we don&#39;t remove the &lt;sos/eos&gt; at the beginning and end of the sentence</span>
        <span class="n">enc_returns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">)</span>
        <span class="c1"># Transformer-based encoder additionally returns the encoder self-attention</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">enc_text</span><span class="p">,</span> <span class="n">enc_text_mask</span><span class="p">,</span> <span class="n">enc_attmat</span><span class="p">,</span> <span class="n">enc_hidden</span> <span class="o">=</span> <span class="n">enc_returns</span>
        <span class="c1"># RNN-based encoder doesn&#39;t return any attention</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="p">(</span><span class="n">enc_text</span><span class="p">,</span> <span class="n">enc_text_mask</span><span class="p">,</span> <span class="n">enc_hidden</span><span class="p">),</span> <span class="n">enc_attmat</span> <span class="o">=</span> <span class="n">enc_returns</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span>

        <span class="c1"># Decoding</span>
        <span class="n">dec_returns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
            <span class="n">enc_text</span><span class="o">=</span><span class="n">enc_text</span><span class="p">,</span>
            <span class="n">enc_text_mask</span><span class="o">=</span><span class="n">enc_text_mask</span><span class="p">,</span>
            <span class="n">feat</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span>
            <span class="n">feat_len</span><span class="o">=</span><span class="n">feat_len</span><span class="p">,</span>
            <span class="n">spk_feat</span><span class="o">=</span><span class="n">spk_feat</span><span class="p">,</span>
            <span class="n">spk_ids</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">,</span>
            <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Transformer-based decoder additionally returns the decoder self-attention</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dec_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
            <span class="p">(</span>
                <span class="n">pred_stop</span><span class="p">,</span>
                <span class="n">pred_feat_before</span><span class="p">,</span>
                <span class="n">pred_feat_after</span><span class="p">,</span>
                <span class="n">tgt_feat</span><span class="p">,</span>
                <span class="n">tgt_feat_len</span><span class="p">,</span>
                <span class="n">dec_attmat</span><span class="p">,</span>
                <span class="n">encdec_attmat</span><span class="p">,</span>
                <span class="n">dec_hidden</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">=</span> <span class="n">dec_returns</span>
        <span class="c1"># RNN-based decoder only returns the encoder-decoder attention</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">dec_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
            <span class="p">(</span>
                <span class="n">pred_stop</span><span class="p">,</span>
                <span class="n">pred_feat_before</span><span class="p">,</span>
                <span class="n">pred_feat_after</span><span class="p">,</span>
                <span class="n">tgt_feat</span><span class="p">,</span>
                <span class="n">tgt_feat_len</span><span class="p">,</span>
                <span class="n">encdec_attmat</span><span class="p">,</span>
                <span class="n">dec_hidden</span><span class="p">,</span>
            <span class="p">),</span> <span class="n">dec_attmat</span> <span class="o">=</span> <span class="p">(</span><span class="n">dec_returns</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span>

        <span class="c1"># initialize the TTS output to be the decoder predictions</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">pred_feat_before</span><span class="o">=</span><span class="n">pred_feat_before</span><span class="p">,</span>
            <span class="n">pred_feat_after</span><span class="o">=</span><span class="n">pred_feat_after</span><span class="p">,</span>
            <span class="n">pred_stop</span><span class="o">=</span><span class="n">pred_stop</span><span class="p">,</span>
            <span class="n">tgt_feat</span><span class="o">=</span><span class="n">tgt_feat</span><span class="p">,</span>
            <span class="n">tgt_feat_len</span><span class="o">=</span><span class="n">tgt_feat_len</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">def</span> <span class="nf">shrink_attention</span><span class="p">(</span><span class="n">input_att_list</span><span class="p">):</span>
            <span class="c1"># pick up the target attention layers</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
                <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_att_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span>
            <span class="p">):</span>
                <span class="n">input_att_list</span> <span class="o">=</span> <span class="n">input_att_list</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span> <span class="p">:]</span>
            <span class="c1"># pick up the target attention heads</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
                <span class="ow">and</span> <span class="n">input_att_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span>
            <span class="p">):</span>
                <span class="n">input_att_list</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">att</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span><span class="p">]</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">input_att_list</span>
                <span class="p">]</span>
            <span class="k">return</span> <span class="n">input_att_list</span>

        <span class="c1"># return the attention results if specified</span>
        <span class="k">if</span> <span class="n">return_att</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;att_guid_loss&quot;</span><span class="p">):</span>
            <span class="c1"># encoder-decoder attention</span>
            <span class="k">if</span> <span class="s2">&quot;encdec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">:</span>
                <span class="c1"># register the encoder-decoder attention</span>
                <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">att</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">encdec</span><span class="o">=</span><span class="n">shrink_attention</span><span class="p">(</span><span class="n">encdec_attmat</span><span class="p">)))</span>
            <span class="c1"># encoder self-attention</span>
            <span class="k">if</span> <span class="n">enc_attmat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;enc&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">enc</span><span class="o">=</span><span class="n">shrink_attention</span><span class="p">(</span><span class="n">enc_attmat</span><span class="p">))</span>
            <span class="c1"># decoder self-attention</span>
            <span class="k">if</span> <span class="n">dec_attmat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;dec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">dec</span><span class="o">=</span><span class="n">shrink_attention</span><span class="p">(</span><span class="n">dec_attmat</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">def</span> <span class="nf">criterion_forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pred_stop</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">pred_feat_before</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">pred_feat_after</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">tgt_feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">tgt_feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">text_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">att</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feat_loss_fn</span><span class="p">:</span> <span class="n">LeastError</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">stop_loss_fn</span><span class="p">:</span> <span class="n">BCELogits</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">att_guid_loss_fn</span><span class="p">:</span> <span class="n">AttentionGuidance</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="ow">or</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            pred_stop: (batch, seq_len, 1)</span>
<span class="sd">                predicted stop probability</span>
<span class="sd">            pred_feat_before: (batch, seq_len, feat_dim * reduction_factor)</span>
<span class="sd">                predicted acoustic feature before postnet residual addition</span>
<span class="sd">            pred_feat_after: (batch, seq_len, feat_dim * reduction_factor)</span>
<span class="sd">                predicted acoustic feature after postnet residual addition</span>
<span class="sd">            tgt_feat: (batch, seq_len, feat_dim)</span>
<span class="sd">                processed acoustic features, length-reduced and edge-padded</span>
<span class="sd">            tgt_feat_len: (batch,)</span>
<span class="sd">            text_len: (batch,)</span>
<span class="sd">            att:</span>
<span class="sd">            feat_loss_fn:</span>
<span class="sd">            stop_loss_fn:</span>
<span class="sd">            att_guid_loss_fn:</span>
<span class="sd">            **kwargs:</span>
<span class="sd">                Unnecessary arguments for criterion calculation.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># --- Losses Calculation --- #</span>
        <span class="c1"># the external feature loss function has the higher priority</span>
        <span class="k">if</span> <span class="n">feat_loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">feat_loss_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feat_loss</span>
        <span class="c1"># acoustic feature prediction loss</span>
        <span class="n">feat_loss_before</span> <span class="o">=</span> <span class="n">feat_loss_fn</span><span class="p">(</span>
            <span class="n">pred</span><span class="o">=</span><span class="n">pred_feat_before</span><span class="p">,</span> <span class="n">tgt</span><span class="o">=</span><span class="n">tgt_feat</span><span class="p">,</span> <span class="n">tgt_len</span><span class="o">=</span><span class="n">tgt_feat_len</span>
        <span class="p">)</span>
        <span class="n">feat_loss_after</span> <span class="o">=</span> <span class="n">feat_loss_fn</span><span class="p">(</span>
            <span class="n">pred</span><span class="o">=</span><span class="n">pred_feat_after</span><span class="p">,</span> <span class="n">tgt</span><span class="o">=</span><span class="n">tgt_feat</span><span class="p">,</span> <span class="n">tgt_len</span><span class="o">=</span><span class="n">tgt_feat_len</span>
        <span class="p">)</span>

        <span class="c1"># feature prediction stop loss</span>
        <span class="n">pred_stop</span> <span class="o">=</span> <span class="n">pred_stop</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">tgt_stop</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">make_mask_from_len</span><span class="p">(</span>
            <span class="n">tgt_feat_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">max_len</span><span class="o">=</span><span class="n">tgt_feat_len</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
            <span class="n">mask_type</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span>
            <span class="n">return_3d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">pred_stop</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">:</span>
            <span class="n">tgt_stop</span> <span class="o">=</span> <span class="n">tgt_stop</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">pred_stop</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># the external feature loss function has the higher priority</span>
        <span class="k">if</span> <span class="n">stop_loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">stop_loss_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_loss</span>
        <span class="c1"># end-flag prediction</span>
        <span class="n">stop_loss</span> <span class="o">=</span> <span class="n">stop_loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="o">=</span><span class="n">pred_stop</span><span class="p">,</span> <span class="n">tgt</span><span class="o">=</span><span class="n">tgt_stop</span><span class="p">,</span> <span class="n">tgt_len</span><span class="o">=</span><span class="n">tgt_feat_len</span><span class="p">)</span>

        <span class="c1"># combine all losses into the final one</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">feat_loss_before</span> <span class="o">+</span> <span class="n">feat_loss_after</span> <span class="o">+</span> <span class="n">stop_loss</span>

        <span class="c1"># attention guidance loss</span>
        <span class="k">if</span> <span class="n">att_guid_loss_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;att_guid_loss&quot;</span><span class="p">):</span>
            <span class="c1"># the external attention guidance loss function has the higher priority</span>
            <span class="k">if</span> <span class="n">att_guid_loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">att_guid_loss_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span>

            <span class="c1"># layer_num * (batch, head_num, ...) -&gt; (batch, layer_num * head_num, ...)</span>
            <span class="n">att_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">att</span><span class="p">[</span><span class="s2">&quot;encdec&quot;</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">att_guid_loss</span> <span class="o">=</span> <span class="n">att_guid_loss_fn</span><span class="p">(</span><span class="n">att_tensor</span><span class="p">,</span> <span class="n">tgt_feat_len</span><span class="p">,</span> <span class="n">text_len</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">att_guid_loss</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">att_guid_loss</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># --- Metrics Calculation --- #</span>
        <span class="n">logits_threshold</span> <span class="o">=</span> <span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_threshold</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">pred_stop_hard</span> <span class="o">=</span> <span class="n">pred_stop</span> <span class="o">&gt;</span> <span class="n">logits_threshold</span>
        <span class="n">stop_accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_accuracy</span><span class="p">(</span><span class="n">pred_stop_hard</span><span class="p">,</span> <span class="n">tgt_stop</span><span class="p">,</span> <span class="n">tgt_feat_len</span><span class="p">)</span>
        <span class="n">stop_fbeta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_fbeta</span><span class="p">(</span><span class="n">pred_stop_hard</span><span class="p">,</span> <span class="n">tgt_stop</span><span class="p">,</span> <span class="n">tgt_feat_len</span><span class="p">)</span>

        <span class="n">losses</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>
        <span class="c1"># .clone() here prevents the trainable variables from value modification</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
            <span class="n">feat_loss_before</span><span class="o">=</span><span class="n">feat_loss_before</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
            <span class="n">feat_loss_after</span><span class="o">=</span><span class="n">feat_loss_after</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
            <span class="n">stop_loss</span><span class="o">=</span><span class="n">stop_loss</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
            <span class="n">stop_accuracy</span><span class="o">=</span><span class="n">stop_accuracy</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
        <span class="p">)</span>
        <span class="n">metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;stop_f</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stop_fbeta</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">stop_fbeta</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">att_guid_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;att_guid_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">att_guid_loss</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">metrics</span>

    <span class="k">def</span> <span class="nf">visualize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">sample_index</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">snapshot_interval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">epoch_records</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">domain</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">text_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">spk_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">spk_feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="c1"># visualization inference is default to be done by teacher-forcing</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visual_infer_conf</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">visual_infer_conf</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="n">teacher_forcing</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_gl_wav</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_feat</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>

        <span class="c1"># obtain the inference results</span>
        <span class="n">infer_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span>
            <span class="n">infer_conf</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">visual_infer_conf</span><span class="p">,</span>
            <span class="n">return_att</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">feat</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span>
            <span class="n">feat_len</span><span class="o">=</span><span class="n">feat_len</span><span class="p">,</span>
            <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
            <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">,</span>
            <span class="n">spk_ids</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">,</span>
            <span class="n">spk_feat</span><span class="o">=</span><span class="n">spk_feat</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># --- snapshot the objective metrics --- #</span>
        <span class="n">vis_logs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># numerical metrics recording</span>
        <span class="n">materials</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="s2">&quot;stop_accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;stop_f2&quot;</span><span class="p">]:</span>
            <span class="c1"># store each target metric into materials</span>
            <span class="k">if</span> <span class="n">metric</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">epoch_records</span><span class="p">[</span><span class="n">sample_index</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">epoch_records</span><span class="p">[</span><span class="n">sample_index</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">epoch_records</span><span class="p">[</span><span class="n">sample_index</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">infer_results</span><span class="p">[</span><span class="n">metric</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">materials</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch_records</span><span class="p">[</span><span class="n">sample_index</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span>
        <span class="c1"># save the visualization log</span>
        <span class="n">vis_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="nb">dict</span><span class="p">(</span>
                <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;curve&quot;</span><span class="p">,</span>
                <span class="n">materials</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">materials</span><span class="p">),</span>
                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
                <span class="n">x_stride</span><span class="o">=</span><span class="n">snapshot_interval</span><span class="p">,</span>
                <span class="n">sep_save</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">subfolder_names</span><span class="o">=</span><span class="n">sample_index</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># --- snapshot the subjective metrics --- #</span>
        <span class="c1"># record the input audio and real text at the first snapshotting step</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">//</span> <span class="n">snapshot_interval</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># if the audio source is raw/wav</span>
            <span class="k">if</span> <span class="n">feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">vis_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="nb">dict</span><span class="p">(</span>
                        <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;audio&quot;</span><span class="p">,</span>
                        <span class="n">materials</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">real_wav</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">feat</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span>
                        <span class="n">sample_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span>
                        <span class="n">audio_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">audio_format</span><span class="p">,</span>
                        <span class="n">subfolder_names</span><span class="o">=</span><span class="n">sample_index</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="c1"># if the audio source is audio feature (mel spectrogram etc)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">vis_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="nb">dict</span><span class="p">(</span>
                        <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;matrix&quot;</span><span class="p">,</span>
                        <span class="n">materials</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">real_feat</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">feat</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span>
                        <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                        <span class="n">sep_save</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">sum_save</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">data_save</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">flip_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">subfolder_names</span><span class="o">=</span><span class="n">sample_index</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>

            <span class="c1"># snapshot input text</span>
            <span class="n">vis_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="nb">dict</span><span class="p">(</span>
                    <span class="n">materials</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                        <span class="n">real_text</span><span class="o">=</span><span class="p">[</span>
                            <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tensor2text</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
                        <span class="p">]</span>
                    <span class="p">),</span>
                    <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
                    <span class="n">subfolder_names</span><span class="o">=</span><span class="n">sample_index</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># snapshot the generated hypothesis acoustic features into a heatmap</span>
        <span class="n">vis_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="nb">dict</span><span class="p">(</span>
                <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;matrix&quot;</span><span class="p">,</span>
                <span class="n">materials</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                    <span class="n">hypo_feat</span><span class="o">=</span><span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;feat&quot;</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
                <span class="p">),</span>
                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                <span class="n">sep_save</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">sum_save</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">data_save</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">flip_y</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">subfolder_names</span><span class="o">=</span><span class="p">[</span><span class="n">sample_index</span><span class="p">,</span> <span class="s2">&quot;hypo_feat&quot;</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># hypothesis attention matrix</span>
        <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_reshape</span><span class="p">(</span><span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">matrix_snapshot</span><span class="p">(</span>
            <span class="n">vis_logs</span><span class="o">=</span><span class="n">vis_logs</span><span class="p">,</span>
            <span class="n">hypo_attention</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]),</span>
            <span class="n">subfolder_names</span><span class="o">=</span><span class="n">sample_index</span><span class="p">,</span>
            <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">vis_logs</span>

    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">infer_conf</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">text_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">spk_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">spk_feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">spk_feat_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">domain</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_att</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">return_gl_wav</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">return_feat</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">use_dropout</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">use_before</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">teacher_forcing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            # --- Testing data arguments --- #</span>
<span class="sd">            feat: (batch_size, feat_maxlen, feat_dim)</span>
<span class="sd">                The ground-truth utterance for the input text</span>
<span class="sd">                Used for teacher-forcing decoding and objective evaluation</span>
<span class="sd">            feat_len: (batch_size,)</span>
<span class="sd">                The length of `feat`.</span>
<span class="sd">            text: (batch_size, text_maxlen)</span>
<span class="sd">                The text data to be inferred.</span>
<span class="sd">            text_len: (batch_size,)</span>
<span class="sd">                The length of `text`.</span>
<span class="sd">            spk_ids: (batch_size,)</span>
<span class="sd">                The ID of the reference speaker.</span>
<span class="sd">            spk_feat: (batch_size, spk_feat_dim)</span>
<span class="sd">                The speaker embedding of the reference speaker.</span>
<span class="sd">            spk_feat_ids: List[str] = None</span>
<span class="sd">                The IDs for the input spk_feat. Mainly used to record the reference speaker embedding during inference.</span>
<span class="sd">            # --- General inference arguments --- #</span>
<span class="sd">            domain: str = None</span>
<span class="sd">                This argument indicates which domain the input speech belongs to.</span>
<span class="sd">                It&#39;s used to indicate the `TTSDecoder` member how to encode the input speech.</span>
<span class="sd">            return_att: bool = False</span>
<span class="sd">                Whether the attention matrix of the input speech is returned.</span>
<span class="sd">            return_gl_wav: bool = True</span>
<span class="sd">                Whether to convert the generated acoustic features back to GL waveforms.</span>
<span class="sd">            use_dropout: bool = False</span>
<span class="sd">                Whether turn on the dropout layers in the prenet of the TTS decoder when decoding.</span>
<span class="sd">            use_before: bool = False</span>
<span class="sd">                Whether return the acoustic feature not processed by the postnet.</span>
<span class="sd">            teacher_forcing: bool = False</span>
<span class="sd">                Whether turn on the dropout layers in the prenet of the TTS decoder when decoding.</span>
<span class="sd">            # --- TTS decoding arguments --- #</span>
<span class="sd">            infer_conf:</span>
<span class="sd">                The inference configuration given from the `infer_cfg` in your `exp_cfg`.</span>
<span class="sd">                For more details, please refer to speechain.infer_func.tts_decoding.auto_regression.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">text_len</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

        <span class="c1"># --- 0. Hyperparameter &amp; Model Preparation Stage --- #</span>
        <span class="c1"># in-place replace infer_conf with its copy to protect the original information</span>
        <span class="n">infer_conf</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">infer_conf</span><span class="p">)</span>
        <span class="c1"># The following argumentsin infer_conf has the higher priority and will not be passed to auto_regression()</span>
        <span class="k">if</span> <span class="s2">&quot;teacher_forcing&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">teacher_forcing</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;teacher_forcing&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;use_dropout&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">use_dropout</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;use_dropout&quot;</span><span class="p">)</span>

        <span class="c1"># &#39;stop_threshold&#39;, and &#39;use_before&#39; are kept as the arguments of auto_regression()</span>
        <span class="c1"># stop_threshold in infer_conf has the higher priority than the built-in one of the model</span>
        <span class="k">if</span> <span class="s2">&quot;stop_threshold&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">infer_conf</span><span class="p">[</span><span class="s2">&quot;stop_threshold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_threshold</span>
        <span class="c1"># use_before in infer_conf has the higher priority than the default values</span>
        <span class="k">if</span> <span class="s2">&quot;use_before&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">use_before</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="p">[</span><span class="s2">&quot;use_before&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">infer_conf</span><span class="p">[</span><span class="s2">&quot;use_before&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">use_before</span>

        <span class="c1"># return_gl_wav in infer_conf has the higher priority and will not be passed to self.module_forward()</span>
        <span class="k">if</span> <span class="s2">&quot;return_gl_wav&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">return_gl_wav</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;return_gl_wav&quot;</span><span class="p">)</span>
        <span class="c1"># return_feat in infer_conf has the higher priority and will not be passed to self.module_forward()</span>
        <span class="k">if</span> <span class="s2">&quot;return_feat&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">return_feat</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;return_feat&quot;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">return_gl_wav</span> <span class="ow">or</span> <span class="n">return_feat</span>
        <span class="p">),</span> <span class="s2">&quot;return_gl_wav and return_feat cannot be False at the same time.&quot;</span>

        <span class="c1"># return_sr in infer_conf has the higher priority and will not be passed to self.module_forward()</span>
        <span class="n">return_sr</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="s2">&quot;return_sr&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">return_sr</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;return_sr&quot;</span><span class="p">)</span>
            <span class="k">assert</span> <span class="n">return_sr</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;You should input &#39;return_sr&#39; lower than the one of the model </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but got return_sr=</span><span class="si">{</span><span class="n">return_sr</span><span class="si">}</span><span class="s2">!&quot;</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;resampler&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">resampler</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resample</span><span class="p">(</span>
                    <span class="n">orig_freq</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="n">new_freq</span><span class="o">=</span><span class="n">return_sr</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">text</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">resampler</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resampler</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">hypo_feat</span><span class="p">,</span> <span class="n">hypo_feat_len</span><span class="p">,</span> <span class="n">feat_token_len_ratio</span><span class="p">,</span> <span class="n">hypo_att</span> <span class="o">=</span> <span class="p">(</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># turn the dropout layer in the decoder on for introducing variability to the synthetic utterances</span>
        <span class="k">if</span> <span class="n">use_dropout</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">turn_on_dropout</span><span class="p">()</span>

        <span class="c1"># Multi-speaker TTS scenario</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">,</span> <span class="s2">&quot;spk_emb&quot;</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># close-set multi-speaker TTS</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">spk_emb</span><span class="o">.</span><span class="n">use_lookup</span><span class="p">:</span>
                <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;idx2spk&quot;</span><span class="p">)</span>
                <span class="c1"># randomly pick up training speakers as the reference speakers</span>
                <span class="k">if</span> <span class="n">spk_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">spk_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span>
                        <span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">high</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx2spk</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,),</span>
                        <span class="n">device</span><span class="o">=</span><span class="n">text</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="p">)</span>
            <span class="c1"># open-set multi-speaker TTS</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">spk_emb</span><span class="o">.</span><span class="n">use_pretrain</span><span class="p">:</span>
                <span class="c1"># use random vectors as the reference speaker embedding if spk_feat is not given</span>
                <span class="k">if</span> <span class="n">spk_feat</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># make sure that the range of random speaker feature is [-1, 1)</span>
                    <span class="n">spk_feat</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
                            <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">spk_emb</span><span class="o">.</span><span class="n">spk_emb_dim</span><span class="p">),</span>
                            <span class="n">device</span><span class="o">=</span><span class="n">text</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                        <span class="p">)</span>
                        <span class="o">*</span> <span class="mi">2</span>
                        <span class="o">-</span> <span class="mi">1</span>
                    <span class="p">)</span>
                    <span class="n">spk_feat_ids</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;rand_spk&quot;</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>

        <span class="c1"># --- 1. Acoustic Feature Generation Stage --- #</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="c1"># --- 1.1. The 1st Pass: TTS Auto-Regressive Decoding --- #</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">teacher_forcing</span><span class="p">:</span>
            <span class="c1"># copy the input data in advance for data safety</span>
            <span class="n">model_input</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">))</span>

            <span class="c1"># Encoding input text</span>
            <span class="n">enc_text</span><span class="p">,</span> <span class="n">enc_text_mask</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="o">**</span><span class="n">model_input</span><span class="p">)</span>

            <span class="c1"># Generate the synthetic acoustic features auto-regressively</span>
            <span class="n">infer_results</span> <span class="o">=</span> <span class="n">auto_regression</span><span class="p">(</span>
                <span class="n">enc_text</span><span class="o">=</span><span class="n">enc_text</span><span class="p">,</span>
                <span class="n">enc_text_mask</span><span class="o">=</span><span class="n">enc_text_mask</span><span class="p">,</span>
                <span class="n">spk_ids</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">,</span>
                <span class="n">spk_feat</span><span class="o">=</span><span class="n">spk_feat</span><span class="p">,</span>
                <span class="n">reduction_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">,</span>
                <span class="n">feat_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span>
                <span class="n">decode_one_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">,</span>
                <span class="o">**</span><span class="n">infer_conf</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">hypo_feat</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;hypo_feat&quot;</span><span class="p">]</span>
            <span class="n">hypo_feat_len</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;hypo_feat_len&quot;</span><span class="p">]</span>
            <span class="n">feat_token_len_ratio</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;feat_token_len_ratio&quot;</span><span class="p">]</span>

        <span class="c1"># --- 1.2. The 2nd Pass: TTS Teacher-Forcing Decoding --- #</span>
        <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="ow">or</span> <span class="n">return_att</span><span class="p">:</span>
            <span class="n">infer_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_forward</span><span class="p">(</span>
                <span class="n">feat</span><span class="o">=</span><span class="n">feat</span> <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="k">else</span> <span class="n">hypo_feat</span><span class="p">,</span>
                <span class="n">feat_len</span><span class="o">=</span><span class="n">feat_len</span> <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="k">else</span> <span class="n">hypo_feat_len</span><span class="p">,</span>
                <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">,</span>
                <span class="n">spk_feat</span><span class="o">=</span><span class="n">spk_feat</span><span class="p">,</span>
                <span class="n">spk_ids</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">,</span>
                <span class="n">return_att</span><span class="o">=</span><span class="n">return_att</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># return the attention matrices</span>
            <span class="k">if</span> <span class="n">return_att</span><span class="p">:</span>
                <span class="n">hypo_att</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span>

            <span class="c1"># update the hypothesis feature-related data in the teacher forcing mode</span>
            <span class="k">if</span> <span class="n">teacher_forcing</span><span class="p">:</span>
                <span class="n">criterion_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span>
                    <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">,</span> <span class="o">**</span><span class="n">infer_results</span>
                <span class="p">)</span>
                <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="n">cri_name</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">tensor_result</span><span class="p">))</span>
                        <span class="k">for</span> <span class="n">cri_name</span><span class="p">,</span> <span class="n">tensor_result</span> <span class="ow">in</span> <span class="n">criterion_results</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                    <span class="p">}</span>
                <span class="p">)</span>
                <span class="n">hypo_feat</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span>
                    <span class="s2">&quot;pred_feat_before&quot;</span> <span class="k">if</span> <span class="n">use_before</span> <span class="k">else</span> <span class="s2">&quot;pred_feat_after&quot;</span>
                <span class="p">]</span>
                <span class="n">hypo_feat_len</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;tgt_feat_len&quot;</span><span class="p">]</span>
                <span class="c1"># hypo_feat &amp; hypo_feat_len recovery by reduction_factor</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">batch_size</span><span class="p">,</span> <span class="n">feat_dim</span> <span class="o">=</span> <span class="n">hypo_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">hypo_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">hypo_feat</span> <span class="o">=</span> <span class="n">hypo_feat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                        <span class="n">batch_size</span><span class="p">,</span>
                        <span class="n">hypo_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">,</span>
                        <span class="n">feat_dim</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">hypo_feat_len</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span>
                <span class="c1"># remove the sos at the beginning and eos at the end</span>
                <span class="n">feat_token_len_ratio</span> <span class="o">=</span> <span class="n">hypo_feat_len</span> <span class="o">/</span> <span class="p">(</span><span class="n">text_len</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)</span>

        <span class="c1"># --- 1.3. The 3rd Pass: denormalize the acoustic feature and transformation to waveforms --- #</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">,</span> <span class="s2">&quot;normalize&quot;</span><span class="p">):</span>
            <span class="n">hypo_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">normalize</span><span class="o">.</span><span class="n">recover</span><span class="p">(</span><span class="n">hypo_feat</span><span class="p">,</span> <span class="n">group_ids</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">)</span>

        <span class="c1"># turn the tensor-like spk_ids (preprocessed by self.spk2idx) into a list</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spk_ids</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">spk_ids</span> <span class="o">=</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">idx2spk</span><span class="p">[</span><span class="n">s_id</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="k">if</span> <span class="n">s_id</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;aver_spk&quot;</span>
                <span class="k">for</span> <span class="n">s_id</span> <span class="ow">in</span> <span class="n">spk_ids</span>
            <span class="p">]</span>

        <span class="c1"># convert the acoustic features back to GL waveforms if specified</span>
        <span class="k">if</span> <span class="n">return_gl_wav</span><span class="p">:</span>
            <span class="n">hypo_wav</span><span class="p">,</span> <span class="n">hypo_wav_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">recover</span><span class="p">(</span>
                <span class="n">hypo_feat</span><span class="p">,</span> <span class="n">hypo_feat_len</span>
            <span class="p">)</span>
            <span class="c1"># remove the redundant silence parts at the end of the synthetic waveforms</span>
            <span class="n">hypo_wav</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">(</span>
                    <span class="n">hypo_wav</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span> <span class="n">hypo_wav_len</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
                    <span class="k">if</span> <span class="n">return_sr</span> <span class="ow">is</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">resampler</span><span class="p">(</span><span class="n">hypo_wav</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span> <span class="n">hypo_wav_len</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hypo_wav</span><span class="p">))</span>
            <span class="p">]</span>
            <span class="n">hypo_wav_len</span> <span class="o">=</span> <span class="p">[</span><span class="n">wav</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">wav</span> <span class="ow">in</span> <span class="n">hypo_wav</span><span class="p">]</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="n">gl_wav</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                    <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;wav&quot;</span><span class="p">,</span>
                    <span class="n">sample_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="k">if</span> <span class="n">return_sr</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">return_sr</span><span class="p">,</span>
                    <span class="n">group_ids</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">,</span>
                    <span class="n">content</span><span class="o">=</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">hypo_wav</span><span class="p">,</span> <span class="n">tgt</span><span class="o">=</span><span class="s2">&quot;numpy&quot;</span><span class="p">),</span>
                <span class="p">),</span>
                <span class="n">gl_wav_len</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">hypo_wav_len</span><span class="p">)),</span>
            <span class="p">)</span>

        <span class="c1"># --- 2. Post-processing for the Generated Acoustic Features --- #</span>
        <span class="c1"># return the acoustic features if specified</span>
        <span class="k">if</span> <span class="n">return_feat</span><span class="p">:</span>
            <span class="c1"># remove the redundant silence parts at the end of the synthetic frames</span>
            <span class="n">hypo_feat</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">hypo_feat</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span> <span class="n">hypo_feat_len</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hypo_feat</span><span class="p">))</span>
            <span class="p">]</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="c1"># the sampling rate of the acoustic features remain the one of the TTS model</span>
                <span class="n">feat</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                    <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;npz&quot;</span><span class="p">,</span>
                    <span class="n">sample_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span>
                    <span class="n">group_ids</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">,</span>
                    <span class="n">content</span><span class="o">=</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">hypo_feat</span><span class="p">,</span> <span class="n">tgt</span><span class="o">=</span><span class="s2">&quot;numpy&quot;</span><span class="p">),</span>
                <span class="p">),</span>
                <span class="n">feat_len</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">hypo_feat_len</span><span class="p">)),</span>
            <span class="p">)</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="n">feat_token_len_ratio</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">feat_token_len_ratio</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># record the speaker ID used as the reference</span>
        <span class="k">if</span> <span class="n">spk_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ref_spk</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">))</span>
        <span class="c1"># record the speaker embedding ID used as the reference</span>
        <span class="k">if</span> <span class="n">spk_feat_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ref_spk_feat</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">spk_feat_ids</span><span class="p">))</span>

        <span class="c1"># evaluation reports for all the testing instances</span>
        <span class="n">instance_report_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># loop each utterance</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)):</span>
            <span class="k">if</span> <span class="s2">&quot;Feature-Token Length Ratio&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Feature-Token Length Ratio&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Feature-Token Length Ratio&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feat_token_len_ratio</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="s2">&quot;Feature Length&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Feature Length&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Feature Length&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">hypo_feat_len</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># register the instance reports for generating instance_reports.md</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_instance_reports</span><span class="p">(</span><span class="n">md_list_dict</span><span class="o">=</span><span class="n">instance_report_dict</span><span class="p">)</span>

        <span class="c1"># add the attention matrix into the output Dict, only used for model visualization during training</span>
        <span class="c1"># because it will consume too much time for saving the attention matrices of all testing samples during testing</span>
        <span class="k">if</span> <span class="n">return_att</span><span class="p">:</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">att</span><span class="o">=</span><span class="n">hypo_att</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="model.ar_tts.ARTTS.criterion_forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">criterion_forward</span><span class="p">(</span><span class="n">pred_stop</span><span class="p">,</span> <span class="n">pred_feat_before</span><span class="p">,</span> <span class="n">pred_feat_after</span><span class="p">,</span> <span class="n">tgt_feat</span><span class="p">,</span> <span class="n">tgt_feat_len</span><span class="p">,</span> <span class="n">text_len</span><span class="p">,</span> <span class="n">att</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feat_loss_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stop_loss_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">att_guid_loss_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>pred_stop</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch, seq_len, 1)
predicted stop probability</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pred_feat_before</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch, seq_len, feat_dim * reduction_factor)
predicted acoustic feature before postnet residual addition</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pred_feat_after</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch, seq_len, feat_dim * reduction_factor)
predicted acoustic feature after postnet residual addition</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tgt_feat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch, seq_len, feat_dim)
processed acoustic features, length-reduced and edge-padded</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>tgt_feat_len</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch,)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>text_len</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch,)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>att</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="typing.List">List</span>[<span title="torch.Tensor">Tensor</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>feat_loss_fn</code>
            </td>
            <td>
                  <code><span title="speechain.criterion.least_error.LeastError">LeastError</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stop_loss_fn</code>
            </td>
            <td>
                  <code><span title="speechain.criterion.bce_logits.BCELogits">BCELogits</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>att_guid_loss_fn</code>
            </td>
            <td>
                  <code><span title="speechain.criterion.att_guid.AttentionGuidance">AttentionGuidance</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Unnecessary arguments for criterion calculation.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/ar_tts.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">criterion_forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">pred_stop</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">pred_feat_before</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">pred_feat_after</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">tgt_feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">tgt_feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">text_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">att</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">feat_loss_fn</span><span class="p">:</span> <span class="n">LeastError</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stop_loss_fn</span><span class="p">:</span> <span class="n">BCELogits</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">att_guid_loss_fn</span><span class="p">:</span> <span class="n">AttentionGuidance</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="ow">or</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        pred_stop: (batch, seq_len, 1)</span>
<span class="sd">            predicted stop probability</span>
<span class="sd">        pred_feat_before: (batch, seq_len, feat_dim * reduction_factor)</span>
<span class="sd">            predicted acoustic feature before postnet residual addition</span>
<span class="sd">        pred_feat_after: (batch, seq_len, feat_dim * reduction_factor)</span>
<span class="sd">            predicted acoustic feature after postnet residual addition</span>
<span class="sd">        tgt_feat: (batch, seq_len, feat_dim)</span>
<span class="sd">            processed acoustic features, length-reduced and edge-padded</span>
<span class="sd">        tgt_feat_len: (batch,)</span>
<span class="sd">        text_len: (batch,)</span>
<span class="sd">        att:</span>
<span class="sd">        feat_loss_fn:</span>
<span class="sd">        stop_loss_fn:</span>
<span class="sd">        att_guid_loss_fn:</span>
<span class="sd">        **kwargs:</span>
<span class="sd">            Unnecessary arguments for criterion calculation.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># --- Losses Calculation --- #</span>
    <span class="c1"># the external feature loss function has the higher priority</span>
    <span class="k">if</span> <span class="n">feat_loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">feat_loss_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feat_loss</span>
    <span class="c1"># acoustic feature prediction loss</span>
    <span class="n">feat_loss_before</span> <span class="o">=</span> <span class="n">feat_loss_fn</span><span class="p">(</span>
        <span class="n">pred</span><span class="o">=</span><span class="n">pred_feat_before</span><span class="p">,</span> <span class="n">tgt</span><span class="o">=</span><span class="n">tgt_feat</span><span class="p">,</span> <span class="n">tgt_len</span><span class="o">=</span><span class="n">tgt_feat_len</span>
    <span class="p">)</span>
    <span class="n">feat_loss_after</span> <span class="o">=</span> <span class="n">feat_loss_fn</span><span class="p">(</span>
        <span class="n">pred</span><span class="o">=</span><span class="n">pred_feat_after</span><span class="p">,</span> <span class="n">tgt</span><span class="o">=</span><span class="n">tgt_feat</span><span class="p">,</span> <span class="n">tgt_len</span><span class="o">=</span><span class="n">tgt_feat_len</span>
    <span class="p">)</span>

    <span class="c1"># feature prediction stop loss</span>
    <span class="n">pred_stop</span> <span class="o">=</span> <span class="n">pred_stop</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">tgt_stop</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">make_mask_from_len</span><span class="p">(</span>
        <span class="n">tgt_feat_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">max_len</span><span class="o">=</span><span class="n">tgt_feat_len</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
        <span class="n">mask_type</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span>
        <span class="n">return_3d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">pred_stop</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">:</span>
        <span class="n">tgt_stop</span> <span class="o">=</span> <span class="n">tgt_stop</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">pred_stop</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="c1"># the external feature loss function has the higher priority</span>
    <span class="k">if</span> <span class="n">stop_loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">stop_loss_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_loss</span>
    <span class="c1"># end-flag prediction</span>
    <span class="n">stop_loss</span> <span class="o">=</span> <span class="n">stop_loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="o">=</span><span class="n">pred_stop</span><span class="p">,</span> <span class="n">tgt</span><span class="o">=</span><span class="n">tgt_stop</span><span class="p">,</span> <span class="n">tgt_len</span><span class="o">=</span><span class="n">tgt_feat_len</span><span class="p">)</span>

    <span class="c1"># combine all losses into the final one</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">feat_loss_before</span> <span class="o">+</span> <span class="n">feat_loss_after</span> <span class="o">+</span> <span class="n">stop_loss</span>

    <span class="c1"># attention guidance loss</span>
    <span class="k">if</span> <span class="n">att_guid_loss_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;att_guid_loss&quot;</span><span class="p">):</span>
        <span class="c1"># the external attention guidance loss function has the higher priority</span>
        <span class="k">if</span> <span class="n">att_guid_loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">att_guid_loss_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span>

        <span class="c1"># layer_num * (batch, head_num, ...) -&gt; (batch, layer_num * head_num, ...)</span>
        <span class="n">att_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">att</span><span class="p">[</span><span class="s2">&quot;encdec&quot;</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">att_guid_loss</span> <span class="o">=</span> <span class="n">att_guid_loss_fn</span><span class="p">(</span><span class="n">att_tensor</span><span class="p">,</span> <span class="n">tgt_feat_len</span><span class="p">,</span> <span class="n">text_len</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="n">att_guid_loss</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">att_guid_loss</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># --- Metrics Calculation --- #</span>
    <span class="n">logits_threshold</span> <span class="o">=</span> <span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_threshold</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pred_stop_hard</span> <span class="o">=</span> <span class="n">pred_stop</span> <span class="o">&gt;</span> <span class="n">logits_threshold</span>
    <span class="n">stop_accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_accuracy</span><span class="p">(</span><span class="n">pred_stop_hard</span><span class="p">,</span> <span class="n">tgt_stop</span><span class="p">,</span> <span class="n">tgt_feat_len</span><span class="p">)</span>
    <span class="n">stop_fbeta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_fbeta</span><span class="p">(</span><span class="n">pred_stop_hard</span><span class="p">,</span> <span class="n">tgt_stop</span><span class="p">,</span> <span class="n">tgt_feat_len</span><span class="p">)</span>

    <span class="n">losses</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>
    <span class="c1"># .clone() here prevents the trainable variables from value modification</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
        <span class="n">feat_loss_before</span><span class="o">=</span><span class="n">feat_loss_before</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
        <span class="n">feat_loss_after</span><span class="o">=</span><span class="n">feat_loss_after</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
        <span class="n">stop_loss</span><span class="o">=</span><span class="n">stop_loss</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
        <span class="n">stop_accuracy</span><span class="o">=</span><span class="n">stop_accuracy</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
    <span class="p">)</span>
    <span class="n">metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;stop_f</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stop_fbeta</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">stop_fbeta</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">att_guid_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;att_guid_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">att_guid_loss</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">metrics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.ar_tts.ARTTS.criterion_init" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">criterion_init</span><span class="p">(</span><span class="n">feat_loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">att_guid_loss</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<details class="this-function-initializes-all-the-necessary-criterion-members-for-an-autoregressive-tts" open>
  <summary>This function initializes all the necessary Criterion members for an autoregressive TTS</summary>
  <ol>
<li><code>speechain.criterion.least_error.LeastError</code> for acoustic feature prediction loss calculation.</li>
<li><code>speechain.criterion.bce_logits.BCELogits</code> for stop flag prediction loss calculation.</li>
<li><code>speechain.criterion.accuracy.Accuracy</code> for teacher-forcing stop flag prediction accuracy calculation.</li>
<li><code>speechain.criterion.fbeta_score.FBetaScore</code> for teacher-forcing stop flag prediction f-score calculation.</li>
</ol>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>feat_loss</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict[str, Any]
The arguments for LeastError(). If not given, the default setting of LeastError() will be used.
Please refer to speechain.criterion.least_error.LeastError for more details.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>att_guid_loss</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span> or bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict[str, Any] or bool
The arguments for AttentionGuidance(). If not given, self.att_guid_loss won't be initialized.
This argument can also be set to a bool value 'True'. If True, the default setting of AttentionGuidance()
will be used.
Please refer to speechain.criterion.att_guid.AttentionGuidance for more details.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/ar_tts.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">criterion_init</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">feat_loss</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">att_guid_loss</span><span class="p">:</span> <span class="n">Dict</span> <span class="ow">or</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function initializes all the necessary Criterion members for an autoregressive TTS:</span>
<span class="sd">        1. `speechain.criterion.least_error.LeastError` for acoustic feature prediction loss calculation.</span>
<span class="sd">        2. `speechain.criterion.bce_logits.BCELogits` for stop flag prediction loss calculation.</span>
<span class="sd">        3. `speechain.criterion.accuracy.Accuracy` for teacher-forcing stop flag prediction accuracy calculation.</span>
<span class="sd">        4. `speechain.criterion.fbeta_score.FBetaScore` for teacher-forcing stop flag prediction f-score calculation.</span>

<span class="sd">    Args:</span>
<span class="sd">        feat_loss: Dict[str, Any]</span>
<span class="sd">            The arguments for LeastError(). If not given, the default setting of LeastError() will be used.</span>
<span class="sd">            Please refer to speechain.criterion.least_error.LeastError for more details.</span>
<span class="sd">        att_guid_loss: Dict[str, Any] or bool</span>
<span class="sd">            The arguments for AttentionGuidance(). If not given, self.att_guid_loss won&#39;t be initialized.</span>
<span class="sd">            This argument can also be set to a bool value &#39;True&#39;. If True, the default setting of AttentionGuidance()</span>
<span class="sd">            will be used.</span>
<span class="sd">            Please refer to speechain.criterion.att_guid.AttentionGuidance for more details.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># --- Criterion Part Initialization --- #</span>
    <span class="c1"># feature prediction loss</span>
    <span class="k">if</span> <span class="n">feat_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">feat_loss</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">feat_loss</span> <span class="o">=</span> <span class="n">LeastError</span><span class="p">(</span><span class="o">**</span><span class="n">feat_loss</span><span class="p">)</span>

    <span class="c1"># synthesis stop loss</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stop_loss</span> <span class="o">=</span> <span class="n">BCELogits</span><span class="p">(</span><span class="n">pos_weight</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stop_pos_weight</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">att_guid_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># if att_guid_loss is given as True, the default arguments of AttentionGuidance will be used</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="n">att_guid_loss</span>
            <span class="p">),</span> <span class="s2">&quot;If you want to use the default setting of AttentionGuidance, please give att_guid_loss as True.&quot;</span>
            <span class="n">att_guid_loss</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="s2">&quot;encdec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span>
        <span class="p">),</span> <span class="s2">&quot;If you want to enable attention guidance for ASR training, please include &#39;encdec&#39; in return_att_type.&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span> <span class="o">=</span> <span class="n">AttentionGuidance</span><span class="p">(</span><span class="o">**</span><span class="n">att_guid_loss</span><span class="p">)</span>

    <span class="c1"># validation metrics</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stop_accuracy</span> <span class="o">=</span> <span class="n">Accuracy</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stop_fbeta</span> <span class="o">=</span> <span class="n">FBetaScore</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.ar_tts.ARTTS.inference" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inference</span><span class="p">(</span><span class="n">infer_conf</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feat</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feat_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">spk_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">spk_feat</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">spk_feat_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_att</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_gl_wav</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_feat</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">use_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">use_before</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">teacher_forcing</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>feat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch_size, feat_maxlen, feat_dim)
The ground-truth utterance for the input text
Used for teacher-forcing decoding and objective evaluation</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>feat_len</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch_size,)
The length of <code>feat</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>text</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch_size, text_maxlen)
The text data to be inferred.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>text_len</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch_size,)
The length of <code>text</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spk_ids</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch_size,)
The ID of the reference speaker.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spk_feat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch_size, spk_feat_dim)
The speaker embedding of the reference speaker.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spk_feat_ids</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List[str] = None
The IDs for the input spk_feat. Mainly used to record the reference speaker embedding during inference.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>domain</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>str = None
This argument indicates which domain the input speech belongs to.
It's used to indicate the <code>TTSDecoder</code> member how to encode the input speech.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_att</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool = False
Whether the attention matrix of the input speech is returned.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_gl_wav</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool = True
Whether to convert the generated acoustic features back to GL waveforms.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_dropout</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool = False
Whether turn on the dropout layers in the prenet of the TTS decoder when decoding.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_before</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool = False
Whether return the acoustic feature not processed by the postnet.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>teacher_forcing</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool = False
Whether turn on the dropout layers in the prenet of the TTS decoder when decoding.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>infer_conf</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The inference configuration given from the <code>infer_cfg</code> in your <code>exp_cfg</code>.
For more details, please refer to speechain.infer_func.tts_decoding.auto_regression.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/ar_tts.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span>
<span class="normal">931</span>
<span class="normal">932</span>
<span class="normal">933</span>
<span class="normal">934</span>
<span class="normal">935</span>
<span class="normal">936</span>
<span class="normal">937</span>
<span class="normal">938</span>
<span class="normal">939</span>
<span class="normal">940</span>
<span class="normal">941</span>
<span class="normal">942</span>
<span class="normal">943</span>
<span class="normal">944</span>
<span class="normal">945</span>
<span class="normal">946</span>
<span class="normal">947</span>
<span class="normal">948</span>
<span class="normal">949</span>
<span class="normal">950</span>
<span class="normal">951</span>
<span class="normal">952</span>
<span class="normal">953</span>
<span class="normal">954</span>
<span class="normal">955</span>
<span class="normal">956</span>
<span class="normal">957</span>
<span class="normal">958</span>
<span class="normal">959</span>
<span class="normal">960</span>
<span class="normal">961</span>
<span class="normal">962</span>
<span class="normal">963</span>
<span class="normal">964</span>
<span class="normal">965</span>
<span class="normal">966</span>
<span class="normal">967</span>
<span class="normal">968</span>
<span class="normal">969</span>
<span class="normal">970</span>
<span class="normal">971</span>
<span class="normal">972</span>
<span class="normal">973</span>
<span class="normal">974</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inference</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">infer_conf</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">text</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">text_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spk_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spk_feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spk_feat_ids</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">domain</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_att</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_gl_wav</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">return_feat</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">use_dropout</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">use_before</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">teacher_forcing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        # --- Testing data arguments --- #</span>
<span class="sd">        feat: (batch_size, feat_maxlen, feat_dim)</span>
<span class="sd">            The ground-truth utterance for the input text</span>
<span class="sd">            Used for teacher-forcing decoding and objective evaluation</span>
<span class="sd">        feat_len: (batch_size,)</span>
<span class="sd">            The length of `feat`.</span>
<span class="sd">        text: (batch_size, text_maxlen)</span>
<span class="sd">            The text data to be inferred.</span>
<span class="sd">        text_len: (batch_size,)</span>
<span class="sd">            The length of `text`.</span>
<span class="sd">        spk_ids: (batch_size,)</span>
<span class="sd">            The ID of the reference speaker.</span>
<span class="sd">        spk_feat: (batch_size, spk_feat_dim)</span>
<span class="sd">            The speaker embedding of the reference speaker.</span>
<span class="sd">        spk_feat_ids: List[str] = None</span>
<span class="sd">            The IDs for the input spk_feat. Mainly used to record the reference speaker embedding during inference.</span>
<span class="sd">        # --- General inference arguments --- #</span>
<span class="sd">        domain: str = None</span>
<span class="sd">            This argument indicates which domain the input speech belongs to.</span>
<span class="sd">            It&#39;s used to indicate the `TTSDecoder` member how to encode the input speech.</span>
<span class="sd">        return_att: bool = False</span>
<span class="sd">            Whether the attention matrix of the input speech is returned.</span>
<span class="sd">        return_gl_wav: bool = True</span>
<span class="sd">            Whether to convert the generated acoustic features back to GL waveforms.</span>
<span class="sd">        use_dropout: bool = False</span>
<span class="sd">            Whether turn on the dropout layers in the prenet of the TTS decoder when decoding.</span>
<span class="sd">        use_before: bool = False</span>
<span class="sd">            Whether return the acoustic feature not processed by the postnet.</span>
<span class="sd">        teacher_forcing: bool = False</span>
<span class="sd">            Whether turn on the dropout layers in the prenet of the TTS decoder when decoding.</span>
<span class="sd">        # --- TTS decoding arguments --- #</span>
<span class="sd">        infer_conf:</span>
<span class="sd">            The inference configuration given from the `infer_cfg` in your `exp_cfg`.</span>
<span class="sd">            For more details, please refer to speechain.infer_func.tts_decoding.auto_regression.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">text_len</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="c1"># --- 0. Hyperparameter &amp; Model Preparation Stage --- #</span>
    <span class="c1"># in-place replace infer_conf with its copy to protect the original information</span>
    <span class="n">infer_conf</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">infer_conf</span><span class="p">)</span>
    <span class="c1"># The following argumentsin infer_conf has the higher priority and will not be passed to auto_regression()</span>
    <span class="k">if</span> <span class="s2">&quot;teacher_forcing&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">teacher_forcing</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;teacher_forcing&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;use_dropout&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">use_dropout</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;use_dropout&quot;</span><span class="p">)</span>

    <span class="c1"># &#39;stop_threshold&#39;, and &#39;use_before&#39; are kept as the arguments of auto_regression()</span>
    <span class="c1"># stop_threshold in infer_conf has the higher priority than the built-in one of the model</span>
    <span class="k">if</span> <span class="s2">&quot;stop_threshold&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">infer_conf</span><span class="p">[</span><span class="s2">&quot;stop_threshold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_threshold</span>
    <span class="c1"># use_before in infer_conf has the higher priority than the default values</span>
    <span class="k">if</span> <span class="s2">&quot;use_before&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">use_before</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="p">[</span><span class="s2">&quot;use_before&quot;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">infer_conf</span><span class="p">[</span><span class="s2">&quot;use_before&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">use_before</span>

    <span class="c1"># return_gl_wav in infer_conf has the higher priority and will not be passed to self.module_forward()</span>
    <span class="k">if</span> <span class="s2">&quot;return_gl_wav&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">return_gl_wav</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;return_gl_wav&quot;</span><span class="p">)</span>
    <span class="c1"># return_feat in infer_conf has the higher priority and will not be passed to self.module_forward()</span>
    <span class="k">if</span> <span class="s2">&quot;return_feat&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">return_feat</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;return_feat&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">return_gl_wav</span> <span class="ow">or</span> <span class="n">return_feat</span>
    <span class="p">),</span> <span class="s2">&quot;return_gl_wav and return_feat cannot be False at the same time.&quot;</span>

    <span class="c1"># return_sr in infer_conf has the higher priority and will not be passed to self.module_forward()</span>
    <span class="n">return_sr</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="s2">&quot;return_sr&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">return_sr</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;return_sr&quot;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">return_sr</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;You should input &#39;return_sr&#39; lower than the one of the model </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;but got return_sr=</span><span class="si">{</span><span class="n">return_sr</span><span class="si">}</span><span class="s2">!&quot;</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;resampler&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resampler</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resample</span><span class="p">(</span>
                <span class="n">orig_freq</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span> <span class="n">new_freq</span><span class="o">=</span><span class="n">return_sr</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">text</span><span class="o">.</span><span class="n">is_cuda</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">resampler</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resampler</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="n">hypo_feat</span><span class="p">,</span> <span class="n">hypo_feat_len</span><span class="p">,</span> <span class="n">feat_token_len_ratio</span><span class="p">,</span> <span class="n">hypo_att</span> <span class="o">=</span> <span class="p">(</span>
        <span class="kc">None</span><span class="p">,</span>
        <span class="kc">None</span><span class="p">,</span>
        <span class="kc">None</span><span class="p">,</span>
        <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># turn the dropout layer in the decoder on for introducing variability to the synthetic utterances</span>
    <span class="k">if</span> <span class="n">use_dropout</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">turn_on_dropout</span><span class="p">()</span>

    <span class="c1"># Multi-speaker TTS scenario</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">,</span> <span class="s2">&quot;spk_emb&quot;</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># close-set multi-speaker TTS</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">spk_emb</span><span class="o">.</span><span class="n">use_lookup</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;idx2spk&quot;</span><span class="p">)</span>
            <span class="c1"># randomly pick up training speakers as the reference speakers</span>
            <span class="k">if</span> <span class="n">spk_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">spk_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span>
                    <span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">high</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx2spk</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,),</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">text</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
        <span class="c1"># open-set multi-speaker TTS</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">spk_emb</span><span class="o">.</span><span class="n">use_pretrain</span><span class="p">:</span>
            <span class="c1"># use random vectors as the reference speaker embedding if spk_feat is not given</span>
            <span class="k">if</span> <span class="n">spk_feat</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># make sure that the range of random speaker feature is [-1, 1)</span>
                <span class="n">spk_feat</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">spk_emb</span><span class="o">.</span><span class="n">spk_emb_dim</span><span class="p">),</span>
                        <span class="n">device</span><span class="o">=</span><span class="n">text</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="o">*</span> <span class="mi">2</span>
                    <span class="o">-</span> <span class="mi">1</span>
                <span class="p">)</span>
                <span class="n">spk_feat_ids</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;rand_spk&quot;</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>

    <span class="c1"># --- 1. Acoustic Feature Generation Stage --- #</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="c1"># --- 1.1. The 1st Pass: TTS Auto-Regressive Decoding --- #</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">teacher_forcing</span><span class="p">:</span>
        <span class="c1"># copy the input data in advance for data safety</span>
        <span class="n">model_input</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">))</span>

        <span class="c1"># Encoding input text</span>
        <span class="n">enc_text</span><span class="p">,</span> <span class="n">enc_text_mask</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="o">**</span><span class="n">model_input</span><span class="p">)</span>

        <span class="c1"># Generate the synthetic acoustic features auto-regressively</span>
        <span class="n">infer_results</span> <span class="o">=</span> <span class="n">auto_regression</span><span class="p">(</span>
            <span class="n">enc_text</span><span class="o">=</span><span class="n">enc_text</span><span class="p">,</span>
            <span class="n">enc_text_mask</span><span class="o">=</span><span class="n">enc_text_mask</span><span class="p">,</span>
            <span class="n">spk_ids</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">,</span>
            <span class="n">spk_feat</span><span class="o">=</span><span class="n">spk_feat</span><span class="p">,</span>
            <span class="n">reduction_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">,</span>
            <span class="n">feat_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span>
            <span class="n">decode_one_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">,</span>
            <span class="o">**</span><span class="n">infer_conf</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">hypo_feat</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;hypo_feat&quot;</span><span class="p">]</span>
        <span class="n">hypo_feat_len</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;hypo_feat_len&quot;</span><span class="p">]</span>
        <span class="n">feat_token_len_ratio</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;feat_token_len_ratio&quot;</span><span class="p">]</span>

    <span class="c1"># --- 1.2. The 2nd Pass: TTS Teacher-Forcing Decoding --- #</span>
    <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="ow">or</span> <span class="n">return_att</span><span class="p">:</span>
        <span class="n">infer_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_forward</span><span class="p">(</span>
            <span class="n">feat</span><span class="o">=</span><span class="n">feat</span> <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="k">else</span> <span class="n">hypo_feat</span><span class="p">,</span>
            <span class="n">feat_len</span><span class="o">=</span><span class="n">feat_len</span> <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="k">else</span> <span class="n">hypo_feat_len</span><span class="p">,</span>
            <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
            <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">,</span>
            <span class="n">spk_feat</span><span class="o">=</span><span class="n">spk_feat</span><span class="p">,</span>
            <span class="n">spk_ids</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">,</span>
            <span class="n">return_att</span><span class="o">=</span><span class="n">return_att</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># return the attention matrices</span>
        <span class="k">if</span> <span class="n">return_att</span><span class="p">:</span>
            <span class="n">hypo_att</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span>

        <span class="c1"># update the hypothesis feature-related data in the teacher forcing mode</span>
        <span class="k">if</span> <span class="n">teacher_forcing</span><span class="p">:</span>
            <span class="n">criterion_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span>
                <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">,</span> <span class="o">**</span><span class="n">infer_results</span>
            <span class="p">)</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="n">cri_name</span><span class="p">:</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">tensor_result</span><span class="p">))</span>
                    <span class="k">for</span> <span class="n">cri_name</span><span class="p">,</span> <span class="n">tensor_result</span> <span class="ow">in</span> <span class="n">criterion_results</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="p">}</span>
            <span class="p">)</span>
            <span class="n">hypo_feat</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span>
                <span class="s2">&quot;pred_feat_before&quot;</span> <span class="k">if</span> <span class="n">use_before</span> <span class="k">else</span> <span class="s2">&quot;pred_feat_after&quot;</span>
            <span class="p">]</span>
            <span class="n">hypo_feat_len</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;tgt_feat_len&quot;</span><span class="p">]</span>
            <span class="c1"># hypo_feat &amp; hypo_feat_len recovery by reduction_factor</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">batch_size</span><span class="p">,</span> <span class="n">feat_dim</span> <span class="o">=</span> <span class="n">hypo_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">hypo_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">hypo_feat</span> <span class="o">=</span> <span class="n">hypo_feat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                    <span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">hypo_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">,</span>
                    <span class="n">feat_dim</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">hypo_feat_len</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span>
            <span class="c1"># remove the sos at the beginning and eos at the end</span>
            <span class="n">feat_token_len_ratio</span> <span class="o">=</span> <span class="n">hypo_feat_len</span> <span class="o">/</span> <span class="p">(</span><span class="n">text_len</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)</span>

    <span class="c1"># --- 1.3. The 3rd Pass: denormalize the acoustic feature and transformation to waveforms --- #</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">,</span> <span class="s2">&quot;normalize&quot;</span><span class="p">):</span>
        <span class="n">hypo_feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">normalize</span><span class="o">.</span><span class="n">recover</span><span class="p">(</span><span class="n">hypo_feat</span><span class="p">,</span> <span class="n">group_ids</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">)</span>

    <span class="c1"># turn the tensor-like spk_ids (preprocessed by self.spk2idx) into a list</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">spk_ids</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">spk_ids</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">idx2spk</span><span class="p">[</span><span class="n">s_id</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="k">if</span> <span class="n">s_id</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="s2">&quot;aver_spk&quot;</span>
            <span class="k">for</span> <span class="n">s_id</span> <span class="ow">in</span> <span class="n">spk_ids</span>
        <span class="p">]</span>

    <span class="c1"># convert the acoustic features back to GL waveforms if specified</span>
    <span class="k">if</span> <span class="n">return_gl_wav</span><span class="p">:</span>
        <span class="n">hypo_wav</span><span class="p">,</span> <span class="n">hypo_wav_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">recover</span><span class="p">(</span>
            <span class="n">hypo_feat</span><span class="p">,</span> <span class="n">hypo_feat_len</span>
        <span class="p">)</span>
        <span class="c1"># remove the redundant silence parts at the end of the synthetic waveforms</span>
        <span class="n">hypo_wav</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">(</span>
                <span class="n">hypo_wav</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span> <span class="n">hypo_wav_len</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
                <span class="k">if</span> <span class="n">return_sr</span> <span class="ow">is</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">resampler</span><span class="p">(</span><span class="n">hypo_wav</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span> <span class="n">hypo_wav_len</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hypo_wav</span><span class="p">))</span>
        <span class="p">]</span>
        <span class="n">hypo_wav_len</span> <span class="o">=</span> <span class="p">[</span><span class="n">wav</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">wav</span> <span class="ow">in</span> <span class="n">hypo_wav</span><span class="p">]</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="n">gl_wav</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;wav&quot;</span><span class="p">,</span>
                <span class="n">sample_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="k">if</span> <span class="n">return_sr</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">return_sr</span><span class="p">,</span>
                <span class="n">group_ids</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">,</span>
                <span class="n">content</span><span class="o">=</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">hypo_wav</span><span class="p">,</span> <span class="n">tgt</span><span class="o">=</span><span class="s2">&quot;numpy&quot;</span><span class="p">),</span>
            <span class="p">),</span>
            <span class="n">gl_wav_len</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">hypo_wav_len</span><span class="p">)),</span>
        <span class="p">)</span>

    <span class="c1"># --- 2. Post-processing for the Generated Acoustic Features --- #</span>
    <span class="c1"># return the acoustic features if specified</span>
    <span class="k">if</span> <span class="n">return_feat</span><span class="p">:</span>
        <span class="c1"># remove the redundant silence parts at the end of the synthetic frames</span>
        <span class="n">hypo_feat</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">hypo_feat</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span> <span class="n">hypo_feat_len</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hypo_feat</span><span class="p">))</span>
        <span class="p">]</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="c1"># the sampling rate of the acoustic features remain the one of the TTS model</span>
            <span class="n">feat</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;npz&quot;</span><span class="p">,</span>
                <span class="n">sample_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span>
                <span class="n">group_ids</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">,</span>
                <span class="n">content</span><span class="o">=</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">hypo_feat</span><span class="p">,</span> <span class="n">tgt</span><span class="o">=</span><span class="s2">&quot;numpy&quot;</span><span class="p">),</span>
            <span class="p">),</span>
            <span class="n">feat_len</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">hypo_feat_len</span><span class="p">)),</span>
        <span class="p">)</span>
    <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="n">feat_token_len_ratio</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">to_cpu</span><span class="p">(</span><span class="n">feat_token_len_ratio</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># record the speaker ID used as the reference</span>
    <span class="k">if</span> <span class="n">spk_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ref_spk</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">))</span>
    <span class="c1"># record the speaker embedding ID used as the reference</span>
    <span class="k">if</span> <span class="n">spk_feat_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ref_spk_feat</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">spk_feat_ids</span><span class="p">))</span>

    <span class="c1"># evaluation reports for all the testing instances</span>
    <span class="n">instance_report_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="c1"># loop each utterance</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)):</span>
        <span class="k">if</span> <span class="s2">&quot;Feature-Token Length Ratio&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Feature-Token Length Ratio&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Feature-Token Length Ratio&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feat_token_len_ratio</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;Feature Length&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Feature Length&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Feature Length&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">hypo_feat_len</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># register the instance reports for generating instance_reports.md</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_instance_reports</span><span class="p">(</span><span class="n">md_list_dict</span><span class="o">=</span><span class="n">instance_report_dict</span><span class="p">)</span>

    <span class="c1"># add the attention matrix into the output Dict, only used for model visualization during training</span>
    <span class="c1"># because it will consume too much time for saving the attention matrices of all testing samples during testing</span>
    <span class="k">if</span> <span class="n">return_att</span><span class="p">:</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">att</span><span class="o">=</span><span class="n">hypo_att</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.ar_tts.ARTTS.module_forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">module_forward</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feat</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feat_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">spk_feat</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">spk_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_att</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>feat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch, feat_maxlen, feat_dim)
The input speech data (grouped or downsampled and edge-padded).</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>feat_len</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch,)
The lengths of input speech data</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>text</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch, text_maxlen)
The input text data with <sos/eos> at the beginning and end</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>text_len</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch,)
The lengths of input text data</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spk_feat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch, 1, speaker embedding dim)
Pre-extracted speaker embedding. (None means single-speaker TTS)</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spk_ids</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch,)
The speaker ids of each speech data. In the form of integer values.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epoch</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The number of the current training epoch.
Mainly used for mean&amp;std calculation in the feature normalization</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_att</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool
Controls whether the attention matrices of each layer in the encoder and decoder will be returned.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Temporary register used to store the redundant arguments.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="torch.Tensor">Tensor</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A dictionary containing all the TTS model outputs (feature, eos bernouli prediction) necessary to calculate the losses</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/ar_tts.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">module_forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">text</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">text_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spk_feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spk_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_att</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        feat: (batch, feat_maxlen, feat_dim)</span>
<span class="sd">            The input speech data (grouped or downsampled and edge-padded).</span>
<span class="sd">        feat_len: (batch,)</span>
<span class="sd">            The lengths of input speech data</span>
<span class="sd">        text: (batch, text_maxlen)</span>
<span class="sd">            The input text data with &lt;sos/eos&gt; at the beginning and end</span>
<span class="sd">        text_len: (batch,)</span>
<span class="sd">            The lengths of input text data</span>
<span class="sd">        spk_feat: (batch, 1, speaker embedding dim)</span>
<span class="sd">            Pre-extracted speaker embedding. (None means single-speaker TTS)</span>
<span class="sd">        spk_ids: (batch,)</span>
<span class="sd">            The speaker ids of each speech data. In the form of integer values.</span>
<span class="sd">        epoch: int</span>
<span class="sd">            The number of the current training epoch.</span>
<span class="sd">            Mainly used for mean&amp;std calculation in the feature normalization</span>
<span class="sd">        return_att: bool</span>
<span class="sd">            Controls whether the attention matrices of each layer in the encoder and decoder will be returned.</span>
<span class="sd">        kwargs:</span>
<span class="sd">            Temporary register used to store the redundant arguments.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A dictionary containing all the TTS model outputs (feature, eos bernouli prediction) necessary to calculate the losses</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># para checking</span>
    <span class="k">assert</span> <span class="n">text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">text_len</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">text</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="n">feat_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">text_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span>
        <span class="mi">0</span>
    <span class="p">),</span> <span class="s2">&quot;The amounts of utterances and sentences are not equal to each other.&quot;</span>
    <span class="k">assert</span> <span class="n">feat_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span>
        <span class="mi">0</span>
    <span class="p">),</span> <span class="s2">&quot;The amounts of utterances and their lengths are not equal to each other.&quot;</span>
    <span class="k">assert</span> <span class="n">text_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">text</span><span class="o">.</span><span class="n">size</span><span class="p">(</span>
        <span class="mi">0</span>
    <span class="p">),</span> <span class="s2">&quot;The amounts of sentences and their lengths are not equal to each other.&quot;</span>

    <span class="c1"># Encoding, we don&#39;t remove the &lt;sos/eos&gt; at the beginning and end of the sentence</span>
    <span class="n">enc_returns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">)</span>
    <span class="c1"># Transformer-based encoder additionally returns the encoder self-attention</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">enc_text</span><span class="p">,</span> <span class="n">enc_text_mask</span><span class="p">,</span> <span class="n">enc_attmat</span><span class="p">,</span> <span class="n">enc_hidden</span> <span class="o">=</span> <span class="n">enc_returns</span>
    <span class="c1"># RNN-based encoder doesn&#39;t return any attention</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="p">(</span><span class="n">enc_text</span><span class="p">,</span> <span class="n">enc_text_mask</span><span class="p">,</span> <span class="n">enc_hidden</span><span class="p">),</span> <span class="n">enc_attmat</span> <span class="o">=</span> <span class="n">enc_returns</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span>

    <span class="c1"># Decoding</span>
    <span class="n">dec_returns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
        <span class="n">enc_text</span><span class="o">=</span><span class="n">enc_text</span><span class="p">,</span>
        <span class="n">enc_text_mask</span><span class="o">=</span><span class="n">enc_text_mask</span><span class="p">,</span>
        <span class="n">feat</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span>
        <span class="n">feat_len</span><span class="o">=</span><span class="n">feat_len</span><span class="p">,</span>
        <span class="n">spk_feat</span><span class="o">=</span><span class="n">spk_feat</span><span class="p">,</span>
        <span class="n">spk_ids</span><span class="o">=</span><span class="n">spk_ids</span><span class="p">,</span>
        <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Transformer-based decoder additionally returns the decoder self-attention</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dec_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">8</span><span class="p">:</span>
        <span class="p">(</span>
            <span class="n">pred_stop</span><span class="p">,</span>
            <span class="n">pred_feat_before</span><span class="p">,</span>
            <span class="n">pred_feat_after</span><span class="p">,</span>
            <span class="n">tgt_feat</span><span class="p">,</span>
            <span class="n">tgt_feat_len</span><span class="p">,</span>
            <span class="n">dec_attmat</span><span class="p">,</span>
            <span class="n">encdec_attmat</span><span class="p">,</span>
            <span class="n">dec_hidden</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">dec_returns</span>
    <span class="c1"># RNN-based decoder only returns the encoder-decoder attention</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">dec_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">7</span><span class="p">:</span>
        <span class="p">(</span>
            <span class="n">pred_stop</span><span class="p">,</span>
            <span class="n">pred_feat_before</span><span class="p">,</span>
            <span class="n">pred_feat_after</span><span class="p">,</span>
            <span class="n">tgt_feat</span><span class="p">,</span>
            <span class="n">tgt_feat_len</span><span class="p">,</span>
            <span class="n">encdec_attmat</span><span class="p">,</span>
            <span class="n">dec_hidden</span><span class="p">,</span>
        <span class="p">),</span> <span class="n">dec_attmat</span> <span class="o">=</span> <span class="p">(</span><span class="n">dec_returns</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span>

    <span class="c1"># initialize the TTS output to be the decoder predictions</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">pred_feat_before</span><span class="o">=</span><span class="n">pred_feat_before</span><span class="p">,</span>
        <span class="n">pred_feat_after</span><span class="o">=</span><span class="n">pred_feat_after</span><span class="p">,</span>
        <span class="n">pred_stop</span><span class="o">=</span><span class="n">pred_stop</span><span class="p">,</span>
        <span class="n">tgt_feat</span><span class="o">=</span><span class="n">tgt_feat</span><span class="p">,</span>
        <span class="n">tgt_feat_len</span><span class="o">=</span><span class="n">tgt_feat_len</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">shrink_attention</span><span class="p">(</span><span class="n">input_att_list</span><span class="p">):</span>
        <span class="c1"># pick up the target attention layers</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_att_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span>
        <span class="p">):</span>
            <span class="n">input_att_list</span> <span class="o">=</span> <span class="n">input_att_list</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span> <span class="p">:]</span>
        <span class="c1"># pick up the target attention heads</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="ow">and</span> <span class="n">input_att_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span>
        <span class="p">):</span>
            <span class="n">input_att_list</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">att</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span><span class="p">]</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">input_att_list</span>
            <span class="p">]</span>
        <span class="k">return</span> <span class="n">input_att_list</span>

    <span class="c1"># return the attention results if specified</span>
    <span class="k">if</span> <span class="n">return_att</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;att_guid_loss&quot;</span><span class="p">):</span>
        <span class="c1"># encoder-decoder attention</span>
        <span class="k">if</span> <span class="s2">&quot;encdec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">:</span>
            <span class="c1"># register the encoder-decoder attention</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">att</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">encdec</span><span class="o">=</span><span class="n">shrink_attention</span><span class="p">(</span><span class="n">encdec_attmat</span><span class="p">)))</span>
        <span class="c1"># encoder self-attention</span>
        <span class="k">if</span> <span class="n">enc_attmat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;enc&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">:</span>
            <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">enc</span><span class="o">=</span><span class="n">shrink_attention</span><span class="p">(</span><span class="n">enc_attmat</span><span class="p">))</span>
        <span class="c1"># decoder self-attention</span>
        <span class="k">if</span> <span class="n">dec_attmat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;dec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">:</span>
            <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">dec</span><span class="o">=</span><span class="n">shrink_attention</span><span class="p">(</span><span class="n">dec_attmat</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.ar_tts.ARTTS.module_init" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">module_init</span><span class="p">(</span><span class="n">token_type</span><span class="p">,</span> <span class="n">token_path</span><span class="p">,</span> <span class="n">enc_emb</span><span class="p">,</span> <span class="n">enc_prenet</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">dec_prenet</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">dec_postnet</span><span class="p">,</span> <span class="n">frontend</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">spk_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">spk_emb</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">22050</span><span class="p">,</span> <span class="n">audio_format</span><span class="o">=</span><span class="s1">&#39;wav&#39;</span><span class="p">,</span> <span class="n">reduction_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stop_pos_weight</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span> <span class="n">stop_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">return_att_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_att_head_num</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">return_att_layer_num</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>frontend</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict (mandatory)
The configuration of the acoustic feature extraction frontend in the <code>ARTTSDecoder</code> member.
This argument must be given since our toolkit doesn't support time-domain TTS.
For more details about how to give <code>frontend</code>, please refer to speechain.module.encoder.ar_tts.ARTTSDecoder.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span> or bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict
The configuration of the normalization layer in the <code>ARTTSDecoder</code> member.
This argument can also be given as a bool value.
True means the default configuration and False means no normalization.
For more details about how to give <code>normalize</code>, please refer to
    speechain.module.norm.feat_norm.FeatureNormalization.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>enc_emb</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict (mandatory)
The configuration of the embedding layer in the <code>TTSEncoder</code> member.
The encoder prenet embeds the input token id into token embeddings before feeding them into
the encoder.
For more details about how to give <code>enc_emb</code>, please refer to speechain.module.encoder.tts.TTSEncoder.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>enc_prenet</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict (mandatory)
The configuration of the prenet in the <code>TTSEncoder</code> member.
The encoder prenet embeds the input token embeddings into high-level embeddings before feeding them into
the encoder.
For more details about how to give <code>enc_prent</code>, please refer to speechain.module.encoder.tts.TTSEncoder.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>encoder</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict (mandatory)
The configuration of the encoder main body in the <code>TTSEncoder</code> member.
The encoder embeds the input embeddings into the encoder representations at each time steps of the
input acoustic features.
For more details about how to give <code>encoder</code>, please refer to speechain.module.encoder.tts.TTSEncoder.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spk_emb</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict = None (conditionally mandatory)
The configuration for the <code>SPKEmbedPrenet</code> in the <code>ARTTSDecoder</code> member.
For more details about how to give <code>spk_emb</code>, please refer to
    speechain.module.prenet.spk_embed.SpeakerEmbedPrenet.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dec_prenet</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict (mandatory)
The configuration of the prenet in the <code>ARTTSDecoder</code> member.
For more details about how to give <code>dec_prenet</code>, please refer to speechain.module.encoder.ar_tts.ARTTSDecoder.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>decoder</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict (mandatory)
The configuration of the decoder main body in the <code>ARTTSDecoder</code> member.
For more details about how to give <code>decoder</code>, please refer to speechain.module.decoder.ar_tts.ARTTSDecoder.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dec_postnet</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict (mandatory)
The configuration of the postnet in the <code>ARTTSDecoder</code> member.
For more details about how to give <code>dec_postnet</code>, please refer to speechain.module.encoder.ar_tts.ARTTSDecoder.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>token_type</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(mandatory)
The type of the built-in tokenizer.
Currently, we support 'char' for <code>CharTokenizer</code> and 'phn' for <code>PhonemeTokenizer</code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>token_path</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(mandatory)
The path of the vocabulary list <code>vocab</code> for initializing the built-in tokenizer.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spk_list</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>str = None (conditionally mandatory)
The path of the speaker list that contains all the speaker ids in your training set.
If you would like to train a close-set multi-speaker TTS, you need to give a spk_list.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sample_rate</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int = 22050 (optional)
The sampling rate of the target speech.
Currently it's used for acoustic feature extraction frontend initialization and tensorboard register of
the input speech during model visualization.
In the future, this argument will also be used to dynamically downsample the input speech during training.</p>
              </div>
            </td>
            <td>
                  <code>22050</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>audio_format</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>str = 'wav' (optional)
This argument is only used for input speech recording during model visualization.</p>
              </div>
            </td>
            <td>
                  <code>&#39;wav&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>reduction_factor</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int = 1 (mandatory)
The factor that controls how much the length of output speech feature is reduced.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stop_threshold</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float = 0.5 (mandatory)
The threshold that controls whether the speech synthesis stops or not.</p>
              </div>
            </td>
            <td>
                  <code>0.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_att_type</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[str] or str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List[str] or str = 'encdec'
The type of attentions you want to return for both attention guidance and attention visualization.
It can be given as a string (one type) or a list of strings (multiple types).
The type should be one of
    1. 'encdec': the encoder-decoder attention, shared by both Transformer and RNN
    2. 'enc': the encoder self-attention, only for Transformer
    3. 'dec': the decoder self-attention, only for Transformer</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_att_head_num</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int = -1
The number of returned attention heads. If -1, all the heads in an attention layer will be returned.
RNN can be considered to one-head attention, so return_att_head_num &gt; 1 is equivalent to 1 for RNN.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_att_layer_num</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int = 1
The number of returned attention layers. If -1, all the attention layers will be returned.
RNN can be considered to one-layer attention, so return_att_layer_num &gt; 1 is equivalent to 1 for RNN.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/ar_tts.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">module_init</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">token_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">token_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">enc_emb</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">enc_prenet</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">encoder</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">dec_prenet</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">decoder</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">dec_postnet</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">frontend</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="n">Dict</span> <span class="ow">or</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">spk_list</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spk_emb</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">22050</span><span class="p">,</span>
    <span class="n">audio_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;wav&quot;</span><span class="p">,</span>
    <span class="n">reduction_factor</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">stop_pos_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5.0</span><span class="p">,</span>
    <span class="n">stop_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">return_att_type</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="ow">or</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_att_head_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">return_att_layer_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        # --- module_conf arguments --- #</span>
<span class="sd">        frontend: Dict (mandatory)</span>
<span class="sd">            The configuration of the acoustic feature extraction frontend in the `ARTTSDecoder` member.</span>
<span class="sd">            This argument must be given since our toolkit doesn&#39;t support time-domain TTS.</span>
<span class="sd">            For more details about how to give `frontend`, please refer to speechain.module.encoder.ar_tts.ARTTSDecoder.</span>
<span class="sd">        normalize: Dict</span>
<span class="sd">            The configuration of the normalization layer in the `ARTTSDecoder` member.</span>
<span class="sd">            This argument can also be given as a bool value.</span>
<span class="sd">            True means the default configuration and False means no normalization.</span>
<span class="sd">            For more details about how to give `normalize`, please refer to</span>
<span class="sd">                speechain.module.norm.feat_norm.FeatureNormalization.</span>
<span class="sd">        enc_emb: Dict (mandatory)</span>
<span class="sd">            The configuration of the embedding layer in the `TTSEncoder` member.</span>
<span class="sd">            The encoder prenet embeds the input token id into token embeddings before feeding them into</span>
<span class="sd">            the encoder.</span>
<span class="sd">            For more details about how to give `enc_emb`, please refer to speechain.module.encoder.tts.TTSEncoder.</span>
<span class="sd">        enc_prenet: Dict (mandatory)</span>
<span class="sd">            The configuration of the prenet in the `TTSEncoder` member.</span>
<span class="sd">            The encoder prenet embeds the input token embeddings into high-level embeddings before feeding them into</span>
<span class="sd">            the encoder.</span>
<span class="sd">            For more details about how to give `enc_prent`, please refer to speechain.module.encoder.tts.TTSEncoder.</span>
<span class="sd">        encoder: Dict (mandatory)</span>
<span class="sd">            The configuration of the encoder main body in the `TTSEncoder` member.</span>
<span class="sd">            The encoder embeds the input embeddings into the encoder representations at each time steps of the</span>
<span class="sd">            input acoustic features.</span>
<span class="sd">            For more details about how to give `encoder`, please refer to speechain.module.encoder.tts.TTSEncoder.</span>
<span class="sd">        spk_emb: Dict = None (conditionally mandatory)</span>
<span class="sd">            The configuration for the `SPKEmbedPrenet` in the `ARTTSDecoder` member.</span>
<span class="sd">            For more details about how to give `spk_emb`, please refer to</span>
<span class="sd">                speechain.module.prenet.spk_embed.SpeakerEmbedPrenet.</span>
<span class="sd">        dec_prenet: Dict (mandatory)</span>
<span class="sd">            The configuration of the prenet in the `ARTTSDecoder` member.</span>
<span class="sd">            For more details about how to give `dec_prenet`, please refer to speechain.module.encoder.ar_tts.ARTTSDecoder.</span>
<span class="sd">        decoder: Dict (mandatory)</span>
<span class="sd">            The configuration of the decoder main body in the `ARTTSDecoder` member.</span>
<span class="sd">            For more details about how to give `decoder`, please refer to speechain.module.decoder.ar_tts.ARTTSDecoder.</span>
<span class="sd">        dec_postnet: Dict (mandatory)</span>
<span class="sd">            The configuration of the postnet in the `ARTTSDecoder` member.</span>
<span class="sd">            For more details about how to give `dec_postnet`, please refer to speechain.module.encoder.ar_tts.ARTTSDecoder.</span>
<span class="sd">        # --- customize_conf arguments --- #</span>
<span class="sd">        token_type: (mandatory)</span>
<span class="sd">            The type of the built-in tokenizer.</span>
<span class="sd">            Currently, we support &#39;char&#39; for `CharTokenizer` and &#39;phn&#39; for `PhonemeTokenizer`.</span>
<span class="sd">        token_path: (mandatory)</span>
<span class="sd">            The path of the vocabulary list `vocab` for initializing the built-in tokenizer.</span>
<span class="sd">        spk_list: str = None (conditionally mandatory)</span>
<span class="sd">            The path of the speaker list that contains all the speaker ids in your training set.</span>
<span class="sd">            If you would like to train a close-set multi-speaker TTS, you need to give a spk_list.</span>
<span class="sd">        sample_rate: int = 22050 (optional)</span>
<span class="sd">            The sampling rate of the target speech.</span>
<span class="sd">            Currently it&#39;s used for acoustic feature extraction frontend initialization and tensorboard register of</span>
<span class="sd">            the input speech during model visualization.</span>
<span class="sd">            In the future, this argument will also be used to dynamically downsample the input speech during training.</span>
<span class="sd">        audio_format: str = &#39;wav&#39; (optional)</span>
<span class="sd">            This argument is only used for input speech recording during model visualization.</span>
<span class="sd">        reduction_factor: int = 1 (mandatory)</span>
<span class="sd">            The factor that controls how much the length of output speech feature is reduced.</span>
<span class="sd">        stop_threshold: float = 0.5 (mandatory)</span>
<span class="sd">            The threshold that controls whether the speech synthesis stops or not.</span>
<span class="sd">        return_att_type: List[str] or str = &#39;encdec&#39;</span>
<span class="sd">            The type of attentions you want to return for both attention guidance and attention visualization.</span>
<span class="sd">            It can be given as a string (one type) or a list of strings (multiple types).</span>
<span class="sd">            The type should be one of</span>
<span class="sd">                1. &#39;encdec&#39;: the encoder-decoder attention, shared by both Transformer and RNN</span>
<span class="sd">                2. &#39;enc&#39;: the encoder self-attention, only for Transformer</span>
<span class="sd">                3. &#39;dec&#39;: the decoder self-attention, only for Transformer</span>
<span class="sd">        return_att_head_num: int = -1</span>
<span class="sd">            The number of returned attention heads. If -1, all the heads in an attention layer will be returned.</span>
<span class="sd">            RNN can be considered to one-head attention, so return_att_head_num &gt; 1 is equivalent to 1 for RNN.</span>
<span class="sd">        return_att_layer_num: int = 1</span>
<span class="sd">            The number of returned attention layers. If -1, all the attention layers will be returned.</span>
<span class="sd">            RNN can be considered to one-layer attention, so return_att_layer_num &gt; 1 is equivalent to 1 for RNN.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># --- 1. Model-Customized Part Initialization --- #</span>
    <span class="c1"># initialize the tokenizer</span>
    <span class="k">if</span> <span class="n">token_type</span> <span class="o">==</span> <span class="s2">&quot;char&quot;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">CharTokenizer</span><span class="p">(</span><span class="n">token_path</span><span class="p">,</span> <span class="n">copy_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">token_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;g2p&quot;</span><span class="p">,</span> <span class="s2">&quot;mfa&quot;</span><span class="p">]:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">GraphemeToPhonemeTokenizer</span><span class="p">(</span>
            <span class="n">token_path</span><span class="p">,</span> <span class="n">copy_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unknown token type </span><span class="si">{</span><span class="n">token_type</span><span class="si">}</span><span class="s2">. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Currently, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> supports one of [&#39;char&#39;, &#39;g2p&#39;].&quot;</span>
        <span class="p">)</span>

    <span class="c1"># initialize the speaker list if given</span>
    <span class="k">if</span> <span class="n">spk_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">spk_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">parse_path_args</span><span class="p">(</span><span class="n">spk_list</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
        <span class="c1"># when the input file is idx2spk, only retain the column of speaker ids</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">spk_list</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">spk_list</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
            <span class="n">spk_list</span> <span class="o">=</span> <span class="n">spk_list</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="c1"># otherwise, the input file must be spk_list which is a single-column file and each row is a speaker id</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">spk_list</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span>
        <span class="c1"># 1. remove redundant elements; 2. sort up the speaker ids in order</span>
        <span class="n">spk_list</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">spk_list</span><span class="p">))</span>
        <span class="c1"># 3. get the corresponding indices (start from 1 since 0 is reserved for unknown speakers)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idx2spk</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">spk_list</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">spk_list</span><span class="p">))</span>
        <span class="c1"># 4. exchange the positions of indices and speaker ids</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spk2idx</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">reversed</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx2spk</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>

    <span class="c1"># initialize the sampling rate, mainly used for visualizing the input audio during training</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">audio_format</span> <span class="o">=</span> <span class="n">audio_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span> <span class="o">=</span> <span class="n">reduction_factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stop_pos_weight</span> <span class="o">=</span> <span class="n">stop_pos_weight</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stop_threshold</span> <span class="o">=</span> <span class="n">stop_threshold</span>

    <span class="k">if</span> <span class="n">return_att_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;encdec&quot;</span><span class="p">,</span> <span class="s2">&quot;enc&quot;</span><span class="p">,</span> <span class="s2">&quot;dec&quot;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">return_att_type</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">return_att_type</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span>
            <span class="k">else</span> <span class="p">[</span><span class="n">return_att_type</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">)):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;enc&quot;</span><span class="p">,</span> <span class="s2">&quot;dec&quot;</span><span class="p">,</span> <span class="s2">&quot;encdec&quot;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The elements of your input return_att_type must be one of [&#39;enc&#39;, &#39;dec&#39;, &#39;encdec&#39;], &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">!&quot;</span>
            <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span> <span class="o">=</span> <span class="n">return_att_head_num</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span> <span class="o">=</span> <span class="n">return_att_layer_num</span>

    <span class="c1"># --- 2. Module Part Construction --- #</span>
    <span class="c1"># --- 2.1. Encoder construction --- #</span>
    <span class="c1"># the vocabulary size is given by the built-in tokenizer instead of the input configuration</span>
    <span class="k">if</span> <span class="s2">&quot;vocab_size&quot;</span> <span class="ow">in</span> <span class="n">enc_emb</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">enc_emb</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">][</span><span class="s2">&quot;vocab_size&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Your input vocabulary size is different from the one obtained from the built-in &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;tokenizer (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2">). The latter one will be used to initialize the &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;encoder for correctness.&quot;</span>
            <span class="p">)</span>
        <span class="n">enc_emb</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;vocab_size&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">TTSEncoder</span><span class="p">(</span>
        <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
        <span class="n">embedding</span><span class="o">=</span><span class="n">enc_emb</span><span class="p">,</span>
        <span class="n">prenet</span><span class="o">=</span><span class="n">enc_prenet</span><span class="p">,</span>
        <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># --- 2.2. Decoder construction --- #</span>
    <span class="c1"># check the sampling rate of the decoder frontend</span>
    <span class="k">if</span> <span class="s2">&quot;sr&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">frontend</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">frontend</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">][</span><span class="s2">&quot;sr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span>
    <span class="c1"># update the sampling rate into the TTS Model object</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">frontend</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">][</span><span class="s2">&quot;sr&quot;</span><span class="p">]</span>

    <span class="c1"># check the speaker embedding configuration</span>
    <span class="k">if</span> <span class="n">spk_emb</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># speaker number for the close-set multi-speaker TTS</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;spk2idx&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="s2">&quot;spk_num&quot;</span> <span class="ow">in</span> <span class="n">spk_emb</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                <span class="ow">and</span> <span class="n">spk_emb</span><span class="p">[</span><span class="s2">&quot;spk_num&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spk2idx</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="p">):</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;Your input spk_num is different from the number of speakers in your given spk_list. &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;Currently, the spk_num is set to </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spk2idx</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="c1"># all seen speakers plus an unknown speaker (ID: 0)</span>
            <span class="n">spk_emb</span><span class="p">[</span><span class="s2">&quot;spk_num&quot;</span><span class="p">],</span> <span class="n">spk_emb</span><span class="p">[</span><span class="s2">&quot;use_lookup&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spk2idx</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="s2">&quot;use_lookup&quot;</span> <span class="ow">in</span> <span class="n">spk_emb</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">spk_emb</span><span class="p">[</span><span class="s2">&quot;use_lookup&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Please give spk_list in model[&#39;customize_conf&#39;] if you want to use speaker lookup &quot;</span>
                <span class="s2">&quot;table for close-set multi-speaker TTS.&quot;</span>
            <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">ARTTSDecoder</span><span class="p">(</span>
        <span class="n">spk_emb</span><span class="o">=</span><span class="n">spk_emb</span><span class="p">,</span>
        <span class="n">frontend</span><span class="o">=</span><span class="n">frontend</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span>
        <span class="n">prenet</span><span class="o">=</span><span class="n">dec_prenet</span><span class="p">,</span>
        <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
        <span class="n">postnet</span><span class="o">=</span><span class="n">dec_postnet</span><span class="p">,</span>
        <span class="n">distributed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span>
        <span class="n">reduction_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction_factor</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="model.ar_tts.MultiDomainARTTS" class="doc doc-heading">
            <code>MultiDomainARTTS</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="model.ar_tts.ARTTS" href="#model.ar_tts.ARTTS">ARTTS</a></code></p>


        <p>Auto-Regressive TTS model trained by multiple dataloaders on different domains.</p>






              <details class="quote">
                <summary>Source code in <code>speechain/model/ar_tts.py</code></summary>
                <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MultiDomainARTTS</span><span class="p">(</span><span class="n">ARTTS</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Auto-Regressive TTS model trained by multiple dataloaders on different domains.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">criterion_init</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">loss_weights</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feat_loss</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">stop_loss</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">att_guid_loss</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="c1"># register the weight for each loss if loss_weights is given</span>
        <span class="k">if</span> <span class="n">loss_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">loss_name</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">loss_weights</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">weight</span> <span class="o">&lt;</span> <span class="mi">1</span>
                <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Your input weight should be a float number in (0, 1), but got loss_weights[</span><span class="si">{</span><span class="n">loss_name</span><span class="si">}</span><span class="s2">]=</span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">!&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="p">[</span><span class="n">loss_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight</span>

        <span class="k">def</span> <span class="nf">recur_init_loss_by_dict</span><span class="p">(</span><span class="n">loss_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">loss_class</span><span class="p">):</span>
            <span class="n">leaf_num</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="p">[</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">loss_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
            <span class="p">)</span>
            <span class="c1"># all the items in loss_dict are not Dict mean that the loss function is shared by all the dataloaders</span>
            <span class="k">if</span> <span class="n">leaf_num</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_dict</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">loss_class</span><span class="p">(</span><span class="o">**</span><span class="n">loss_dict</span><span class="p">)</span>
            <span class="c1"># no item in loss_dict is Dict mean that each dataloader has its own loss function</span>
            <span class="k">elif</span> <span class="n">leaf_num</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;loss_weights&quot;</span><span class="p">):</span>
                    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_dict</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span>
                    <span class="p">),</span> <span class="s2">&quot;The key number in the xxx_loss should match the one in the loss_weights&quot;</span>

                <span class="n">nested_loss</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">conf</span> <span class="ow">in</span> <span class="n">loss_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;loss_weights&quot;</span><span class="p">):</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;The key name </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> doesn&#39;t match anyone in the loss_weights!&quot;</span>
                    <span class="n">nested_loss</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_class</span><span class="p">(</span><span class="o">**</span><span class="n">conf</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">nested_loss</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Your loss configuration must be either Dict[str, Any] or Dict[str, Dict[str, Any]]&quot;</span>
                <span class="p">)</span>

        <span class="c1"># feature loss will be initialized no matter whether feat_loss is given or not</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feat_loss</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">recur_init_loss_by_dict</span><span class="p">(</span><span class="n">feat_loss</span><span class="p">,</span> <span class="n">LeastError</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">feat_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">LeastError</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># stop loss will be initialized no matter whether stop_loss is given or not</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_loss</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">recur_init_loss_by_dict</span><span class="p">(</span><span class="n">stop_loss</span><span class="p">,</span> <span class="n">BCELogits</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">stop_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">BCELogits</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># only initialize attention-guidance loss if it is given</span>
        <span class="k">if</span> <span class="n">att_guid_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="s2">&quot;encdec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span>
            <span class="p">),</span> <span class="s2">&quot;If you want to enable attention guidance for ASR training, please include &#39;encdec&#39; in return_att_type.&quot;</span>

            <span class="c1"># if att_guid_loss is given as True, the default arguments of AttentionGuidance will be used</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="n">att_guid_loss</span>
                <span class="p">),</span> <span class="s2">&quot;If you want to use the default setting of AttentionGuidance, please give att_guid_loss as True.&quot;</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span> <span class="o">=</span> <span class="n">recur_init_loss_by_dict</span><span class="p">(</span>
                    <span class="n">att_guid_loss</span><span class="p">,</span> <span class="n">AttentionGuidance</span>
                <span class="p">)</span>
            <span class="c1"># att_guid_loss is True, intialize the default AttentionGuidance criterion</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span> <span class="o">=</span> <span class="n">AttentionGuidance</span><span class="p">()</span>

        <span class="c1"># validation metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_accuracy</span> <span class="o">=</span> <span class="n">Accuracy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_fbeta</span> <span class="o">=</span> <span class="n">FBetaScore</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">module_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">batch_data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            **batch_data:</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># whether the input batch_data is generated by multiple dataloaders</span>
        <span class="n">multi_flag</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
        <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>

        <span class="c1"># Single-dataloader scenario</span>
        <span class="c1"># probably for the validation stage of in-domain semi-supervised ASR where we only have one data-label pair</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">multi_flag</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDomainARTTS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">module_forward</span><span class="p">(</span><span class="o">**</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="c1"># Multi-dataloader scenario</span>
        <span class="c1"># For semi-supervised training or validation of out-domain semi-supervised ASR where we may have multiple</span>
        <span class="c1"># data-label pairs in a single batch, we need to go through forward function once for each pair.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># pop the non-Dict arguments from the input batch data</span>
            <span class="n">general_args</span><span class="p">,</span> <span class="n">data_keys</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(),</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch_data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">data_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_data</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">Dict</span><span class="p">):</span>
                    <span class="n">general_args</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

            <span class="c1"># otherwise, go through the normal training process once for all the sub-batches</span>
            <span class="c1"># (each sub-batch corresponds to a dataloader)</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="n">domain</span><span class="p">:</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDomainARTTS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">module_forward</span><span class="p">(</span>
                    <span class="n">domain</span><span class="o">=</span><span class="n">domain</span><span class="p">,</span> <span class="o">**</span><span class="n">general_args</span><span class="p">,</span> <span class="o">**</span><span class="n">domain_data</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">domain</span><span class="p">,</span> <span class="n">domain_data</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>

    <span class="k">def</span> <span class="nf">criterion_forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">data_output_dict</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            **data_output_dict:</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># whether the input data_output_dict is generated by multiple dataloaders</span>
        <span class="n">multi_flag</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data_output_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
        <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_output_dict</span><span class="p">)</span>

        <span class="c1"># Single-dataloader scenario</span>
        <span class="c1"># probably for the validation stage of in-domain semi-supervised ASR where we only have one data-label pair</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">multi_flag</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDomainARTTS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span><span class="o">**</span><span class="n">data_output_dict</span><span class="p">)</span>
        <span class="c1"># Multi-dataloader scenario</span>
        <span class="c1"># For semi-supervised training or validation of out-domain semi-supervised ASR where we may have multiple</span>
        <span class="c1"># data-label pairs in a single batch, we need to go through forward function once for each pair.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">domain_list</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(),</span> <span class="nb">dict</span><span class="p">(),</span> <span class="nb">list</span><span class="p">(</span><span class="n">data_output_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span><span class="p">:</span>
                <span class="c1"># initialize the feature loss function</span>
                <span class="n">feat_loss_fn</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">feat_loss</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feat_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">feat_loss</span>
                <span class="p">)</span>
                <span class="c1"># initialize the stop loss function</span>
                <span class="n">stop_loss_fn</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">stop_loss</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stop_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_loss</span>
                <span class="p">)</span>
                <span class="c1"># initialize the attention-guidance loss function only if att_guid_loss is created</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;att_guid_loss&quot;</span><span class="p">):</span>
                    <span class="n">att_guid_loss_fn</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span>
                        <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">att_guid_loss_fn</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="c1"># call the criterion_forward() of the parent class by the initialized loss functions</span>
                <span class="n">_criteria</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDomainARTTS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span>
                    <span class="n">feat_loss_fn</span><span class="o">=</span><span class="n">feat_loss_fn</span><span class="p">,</span>
                    <span class="n">stop_loss_fn</span><span class="o">=</span><span class="n">stop_loss_fn</span><span class="p">,</span>
                    <span class="n">att_guid_loss_fn</span><span class="o">=</span><span class="n">att_guid_loss_fn</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">data_output_dict</span><span class="p">[</span><span class="n">domain</span><span class="p">],</span>
                <span class="p">)</span>

                <span class="c1"># update loss and metric Dicts during training</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                    <span class="c1"># update the losses and metrics Dicts by the domain name at the beginning</span>
                    <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="o">**</span><span class="p">{</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">_key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">_value</span>
                            <span class="k">for</span> <span class="n">_key</span><span class="p">,</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">_criteria</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                    <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="o">**</span><span class="p">{</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">_key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">_value</span>
                            <span class="k">for</span> <span class="n">_key</span><span class="p">,</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">_criteria</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                <span class="c1"># only update metric Dict during validation</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="o">**</span><span class="p">{</span>
                            <span class="p">(</span>
                                <span class="n">_key</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">domain_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">_key</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="p">):</span> <span class="n">_value</span>
                            <span class="k">for</span> <span class="n">_key</span><span class="p">,</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">_criteria</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                        <span class="p">}</span>
                    <span class="p">)</span>

            <span class="c1"># calculate the overall weighted loss during training</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="c1"># normalize losses of all the domains by the given loss_weights</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;loss_weights&quot;</span><span class="p">):</span>
                    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                        <span class="n">domain_list</span>
                    <span class="p">),</span> <span class="s2">&quot;There is a number mismatch of the domains between your data_cfg and train_cfg.&quot;</span>
                    <span class="k">assert</span> <span class="nb">sum</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">domain</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span><span class="p">]</span>
                    <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                        <span class="n">domain_list</span>
                    <span class="p">),</span> <span class="s2">&quot;There is a name mismatch of the domains between your data_cfg and train_cfg.&quot;</span>
                    <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="n">loss</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span>
                            <span class="p">[</span>
                                <span class="n">losses</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_loss&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span>
                                <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span>
                            <span class="p">]</span>
                        <span class="p">)</span>
                        <span class="o">/</span> <span class="nb">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span> <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span><span class="p">])</span>
                    <span class="p">)</span>
                <span class="c1"># average losses of all the domains if loss_weights is not given</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="n">loss</span><span class="o">=</span><span class="nb">sum</span><span class="p">([</span><span class="n">losses</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_loss&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span><span class="p">])</span>
                        <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">domain_list</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">metrics</span>

    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">infer_conf</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="o">**</span><span class="n">test_batch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            infer_conf:</span>
<span class="sd">            **test_batch:</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">multi_flag</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
        <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span>
        <span class="c1"># no sub-Dict means one normal supervised dataloader, go through the inference function of ASR</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">multi_flag</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDomainARTTS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span>
                <span class="n">infer_conf</span><span class="o">=</span><span class="n">infer_conf</span><span class="p">,</span> <span class="o">**</span><span class="n">test_batch</span>
            <span class="p">)</span>

        <span class="c1"># sub-Dict means that the domain information is given for ASR inference</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="p">),</span> <span class="s2">&quot;If you want to evaluate the ASR model by multiple domains, please evaluate them one by one.&quot;</span>
            <span class="k">for</span> <span class="n">domain</span><span class="p">,</span> <span class="n">domain_batch</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDomainARTTS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span>
                    <span class="n">infer_conf</span><span class="o">=</span><span class="n">infer_conf</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">domain</span><span class="p">,</span> <span class="o">**</span><span class="n">domain_batch</span>
                <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="model.ar_tts.MultiDomainARTTS.criterion_forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">criterion_forward</span><span class="p">(</span><span class="o">**</span><span class="n">data_output_dict</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>**data_output_dict</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Returns:</p>

            <details class="quote">
              <summary>Source code in <code>speechain/model/ar_tts.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">criterion_forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">data_output_dict</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        **data_output_dict:</span>

<span class="sd">    Returns:</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># whether the input data_output_dict is generated by multiple dataloaders</span>
    <span class="n">multi_flag</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
        <span class="p">[</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data_output_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
    <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_output_dict</span><span class="p">)</span>

    <span class="c1"># Single-dataloader scenario</span>
    <span class="c1"># probably for the validation stage of in-domain semi-supervised ASR where we only have one data-label pair</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">multi_flag</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDomainARTTS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span><span class="o">**</span><span class="n">data_output_dict</span><span class="p">)</span>
    <span class="c1"># Multi-dataloader scenario</span>
    <span class="c1"># For semi-supervised training or validation of out-domain semi-supervised ASR where we may have multiple</span>
    <span class="c1"># data-label pairs in a single batch, we need to go through forward function once for each pair.</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">domain_list</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(),</span> <span class="nb">dict</span><span class="p">(),</span> <span class="nb">list</span><span class="p">(</span><span class="n">data_output_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span><span class="p">:</span>
            <span class="c1"># initialize the feature loss function</span>
            <span class="n">feat_loss_fn</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">feat_loss</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feat_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span>
                <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">feat_loss</span>
            <span class="p">)</span>
            <span class="c1"># initialize the stop loss function</span>
            <span class="n">stop_loss_fn</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stop_loss</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stop_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span>
                <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_loss</span>
            <span class="p">)</span>
            <span class="c1"># initialize the attention-guidance loss function only if att_guid_loss is created</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;att_guid_loss&quot;</span><span class="p">):</span>
                <span class="n">att_guid_loss_fn</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">att_guid_loss_fn</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># call the criterion_forward() of the parent class by the initialized loss functions</span>
            <span class="n">_criteria</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDomainARTTS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span>
                <span class="n">feat_loss_fn</span><span class="o">=</span><span class="n">feat_loss_fn</span><span class="p">,</span>
                <span class="n">stop_loss_fn</span><span class="o">=</span><span class="n">stop_loss_fn</span><span class="p">,</span>
                <span class="n">att_guid_loss_fn</span><span class="o">=</span><span class="n">att_guid_loss_fn</span><span class="p">,</span>
                <span class="o">**</span><span class="n">data_output_dict</span><span class="p">[</span><span class="n">domain</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="c1"># update loss and metric Dicts during training</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="c1"># update the losses and metrics Dicts by the domain name at the beginning</span>
                <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="o">**</span><span class="p">{</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">_key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">_value</span>
                        <span class="k">for</span> <span class="n">_key</span><span class="p">,</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">_criteria</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                    <span class="p">}</span>
                <span class="p">)</span>
                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="o">**</span><span class="p">{</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">_key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">_value</span>
                        <span class="k">for</span> <span class="n">_key</span><span class="p">,</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">_criteria</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                    <span class="p">}</span>
                <span class="p">)</span>
            <span class="c1"># only update metric Dict during validation</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="o">**</span><span class="p">{</span>
                        <span class="p">(</span>
                            <span class="n">_key</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">domain_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">_key</span><span class="si">}</span><span class="s2">&quot;</span>
                        <span class="p">):</span> <span class="n">_value</span>
                        <span class="k">for</span> <span class="n">_key</span><span class="p">,</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">_criteria</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                    <span class="p">}</span>
                <span class="p">)</span>

        <span class="c1"># calculate the overall weighted loss during training</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="c1"># normalize losses of all the domains by the given loss_weights</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;loss_weights&quot;</span><span class="p">):</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                    <span class="n">domain_list</span>
                <span class="p">),</span> <span class="s2">&quot;There is a number mismatch of the domains between your data_cfg and train_cfg.&quot;</span>
                <span class="k">assert</span> <span class="nb">sum</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">domain</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span><span class="p">]</span>
                <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                    <span class="n">domain_list</span>
                <span class="p">),</span> <span class="s2">&quot;There is a name mismatch of the domains between your data_cfg and train_cfg.&quot;</span>
                <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="n">loss</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="n">losses</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_loss&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span>
                            <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span>
                        <span class="p">]</span>
                    <span class="p">)</span>
                    <span class="o">/</span> <span class="nb">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span> <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span><span class="p">])</span>
                <span class="p">)</span>
            <span class="c1"># average losses of all the domains if loss_weights is not given</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="n">loss</span><span class="o">=</span><span class="nb">sum</span><span class="p">([</span><span class="n">losses</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_loss&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span><span class="p">])</span>
                    <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">domain_list</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">metrics</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.ar_tts.MultiDomainARTTS.inference" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inference</span><span class="p">(</span><span class="n">infer_conf</span><span class="p">,</span> <span class="o">**</span><span class="n">test_batch</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>infer_conf</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>**test_batch</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Returns:</p>

            <details class="quote">
              <summary>Source code in <code>speechain/model/ar_tts.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">infer_conf</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="o">**</span><span class="n">test_batch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        infer_conf:</span>
<span class="sd">        **test_batch:</span>

<span class="sd">    Returns:</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">multi_flag</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
        <span class="p">[</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
    <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span>
    <span class="c1"># no sub-Dict means one normal supervised dataloader, go through the inference function of ASR</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">multi_flag</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDomainARTTS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span>
            <span class="n">infer_conf</span><span class="o">=</span><span class="n">infer_conf</span><span class="p">,</span> <span class="o">**</span><span class="n">test_batch</span>
        <span class="p">)</span>

    <span class="c1"># sub-Dict means that the domain information is given for ASR inference</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="p">),</span> <span class="s2">&quot;If you want to evaluate the ASR model by multiple domains, please evaluate them one by one.&quot;</span>
        <span class="k">for</span> <span class="n">domain</span><span class="p">,</span> <span class="n">domain_batch</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDomainARTTS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span>
                <span class="n">infer_conf</span><span class="o">=</span><span class="n">infer_conf</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">domain</span><span class="p">,</span> <span class="o">**</span><span class="n">domain_batch</span>
            <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.ar_tts.MultiDomainARTTS.module_forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">module_forward</span><span class="p">(</span><span class="o">**</span><span class="n">batch_data</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>**batch_data</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Returns:</p>

            <details class="quote">
              <summary>Source code in <code>speechain/model/ar_tts.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">module_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">batch_data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        **batch_data:</span>

<span class="sd">    Returns:</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># whether the input batch_data is generated by multiple dataloaders</span>
    <span class="n">multi_flag</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
        <span class="p">[</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
    <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>

    <span class="c1"># Single-dataloader scenario</span>
    <span class="c1"># probably for the validation stage of in-domain semi-supervised ASR where we only have one data-label pair</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">multi_flag</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDomainARTTS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">module_forward</span><span class="p">(</span><span class="o">**</span><span class="n">batch_data</span><span class="p">)</span>
    <span class="c1"># Multi-dataloader scenario</span>
    <span class="c1"># For semi-supervised training or validation of out-domain semi-supervised ASR where we may have multiple</span>
    <span class="c1"># data-label pairs in a single batch, we need to go through forward function once for each pair.</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># pop the non-Dict arguments from the input batch data</span>
        <span class="n">general_args</span><span class="p">,</span> <span class="n">data_keys</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(),</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch_data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">data_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_data</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">Dict</span><span class="p">):</span>
                <span class="n">general_args</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="c1"># otherwise, go through the normal training process once for all the sub-batches</span>
        <span class="c1"># (each sub-batch corresponds to a dataloader)</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">domain</span><span class="p">:</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDomainARTTS</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">module_forward</span><span class="p">(</span>
                <span class="n">domain</span><span class="o">=</span><span class="n">domain</span><span class="p">,</span> <span class="o">**</span><span class="n">general_args</span><span class="p">,</span> <span class="o">**</span><span class="n">domain_data</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">domain</span><span class="p">,</span> <span class="n">domain_data</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>