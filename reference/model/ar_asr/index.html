
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Documentation for Speechain Toolkit">
      
      
      
      
        <link rel="prev" href="../abs/">
      
      
        <link rel="next" href="../ar_tts/">
      
      
      <link rel="icon" href="../../../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.49">
    
    
      
        <title>ar_asr - Speechain</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../css/code_select.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#model.ar_asr" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Speechain" class="md-header__button md-logo" aria-label="Speechain" data-md-component="logo">
      
  <img src="../../../img/speechain_inverted.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Speechain
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ar_asr
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/bagustris/speechain" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Speechain" class="md-nav__button md-logo" aria-label="Speechain" data-md-component="logo">
      
  <img src="../../../img/speechain_inverted.png" alt="logo">

    </a>
    Speechain
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/bagustris/speechain" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../recipes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recipes
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ASR
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TTS
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../handbook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Handbook
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../criterion/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    criterion
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_1" id="__nav_7_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_1">
            <span class="md-nav__icon md-icon"></span>
            criterion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/accuracy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    accuracy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/att_guid/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    att_guid
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/bce_logits/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bce_logits
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/cross_entropy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cross_entropy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/ctc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctc
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/error_rate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    error_rate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/fbeta_score/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    fbeta_score
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/least_error/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    least_error
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/perplexity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    perplexity
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../dataset/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    dataset
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_2">
            <span class="md-nav__icon md-icon"></span>
            dataset
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/speech_text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_text
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../infer_func/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    infer_func
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_3" id="__nav_7_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_3">
            <span class="md-nav__icon md-icon"></span>
            infer_func
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../infer_func/beam_search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam_search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../infer_func/ctc_decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctc_decoding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../infer_func/tts_decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tts_decoding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../iterator/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    iterator
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_4" id="__nav_7_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_4">
            <span class="md-nav__icon md-icon"></span>
            iterator
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../iterator/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../iterator/block/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    block
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_5" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    model
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_5" id="__nav_7_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7_5">
            <span class="md-nav__icon md-icon"></span>
            model
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    ar_asr
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    ar_asr
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#model.ar_asr" class="md-nav__link">
    <span class="md-ellipsis">
      ar_asr
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model.ar_asr.ARASR" class="md-nav__link">
    <span class="md-ellipsis">
      ARASR
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ARASR">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model.ar_asr.ARASR.criterion_init" class="md-nav__link">
    <span class="md-ellipsis">
      criterion_init
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_asr.ARASR.inference" class="md-nav__link">
    <span class="md-ellipsis">
      inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_asr.ARASR.module_forward" class="md-nav__link">
    <span class="md-ellipsis">
      module_forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_asr.ARASR.module_init" class="md-nav__link">
    <span class="md-ellipsis">
      module_init
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model.ar_asr.MultiDataLoaderARASR" class="md-nav__link">
    <span class="md-ellipsis">
      MultiDataLoaderARASR
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_tts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    lm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../nar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nar_tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    module
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6" id="__nav_7_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6">
            <span class="md-nav__icon md-icon"></span>
            module
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/augment/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    augment
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_2" id="__nav_7_6_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_2">
            <span class="md-nav__icon md-icon"></span>
            augment
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/augment/specaug/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    specaug
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/conformer/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    conformer
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_3" id="__nav_7_6_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_3">
            <span class="md-nav__icon md-icon"></span>
            conformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/conformer/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/conformer/encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/conformer/pos_enc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pos_enc
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/decoder/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    decoder
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_4" id="__nav_7_6_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_4">
            <span class="md-nav__icon md-icon"></span>
            decoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/decoder/ar_asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/decoder/ar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_tts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/decoder/nar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nar_tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/encoder/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    encoder
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_5" id="__nav_7_6_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_5">
            <span class="md-nav__icon md-icon"></span>
            encoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/speaker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speaker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/test_speaker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    test_speaker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/frontend/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    frontend
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_6" id="__nav_7_6_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_6">
            <span class="md-nav__icon md-icon"></span>
            frontend
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/delta_feat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    delta_feat
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/linear2mel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear2mel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/speech2linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech2linear
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/speech2mel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech2mel
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/norm/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    norm
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_7" id="__nav_7_6_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_7">
            <span class="md-nav__icon md-icon"></span>
            norm
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/norm/feat_norm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feat_norm
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/postnet/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    postnet
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_8" id="__nav_7_6_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_8">
            <span class="md-nav__icon md-icon"></span>
            postnet
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/postnet/conv1d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv1d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/postnet/token/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    token
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_9" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/prenet/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    prenet
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_9" id="__nav_7_6_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_9">
            <span class="md-nav__icon md-icon"></span>
            prenet
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/conv1d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv1d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/conv2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv2d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/embed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    embed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/spk_embed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    spk_embed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/var_pred/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    var_pred
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_10" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/standalone/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    standalone
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_10" id="__nav_7_6_10_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_10">
            <span class="md-nav__icon md-icon"></span>
            standalone
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/standalone/lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    lm
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_11" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/transformer/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    transformer
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_11" id="__nav_7_6_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_11">
            <span class="md-nav__icon md-icon"></span>
            transformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    decoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/feed_forward/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feed_forward
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/pos_enc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pos_enc
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_12" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/vocoder/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    vocoder
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_12" id="__nav_7_6_12_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_12">
            <span class="md-nav__icon md-icon"></span>
            vocoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/vocoder/hifigan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hifigan
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/vocoder/test_hifigan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    test_hifigan
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../monitor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    monitor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../optim_sche/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    optim_sche
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_8" id="__nav_7_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_8">
            <span class="md-nav__icon md-icon"></span>
            optim_sche
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optim_sche/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optim_sche/exp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    exp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optim_sche/noam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    noam
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_9" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../pyscripts/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    pyscripts
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_9" id="__nav_7_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_9">
            <span class="md-nav__icon md-icon"></span>
            pyscripts
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/empty_file_checker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    empty_file_checker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/folder_summarizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    folder_summarizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/model_para_renamer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    model_para_renamer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/phn_duaration_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phn_duaration_visualizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/text_dist_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_dist_visualizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/wavlen_dist_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wavlen_dist_visualizer
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../runner/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    runner
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../snapshooter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    snapshooter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_12" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../tokenizer/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    tokenizer
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_12" id="__nav_7_12_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_12">
            <span class="md-nav__icon md-icon"></span>
            tokenizer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/char/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    char
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/g2p/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    g2p
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/sp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sp
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_13" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../utilbox/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    utilbox
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_13" id="__nav_7_13_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_13">
            <span class="md-nav__icon md-icon"></span>
            utilbox
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/data_loading_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_loading_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/data_saving_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_saving_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/dump_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    dump_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/eval_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    eval_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/feat_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feat_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/humanfriendly/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    humanfriendly
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/import_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    import_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/log_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    log_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/md_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    md_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/regex_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    regex_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/sb_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sb_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/spk_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    spk_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/tensor_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tensor_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/test_humanfriendly/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    test_humanfriendly
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/text_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/train_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    train_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/type_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    type_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/yaml_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    yaml_util
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#model.ar_asr" class="md-nav__link">
    <span class="md-ellipsis">
      ar_asr
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model.ar_asr.ARASR" class="md-nav__link">
    <span class="md-ellipsis">
      ARASR
    </span>
  </a>
  
    <nav class="md-nav" aria-label="ARASR">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#model.ar_asr.ARASR.criterion_init" class="md-nav__link">
    <span class="md-ellipsis">
      criterion_init
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_asr.ARASR.inference" class="md-nav__link">
    <span class="md-ellipsis">
      inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_asr.ARASR.module_forward" class="md-nav__link">
    <span class="md-ellipsis">
      module_forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#model.ar_asr.ARASR.module_init" class="md-nav__link">
    <span class="md-ellipsis">
      module_init
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model.ar_asr.MultiDataLoaderARASR" class="md-nav__link">
    <span class="md-ellipsis">
      MultiDataLoaderARASR
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>ar_asr</h1>

<div class="doc doc-object doc-module">



<a id="model.ar_asr"></a>
    <div class="doc doc-contents first">

        <p>Author: Heli Qi
Affiliation: NAIST
Date: 2022.07</p>








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="model.ar_asr.ARASR" class="doc doc-heading">
            <code>ARASR</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="speechain.model.abs.Model">Model</span></code></p>


        <p>Auto-Regressive Attention-based Automatic Speech Recognition (AR-ASR) implementation.</p>
<p>The neural network structure of an <code>ASR</code> Model object is made up of 3 Module members:</p>
<ol>
<li>
<p>an <code>ASREncoder</code> made up of:</p>
<ol>
<li><code>frontend</code> converts the  raw waveforms into acoustic features on-the-fly.</li>
<li><code>normalize</code> normalizes the extracted acoustic features to normal distribution for faster convergence.</li>
<li><code>specaug</code> randomly warps and masks the normalized acoustic features.</li>
<li><code>prenet</code> preprocesses the augmented acoustic features before passing them to the encoder.</li>
<li><code>encoder</code> extracts the encoder hidden representations of the preprocessed acoustic features and passes them
    to <code>ARASRDecoder</code>.</li>
</ol>
</li>
<li>
<p>an <code>ARASRDecoder</code> made up of:</p>
<ol>
<li><code>embedding</code> embeds each tokens in the input sentence into token embedding vectors.</li>
<li><code>decoder</code> extracts the decoder hidden representations based on the token embedding vectors and encoder
    hidden representations.</li>
<li><code>postnet</code> predicts the probability of the next tokens by the decoder hidden representations.</li>
</ol>
</li>
<li>
<p>(optional) a CTC layer made up of a 'TokenPostnet'</p>
</li>
</ol>






              <details class="quote">
                <summary>Source code in <code>speechain/model/ar_asr.py</code></summary>
                <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  37</span>
<span class="normal">  38</span>
<span class="normal">  39</span>
<span class="normal">  40</span>
<span class="normal">  41</span>
<span class="normal">  42</span>
<span class="normal">  43</span>
<span class="normal">  44</span>
<span class="normal">  45</span>
<span class="normal">  46</span>
<span class="normal">  47</span>
<span class="normal">  48</span>
<span class="normal">  49</span>
<span class="normal">  50</span>
<span class="normal">  51</span>
<span class="normal">  52</span>
<span class="normal">  53</span>
<span class="normal">  54</span>
<span class="normal">  55</span>
<span class="normal">  56</span>
<span class="normal">  57</span>
<span class="normal">  58</span>
<span class="normal">  59</span>
<span class="normal">  60</span>
<span class="normal">  61</span>
<span class="normal">  62</span>
<span class="normal">  63</span>
<span class="normal">  64</span>
<span class="normal">  65</span>
<span class="normal">  66</span>
<span class="normal">  67</span>
<span class="normal">  68</span>
<span class="normal">  69</span>
<span class="normal">  70</span>
<span class="normal">  71</span>
<span class="normal">  72</span>
<span class="normal">  73</span>
<span class="normal">  74</span>
<span class="normal">  75</span>
<span class="normal">  76</span>
<span class="normal">  77</span>
<span class="normal">  78</span>
<span class="normal">  79</span>
<span class="normal">  80</span>
<span class="normal">  81</span>
<span class="normal">  82</span>
<span class="normal">  83</span>
<span class="normal">  84</span>
<span class="normal">  85</span>
<span class="normal">  86</span>
<span class="normal">  87</span>
<span class="normal">  88</span>
<span class="normal">  89</span>
<span class="normal">  90</span>
<span class="normal">  91</span>
<span class="normal">  92</span>
<span class="normal">  93</span>
<span class="normal">  94</span>
<span class="normal">  95</span>
<span class="normal">  96</span>
<span class="normal">  97</span>
<span class="normal">  98</span>
<span class="normal">  99</span>
<span class="normal"> 100</span>
<span class="normal"> 101</span>
<span class="normal"> 102</span>
<span class="normal"> 103</span>
<span class="normal"> 104</span>
<span class="normal"> 105</span>
<span class="normal"> 106</span>
<span class="normal"> 107</span>
<span class="normal"> 108</span>
<span class="normal"> 109</span>
<span class="normal"> 110</span>
<span class="normal"> 111</span>
<span class="normal"> 112</span>
<span class="normal"> 113</span>
<span class="normal"> 114</span>
<span class="normal"> 115</span>
<span class="normal"> 116</span>
<span class="normal"> 117</span>
<span class="normal"> 118</span>
<span class="normal"> 119</span>
<span class="normal"> 120</span>
<span class="normal"> 121</span>
<span class="normal"> 122</span>
<span class="normal"> 123</span>
<span class="normal"> 124</span>
<span class="normal"> 125</span>
<span class="normal"> 126</span>
<span class="normal"> 127</span>
<span class="normal"> 128</span>
<span class="normal"> 129</span>
<span class="normal"> 130</span>
<span class="normal"> 131</span>
<span class="normal"> 132</span>
<span class="normal"> 133</span>
<span class="normal"> 134</span>
<span class="normal"> 135</span>
<span class="normal"> 136</span>
<span class="normal"> 137</span>
<span class="normal"> 138</span>
<span class="normal"> 139</span>
<span class="normal"> 140</span>
<span class="normal"> 141</span>
<span class="normal"> 142</span>
<span class="normal"> 143</span>
<span class="normal"> 144</span>
<span class="normal"> 145</span>
<span class="normal"> 146</span>
<span class="normal"> 147</span>
<span class="normal"> 148</span>
<span class="normal"> 149</span>
<span class="normal"> 150</span>
<span class="normal"> 151</span>
<span class="normal"> 152</span>
<span class="normal"> 153</span>
<span class="normal"> 154</span>
<span class="normal"> 155</span>
<span class="normal"> 156</span>
<span class="normal"> 157</span>
<span class="normal"> 158</span>
<span class="normal"> 159</span>
<span class="normal"> 160</span>
<span class="normal"> 161</span>
<span class="normal"> 162</span>
<span class="normal"> 163</span>
<span class="normal"> 164</span>
<span class="normal"> 165</span>
<span class="normal"> 166</span>
<span class="normal"> 167</span>
<span class="normal"> 168</span>
<span class="normal"> 169</span>
<span class="normal"> 170</span>
<span class="normal"> 171</span>
<span class="normal"> 172</span>
<span class="normal"> 173</span>
<span class="normal"> 174</span>
<span class="normal"> 175</span>
<span class="normal"> 176</span>
<span class="normal"> 177</span>
<span class="normal"> 178</span>
<span class="normal"> 179</span>
<span class="normal"> 180</span>
<span class="normal"> 181</span>
<span class="normal"> 182</span>
<span class="normal"> 183</span>
<span class="normal"> 184</span>
<span class="normal"> 185</span>
<span class="normal"> 186</span>
<span class="normal"> 187</span>
<span class="normal"> 188</span>
<span class="normal"> 189</span>
<span class="normal"> 190</span>
<span class="normal"> 191</span>
<span class="normal"> 192</span>
<span class="normal"> 193</span>
<span class="normal"> 194</span>
<span class="normal"> 195</span>
<span class="normal"> 196</span>
<span class="normal"> 197</span>
<span class="normal"> 198</span>
<span class="normal"> 199</span>
<span class="normal"> 200</span>
<span class="normal"> 201</span>
<span class="normal"> 202</span>
<span class="normal"> 203</span>
<span class="normal"> 204</span>
<span class="normal"> 205</span>
<span class="normal"> 206</span>
<span class="normal"> 207</span>
<span class="normal"> 208</span>
<span class="normal"> 209</span>
<span class="normal"> 210</span>
<span class="normal"> 211</span>
<span class="normal"> 212</span>
<span class="normal"> 213</span>
<span class="normal"> 214</span>
<span class="normal"> 215</span>
<span class="normal"> 216</span>
<span class="normal"> 217</span>
<span class="normal"> 218</span>
<span class="normal"> 219</span>
<span class="normal"> 220</span>
<span class="normal"> 221</span>
<span class="normal"> 222</span>
<span class="normal"> 223</span>
<span class="normal"> 224</span>
<span class="normal"> 225</span>
<span class="normal"> 226</span>
<span class="normal"> 227</span>
<span class="normal"> 228</span>
<span class="normal"> 229</span>
<span class="normal"> 230</span>
<span class="normal"> 231</span>
<span class="normal"> 232</span>
<span class="normal"> 233</span>
<span class="normal"> 234</span>
<span class="normal"> 235</span>
<span class="normal"> 236</span>
<span class="normal"> 237</span>
<span class="normal"> 238</span>
<span class="normal"> 239</span>
<span class="normal"> 240</span>
<span class="normal"> 241</span>
<span class="normal"> 242</span>
<span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">ARASR</span><span class="p">(</span><span class="n">Model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Auto-Regressive Attention-based Automatic Speech Recognition (AR-ASR) implementation.</span>

<span class="sd">    The neural network structure of an `ASR` Model object is made up of 3 Module members:</span>

<span class="sd">    1. an `ASREncoder` made up of:</span>
<span class="sd">        1. `frontend` converts the  raw waveforms into acoustic features on-the-fly.</span>
<span class="sd">        2. `normalize` normalizes the extracted acoustic features to normal distribution for faster convergence.</span>
<span class="sd">        3. `specaug` randomly warps and masks the normalized acoustic features.</span>
<span class="sd">        4. `prenet` preprocesses the augmented acoustic features before passing them to the encoder.</span>
<span class="sd">        5. `encoder` extracts the encoder hidden representations of the preprocessed acoustic features and passes them</span>
<span class="sd">            to `ARASRDecoder`.</span>

<span class="sd">    2. an `ARASRDecoder` made up of:</span>
<span class="sd">        1. `embedding` embeds each tokens in the input sentence into token embedding vectors.</span>
<span class="sd">        2. `decoder` extracts the decoder hidden representations based on the token embedding vectors and encoder</span>
<span class="sd">            hidden representations.</span>
<span class="sd">        3. `postnet` predicts the probability of the next tokens by the decoder hidden representations.</span>

<span class="sd">    3. (optional) a CTC layer made up of a &#39;TokenPostnet&#39;</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">module_init</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">token_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">token_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">enc_prenet</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">encoder</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">dec_emb</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">decoder</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">frontend</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">normalize</span><span class="p">:</span> <span class="n">Dict</span> <span class="ow">or</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">specaug</span><span class="p">:</span> <span class="n">Dict</span> <span class="ow">or</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ilm_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">ilm_sub_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">ctc_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16000</span><span class="p">,</span>
        <span class="n">audio_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;wav&quot;</span><span class="p">,</span>
        <span class="n">return_att_type</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="ow">or</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_att_head_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">return_att_layer_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">lm_model_cfg</span><span class="p">:</span> <span class="n">Dict</span> <span class="ow">or</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lm_model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This initialization function contains 4 steps:</span>
<span class="sd">        1. `Tokenizer` initialization.</span>
<span class="sd">        2. `ASREncoder` initialization.</span>
<span class="sd">        3. `ARASRDecoder` initialization.</span>
<span class="sd">        4. (optional) &#39;CTC&#39; layer initialization</span>

<span class="sd">        The input arguments of this function are two-fold:</span>
<span class="sd">        1. the ones from `customize_conf` of `model` in `train_cfg`</span>
<span class="sd">        2. the ones from `module_conf` of `model` in `train_cfg`</span>

<span class="sd">        Args:</span>
<span class="sd">            # --- module_conf arguments --- #</span>
<span class="sd">            frontend: (optional)</span>
<span class="sd">                The configuration of the acoustic feature extraction frontend in the `ASREncoder` member.</span>
<span class="sd">                This argument must be given since our toolkit doesn&#39;t support time-domain ASR.</span>
<span class="sd">                For more details about how to give `frontend`, please refer to speechain.module.encoder.asr.ASREncoder.</span>
<span class="sd">            normalize: (optional)</span>
<span class="sd">                The configuration of the normalization layer in the `ASREncoder` member.</span>
<span class="sd">                This argument can also be given as a bool value.</span>
<span class="sd">                True means the default configuration and False means no normalization.</span>
<span class="sd">                For more details about how to give `normalize`, please refer to</span>
<span class="sd">                    speechain.module.norm.feat_norm.FeatureNormalization.</span>
<span class="sd">            specaug: (optional)</span>
<span class="sd">                The configuration of the SpecAugment layer in the `ASREncoder` member.</span>
<span class="sd">                This argument can also be given as a bool value.</span>
<span class="sd">                True means the default configuration and False means no SpecAugment.</span>
<span class="sd">                For more details about how to give `specaug`, please refer to</span>
<span class="sd">                    speechain.module.augment.specaug.SpecAugment.</span>
<span class="sd">            enc_prenet: (mandatory)</span>
<span class="sd">                The configuration of the prenet in the `ASREncoder` member.</span>
<span class="sd">                The encoder prenet embeds the input acoustic features into hidden embeddings before feeding them into</span>
<span class="sd">                the encoder.</span>
<span class="sd">                For more details about how to give `enc_prent`, please refer to speechain.module.encoder.asr.ASREncoder.</span>
<span class="sd">            encoder: (mandatory)</span>
<span class="sd">                The configuration of the encoder main body in the `ASREncoder` member.</span>
<span class="sd">                The encoder embeds the hidden embeddings into the encoder representations at each time steps of the</span>
<span class="sd">                input acoustic features.</span>
<span class="sd">                For more details about how to give `encoder`, please refer to speechain.module.encoder.asr.ASREncoder.</span>
<span class="sd">            dec_emb: (mandatory)</span>
<span class="sd">                The configuration of the embedding layer in the `ARASRDecoder` member.</span>
<span class="sd">                The decoder prenet embeds the input token ids into hidden embeddings before feeding them into</span>
<span class="sd">                the decoder.</span>
<span class="sd">                For more details about how to give `dec_emb`, please refer to speechain.module.encoder.asr.ASREncoder.</span>
<span class="sd">            decoder: (mandatory)</span>
<span class="sd">                The configuration of the decoder main body in the `ARASRDecoder` member.</span>
<span class="sd">                The decoder predicts the probability of the next token at each time steps based on the token embeddings.</span>
<span class="sd">                For more details about how to give `decoder`, please refer to speechain.module.decoder.ar_asr.ARASRDecoder.</span>
<span class="sd">            # --- customize_conf arguments --- #</span>
<span class="sd">            token_type: (mandatory)</span>
<span class="sd">                The type of the built-in tokenizer.</span>
<span class="sd">            token_path: (mandatory)</span>
<span class="sd">                The path of the vocabulary for initializing the built-in tokenizer.</span>
<span class="sd">            sample_rate: int = 16000 (optional)</span>
<span class="sd">                The sampling rate of the input speech.</span>
<span class="sd">                Currently, it&#39;s used for acoustic feature extraction frontend initialization and tensorboard register of</span>
<span class="sd">                the input speech for model visualization.</span>
<span class="sd">                In the future, this argument will also be used to on-the-fly downsample the input speech.</span>
<span class="sd">            audio_format: (optional)</span>
<span class="sd">                This argument is only used for input speech recording during model visualization.</span>
<span class="sd">            return_att_type: List[str] or str = [&#39;encdec&#39;, &#39;enc&#39;, &#39;dec&#39;]</span>
<span class="sd">                The type of attentions you want to return for both attention guidance and attention visualization.</span>
<span class="sd">                It can be given as a string (one type) or a list of strings (multiple types).</span>
<span class="sd">                The type should be one of</span>
<span class="sd">                    1. &#39;encdec&#39;: the encoder-decoder attention, shared by both Transformer and RNN</span>
<span class="sd">                    2. &#39;enc&#39;: the encoder self-attention, only for Transformer</span>
<span class="sd">                    3. &#39;dec&#39;: the decoder self-attention, only for Transformer</span>
<span class="sd">            return_att_head_num: int = -1</span>
<span class="sd">                The number of returned attention heads. If -1, all the heads in an attention layer will be returned.</span>
<span class="sd">                RNN can be considered to one-head attention, so return_att_head_num &gt; 1 is equivalent to 1 for RNN.</span>
<span class="sd">            return_att_layer_num: int = 1</span>
<span class="sd">                The number of returned attention layers. If -1, all the attention layers will be returned.</span>
<span class="sd">                RNN can be considered to one-layer attention, so return_att_layer_num &gt; 1 is equivalent to 1 for RNN.</span>
<span class="sd">            lm_model_cfg: Dict or str</span>
<span class="sd">                The configuration for the language model used for joint decoding.</span>
<span class="sd">                Can be either a Dict or a string indicating where the .yaml model configuration file is placed.</span>
<span class="sd">            lm_model_path: str</span>
<span class="sd">                The string indicating where the .pth model parameter file is placed.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># --- 1. Module-independent Initialization --- #</span>
        <span class="c1"># initialize the tokenizer</span>
        <span class="k">if</span> <span class="n">token_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;char&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">CharTokenizer</span><span class="p">(</span><span class="n">token_path</span><span class="p">,</span> <span class="n">copy_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">token_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;sentencepiece&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">SentencePieceTokenizer</span><span class="p">(</span>
                <span class="n">token_path</span><span class="p">,</span> <span class="n">copy_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Unknown token_type </span><span class="si">{</span><span class="n">token_type</span><span class="si">}</span><span class="s2">. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Currently, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> supports one of [&#39;char&#39;, &#39;sentencepiece&#39;].&quot;</span>
            <span class="p">)</span>

        <span class="c1"># initialize the sampling rate, mainly used for visualizing the input audio during training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">audio_format</span> <span class="o">=</span> <span class="n">audio_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

        <span class="c1"># attention-related</span>
        <span class="k">if</span> <span class="n">return_att_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;encdec&quot;</span><span class="p">,</span> <span class="s2">&quot;enc&quot;</span><span class="p">,</span> <span class="s2">&quot;dec&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">return_att_type</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">return_att_type</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span>
                <span class="k">else</span> <span class="p">[</span><span class="n">return_att_type</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">)):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;enc&quot;</span><span class="p">,</span> <span class="s2">&quot;dec&quot;</span><span class="p">,</span> <span class="s2">&quot;encdec&quot;</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;The elements of your input return_att_type must be one of [&#39;enc&#39;, &#39;dec&#39;, &#39;encdec&#39;], &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">!&quot;</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span> <span class="o">=</span> <span class="n">return_att_head_num</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span> <span class="o">=</span> <span class="n">return_att_layer_num</span>

        <span class="c1"># language model-related, used for lazy initialization during inference</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="o">=</span> <span class="n">lm_model_cfg</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_path</span> <span class="o">=</span> <span class="n">lm_model_path</span>

        <span class="c1"># --- 2. Module Initialization --- #</span>
        <span class="c1"># --- 2.1 Encoder construction --- #</span>
        <span class="c1"># the sampling rate will be first initialized</span>
        <span class="k">if</span> <span class="s2">&quot;sr&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">frontend</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">frontend</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">][</span><span class="s2">&quot;sr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span>
        <span class="c1"># update the sampling rate into the ASR Model object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">frontend</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">][</span><span class="s2">&quot;sr&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">ASREncoder</span><span class="p">(</span>
            <span class="n">frontend</span><span class="o">=</span><span class="n">frontend</span><span class="p">,</span>
            <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span>
            <span class="n">specaug</span><span class="o">=</span><span class="n">specaug</span><span class="p">,</span>
            <span class="n">prenet</span><span class="o">=</span><span class="n">enc_prenet</span><span class="p">,</span>
            <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
            <span class="n">distributed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># --- 2.2 CTC layer construction (optional) --- #</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ctc_weight</span> <span class="o">=</span> <span class="n">ctc_weight</span>
        <span class="k">assert</span> <span class="n">ctc_weight</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;ctc_weight cannot be lower than 0!&quot;</span>
        <span class="k">if</span> <span class="n">ctc_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ctc_layer</span> <span class="o">=</span> <span class="n">TokenPostnet</span><span class="p">(</span>
                <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span>
                <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># --- 2.3 Decoder construction --- #</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ilm_weight</span> <span class="o">=</span> <span class="n">ilm_weight</span>
        <span class="k">assert</span> <span class="n">ilm_weight</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;ilm_weight cannot be lower than 0!&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ilm_sub_weight</span> <span class="o">=</span> <span class="n">ilm_sub_weight</span>
        <span class="k">assert</span> <span class="n">ilm_sub_weight</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;ilm_sub_weight cannot be lower than 0!&quot;</span>
        <span class="c1"># the vocabulary size is given by the built-in tokenizer instead of the input configuration</span>
        <span class="k">if</span> <span class="s2">&quot;vocab_size&quot;</span> <span class="ow">in</span> <span class="n">dec_emb</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">dec_emb</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">][</span><span class="s2">&quot;vocab_size&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Your input vocabulary size is different from the one obtained from the built-in &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;tokenizer (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2">). The latter one will be used to initialize the &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;decoder for correctness.&quot;</span>
                <span class="p">)</span>
            <span class="n">dec_emb</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;vocab_size&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">ARASRDecoder</span><span class="p">(</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding</span><span class="o">=</span><span class="n">dec_emb</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">criterion_init</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">ce_loss</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ilm_loss</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ctc_loss</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="ow">or</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">att_guid_loss</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="ow">or</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function initializes all the necessary _Criterion_ members:</span>
<span class="sd">            1. `speechain.criterion.cross_entropy.CrossEntropy` for training loss calculation.</span>
<span class="sd">            2. `speechain.criterion.ctc.CTCLoss` for training loss calculation.</span>
<span class="sd">            3. `speechain.criterion.accuracy.Accuracy` for teacher-forcing validation accuracy calculation.</span>
<span class="sd">            4. `speechain.criterion.error_rate.ErrorRate` for evaluation CER &amp; WER calculation.</span>

<span class="sd">        Args:</span>
<span class="sd">            ce_loss: Dict[str, Any]</span>
<span class="sd">                The arguments for CrossEntropy(). If not given, the default setting of CrossEntropy() will be used.</span>
<span class="sd">                Please refer to speechain.criterion.cross_entropy.CrossEntropy for more details.</span>
<span class="sd">            ilm_loss:</span>
<span class="sd">            ctc_loss: Dict[str, Any] or bool</span>
<span class="sd">                The arguments for CTCLoss(). If not given, self.ctc_loss won&#39;t be initialized.</span>
<span class="sd">                This argument can also be set to a bool value &#39;True&#39;. If True, the default setting of CTCLoss()</span>
<span class="sd">                will be used.</span>
<span class="sd">                Please refer to speechain.criterion.ctc.CTCLoss for more details.</span>
<span class="sd">            att_guid_loss: Dict[str, Any] or bool</span>
<span class="sd">                The arguments for AttentionGuidance(). If not given, self.att_guid_loss won&#39;t be initialized.</span>
<span class="sd">                This argument can also be set to a bool value &#39;True&#39;. If True, the default setting of AttentionGuidance()</span>
<span class="sd">                will be used.</span>
<span class="sd">                Please refer to speechain.criterion.att_guid.AttentionGuidance for more details.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># initialize cross-entropy loss for the encoder-decoder</span>
        <span class="k">if</span> <span class="n">ce_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ce_loss</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ce_loss</span> <span class="o">=</span> <span class="n">CrossEntropy</span><span class="p">(</span><span class="o">**</span><span class="n">ce_loss</span><span class="p">)</span>

        <span class="c1"># initialize cross-entropy loss for the internal LM</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># ilm_loss is default to be normalized by sentence lengths</span>
            <span class="k">if</span> <span class="n">ilm_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ilm_loss</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">length_normalized</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ilm_loss</span> <span class="o">=</span> <span class="n">CrossEntropy</span><span class="p">(</span><span class="o">**</span><span class="n">ilm_loss</span><span class="p">)</span>

        <span class="c1"># initialize ctc loss</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># if ctc_loss is given as True or None, the default arguments of CTCLoss will be used</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ctc_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
                <span class="n">ctc_loss</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="s2">&quot;cpu&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;For speeding up CTC calculation by CuDNN, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;please set the blank id to 0 (got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span><span class="si">}</span><span class="s2">).&quot;</span>
                <span class="p">)</span>

            <span class="n">ctc_loss</span><span class="p">[</span><span class="s2">&quot;blank&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ctc_loss</span> <span class="o">=</span> <span class="n">CTCLoss</span><span class="p">(</span><span class="o">**</span><span class="n">ctc_loss</span><span class="p">)</span>

        <span class="c1"># initialize attention guidance loss</span>
        <span class="k">if</span> <span class="n">att_guid_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># if att_guid_loss is given as True, the default arguments of AttentionGuidance will be used</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="n">att_guid_loss</span>
                <span class="p">),</span> <span class="s2">&quot;If you want to use the default setting of AttentionGuidance, please give att_guid_loss as True.&quot;</span>
                <span class="n">att_guid_loss</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="k">assert</span> <span class="p">(</span>
                <span class="s2">&quot;encdec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span>
            <span class="p">),</span> <span class="s2">&quot;If you want to enable attention guidance for ASR training, please include &#39;encdec&#39; in return_att_type.&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span> <span class="o">=</span> <span class="n">AttentionGuidance</span><span class="p">(</span><span class="o">**</span><span class="n">att_guid_loss</span><span class="p">)</span>

        <span class="c1"># initialize teacher-forcing accuracy for validation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">Accuracy</span><span class="p">()</span>

        <span class="c1"># initialize text perplexity calculator for internal LM if needed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">perplexity</span> <span class="o">=</span> <span class="n">Perplexity</span><span class="p">()</span>

        <span class="c1"># initialize error rate (CER &amp; WER) for evaluation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span> <span class="o">=</span> <span class="n">ErrorRate</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">bad_cases_selection_init_fn</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span> <span class="ow">or</span> <span class="nb">int</span><span class="p">]]</span> <span class="ow">or</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="p">[</span><span class="s2">&quot;wer&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
            <span class="p">[</span><span class="s2">&quot;cer&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
            <span class="p">[</span><span class="s2">&quot;feat_token_len_ratio&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
            <span class="p">[</span><span class="s2">&quot;feat_token_len_ratio&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
            <span class="p">[</span><span class="s2">&quot;text_confid&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
            <span class="p">[</span><span class="s2">&quot;text_confid&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span>
        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">module_forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">text_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">domain</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_att</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            feat: (batch, feat_maxlen, feat_dim)</span>
<span class="sd">                The input speech data. feat_dim = 1 in the case of raw speech waveforms.</span>
<span class="sd">            feat_len: (batch,)</span>
<span class="sd">                The lengths of input speech data</span>
<span class="sd">            text: (batch, text_maxlen)</span>
<span class="sd">                The input text data with &lt;sos/eos&gt; at the beginning and end</span>
<span class="sd">            text_len: (batch,)</span>
<span class="sd">                The lengths of input text data</span>
<span class="sd">            epoch: int</span>
<span class="sd">                The number of the current training epoch.</span>
<span class="sd">                Mainly used for mean&amp;std calculation in the feature normalization</span>
<span class="sd">            domain: str = None</span>
<span class="sd">            return_att: bool</span>
<span class="sd">                Controls whether the attention matrices of each layer in the encoder and decoder will be returned.</span>
<span class="sd">            kwargs:</span>
<span class="sd">                Temporary register used to store the redundant arguments.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># para checking</span>
        <span class="k">assert</span> <span class="n">feat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">feat_len</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">assert</span> <span class="n">feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">text</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="n">feat_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">text_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span>
            <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;The amounts of utterances and sentences are not equal to each other.&quot;</span>
        <span class="k">assert</span> <span class="n">feat_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span>
            <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;The amounts of utterances and their lengths are not equal to each other.&quot;</span>
        <span class="k">assert</span> <span class="n">text_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">text</span><span class="o">.</span><span class="n">size</span><span class="p">(</span>
            <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;The amounts of sentences and their lengths are not equal to each other.&quot;</span>

        <span class="c1"># remove the &lt;sos/eos&gt; at the end of each sentence</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">text_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
            <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">text_len</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span>
        <span class="n">text</span><span class="p">,</span> <span class="n">text_len</span> <span class="o">=</span> <span class="n">text</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">text_len</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="c1"># --- 1. Encoder: Input Feature to Encoder Hidden Representation --- #</span>
        <span class="n">enc_returns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span>
            <span class="n">feat</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span><span class="o">=</span><span class="n">feat_len</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">domain</span>
        <span class="p">)</span>
        <span class="c1"># Transformer-based encoder additionally returns the encoder self-attention</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">enc_feat</span><span class="p">,</span> <span class="n">enc_feat_mask</span><span class="p">,</span> <span class="n">enc_attmat</span><span class="p">,</span> <span class="n">enc_hidden</span> <span class="o">=</span> <span class="n">enc_returns</span>
        <span class="c1"># RNN-based encoder doesn&#39;t return any attention</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="p">(</span><span class="n">enc_feat</span><span class="p">,</span> <span class="n">enc_feat_mask</span><span class="p">,</span> <span class="n">enc_hidden</span><span class="p">),</span> <span class="n">enc_attmat</span> <span class="o">=</span> <span class="n">enc_returns</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span>

        <span class="c1"># --- 2. Decoder: Encoder Hidden Representation to Decoder Hidden Representation --- #</span>
        <span class="n">dec_returns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
            <span class="n">enc_feat</span><span class="o">=</span><span class="n">enc_feat</span><span class="p">,</span> <span class="n">enc_feat_mask</span><span class="o">=</span><span class="n">enc_feat_mask</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span>
        <span class="p">)</span>
        <span class="c1"># Transformer-based decoder additionally returns the decoder self-attention</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dec_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">dec_feat</span><span class="p">,</span> <span class="n">dec_attmat</span><span class="p">,</span> <span class="n">encdec_attmat</span><span class="p">,</span> <span class="n">dec_hidden</span> <span class="o">=</span> <span class="n">dec_returns</span>
        <span class="c1"># RNN-based decoder only returns the encoder-decoder attention</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">dec_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="p">(</span><span class="n">dec_feat</span><span class="p">,</span> <span class="n">encdec_attmat</span><span class="p">,</span> <span class="n">dec_hidden</span><span class="p">),</span> <span class="n">dec_attmat</span> <span class="o">=</span> <span class="n">dec_returns</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span>

        <span class="c1"># initialize the asr output to be the decoder predictions</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">dec_feat</span><span class="p">)</span>

        <span class="c1"># --- 3.(optional) Decoder: Internal LM Estimation by zeroing Encoder Hidden Representation --- #</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_weight</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_sub_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">ilm_returns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
                <span class="n">enc_feat</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="n">enc_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">enc_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">enc_feat</span><span class="o">.</span><span class="n">device</span>
                <span class="p">),</span>
                <span class="n">enc_feat_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
                    <span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                    <span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
                    <span class="mi">1</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Transformer-based decoder additionally returns the decoder self-attention</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ilm_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                <span class="n">ilm_feat</span><span class="p">,</span> <span class="n">ilm_dec_attmat</span><span class="p">,</span> <span class="n">ilm_encdec_attmat</span><span class="p">,</span> <span class="n">ilm_hidden</span> <span class="o">=</span> <span class="n">ilm_returns</span>
            <span class="c1"># RNN-based decoder only returns the encoder-decoder attention</span>
            <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">ilm_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="p">(</span><span class="n">ilm_feat</span><span class="p">,</span> <span class="n">ilm_encdec_attmat</span><span class="p">,</span> <span class="n">ilm_hidden</span><span class="p">),</span> <span class="n">ilm_dec_attmat</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">ilm_returns</span><span class="p">,</span>
                    <span class="kc">None</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ilm_logits</span><span class="o">=</span><span class="n">ilm_feat</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_sub_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_sub_weight</span> <span class="o">*</span> <span class="n">ilm_feat</span>

        <span class="c1"># --- 4.(optional) Encoder Hidden Representation to CTC Prediction --- #</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;ctc_layer&quot;</span><span class="p">):</span>
            <span class="n">ctc_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_layer</span><span class="p">(</span><span class="n">enc_feat</span><span class="p">)</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="n">ctc_logits</span><span class="o">=</span><span class="n">ctc_logits</span><span class="p">,</span>
                <span class="n">enc_feat_len</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
            <span class="p">)</span>

        <span class="k">def</span> <span class="nf">shrink_attention</span><span class="p">(</span><span class="n">input_att_list</span><span class="p">):</span>
            <span class="c1"># pick up the target attention layers</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
                <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_att_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span>
            <span class="p">):</span>
                <span class="n">input_att_list</span> <span class="o">=</span> <span class="n">input_att_list</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span> <span class="p">:]</span>
            <span class="c1"># pick up the target attention heads</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
                <span class="ow">and</span> <span class="n">input_att_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span>
            <span class="p">):</span>
                <span class="n">input_att_list</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">att</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span><span class="p">]</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">input_att_list</span>
                <span class="p">]</span>
            <span class="k">return</span> <span class="n">input_att_list</span>

        <span class="c1"># return the attention results if specified</span>
        <span class="k">if</span> <span class="n">return_att</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;att_guid_loss&quot;</span><span class="p">):</span>
            <span class="c1"># encoder-decoder attention</span>
            <span class="k">if</span> <span class="s2">&quot;encdec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">:</span>
                <span class="c1"># register the encoder-decoder attention</span>
                <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">att</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">encdec</span><span class="o">=</span><span class="n">shrink_attention</span><span class="p">(</span><span class="n">encdec_attmat</span><span class="p">)))</span>
            <span class="c1"># encoder self-attention</span>
            <span class="k">if</span> <span class="n">enc_attmat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;enc&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">enc</span><span class="o">=</span><span class="n">shrink_attention</span><span class="p">(</span><span class="n">enc_attmat</span><span class="p">))</span>
            <span class="c1"># decoder self-attention</span>
            <span class="k">if</span> <span class="n">dec_attmat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;dec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">:</span>
                <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">dec</span><span class="o">=</span><span class="n">shrink_attention</span><span class="p">(</span><span class="n">dec_attmat</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">def</span> <span class="nf">get_ctc_forward_results</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">ctc_logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">enc_feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">ctc_loss_fn</span><span class="p">:</span> <span class="nb">callable</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="n">ctc_text_confid</span> <span class="o">=</span> <span class="n">ctc_logits</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">ctc_recover_text</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tensor2text</span><span class="p">(</span><span class="n">ctc_text</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">ctc_text</span> <span class="ow">in</span> <span class="n">ctc_loss_fn</span><span class="o">.</span><span class="n">recover</span><span class="p">(</span><span class="n">ctc_logits</span><span class="p">,</span> <span class="n">enc_feat_len</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">real_text</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tensor2text</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">text</span><span class="p">]</span>
        <span class="n">ctc_cer_wer</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">hypo_text</span><span class="o">=</span><span class="n">ctc_recover_text</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">real_text</span><span class="o">=</span><span class="n">real_text</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">real_text</span><span class="p">))</span>
        <span class="p">]</span>

        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">ctc_text_confid</span><span class="o">=</span><span class="n">ctc_text_confid</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
            <span class="n">ctc_cer</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">ctc_cer_wer</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ctc_cer_wer</span><span class="p">))]),</span>
            <span class="n">ctc_wer</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">ctc_cer_wer</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ctc_cer_wer</span><span class="p">))]),</span>
            <span class="n">ctc_text</span><span class="o">=</span><span class="n">ctc_recover_text</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">criterion_forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">text_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">ilm_logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ctc_logits</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">enc_feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">att</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ce_loss_fn</span><span class="p">:</span> <span class="n">CrossEntropy</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ilm_loss_fn</span><span class="p">:</span> <span class="n">CrossEntropy</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ctc_loss_fn</span><span class="p">:</span> <span class="n">CTCLoss</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">att_guid_loss_fn</span><span class="p">:</span> <span class="n">AttentionGuidance</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">forward_ctc</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="ow">or</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>

        <span class="n">accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">)</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">accuracy</span><span class="o">=</span><span class="n">accuracy</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

        <span class="c1"># the external cross-entropy loss function has the higher priority</span>
        <span class="k">if</span> <span class="n">ce_loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ce_loss_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ce_loss</span>
        <span class="n">ce_loss</span> <span class="o">=</span> <span class="n">ce_loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">)</span>
        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ce_loss</span><span class="o">=</span><span class="n">ce_loss</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

        <span class="c1"># if ctc_loss is specified, calculate the weighted sum of ctc_loss and ce_loss as loss in the metrics Dict</span>
        <span class="k">if</span> <span class="n">ctc_loss_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;ctc_loss&quot;</span><span class="p">):</span>
            <span class="c1"># the external ctc loss function has the higher priority</span>
            <span class="k">if</span> <span class="n">ctc_loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ctc_loss_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_loss</span>

            <span class="n">ctc_loss</span> <span class="o">=</span> <span class="n">ctc_loss_fn</span><span class="p">(</span><span class="n">ctc_logits</span><span class="p">,</span> <span class="n">enc_feat_len</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">text_len</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">ce_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_weight</span> <span class="o">*</span> <span class="n">ctc_loss</span>
            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ctc_loss</span><span class="o">=</span><span class="n">ctc_loss</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

            <span class="k">if</span> <span class="n">forward_ctc</span><span class="p">:</span>
                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">get_ctc_forward_results</span><span class="p">(</span>
                        <span class="n">ctc_logits</span><span class="o">=</span><span class="n">ctc_logits</span><span class="p">,</span>
                        <span class="n">enc_feat_len</span><span class="o">=</span><span class="n">enc_feat_len</span><span class="p">,</span>
                        <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
                        <span class="n">ctc_loss_fn</span><span class="o">=</span><span class="n">ctc_loss_fn</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">)</span>

        <span class="c1"># if ctc_loss is not specified, only record ce_loss as loss in the returned Dicts</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">ce_loss</span>

        <span class="c1"># if ilm_loss is specified, add ilm_loss to loss in the metrics Dict</span>
        <span class="k">if</span> <span class="n">ilm_loss_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;ilm_loss&quot;</span><span class="p">):</span>
            <span class="c1"># the external ctc loss function has the higher priority</span>
            <span class="k">if</span> <span class="n">ilm_loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ilm_loss_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_loss</span>

            <span class="n">ilm_loss</span> <span class="o">=</span> <span class="n">ilm_loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">ilm_logits</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">)</span>
            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ilm_loss</span><span class="o">=</span><span class="n">ilm_loss</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_weight</span> <span class="o">*</span> <span class="n">ilm_loss</span>

            <span class="c1"># calculate perplexity</span>
            <span class="n">ilm_ppl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">perplexity</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">ilm_logits</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">)</span>
            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ilm_text_ppl</span><span class="o">=</span><span class="n">ilm_ppl</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

        <span class="c1"># if att_guid_loss is given, record att_guid_loss in the metrics Dict</span>
        <span class="k">if</span> <span class="n">att_guid_loss_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;att_guid_loss&quot;</span><span class="p">):</span>
            <span class="c1"># the external attention guidance loss function has the higher priority</span>
            <span class="k">if</span> <span class="n">att_guid_loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">att_guid_loss_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span>

            <span class="c1"># layer_num * (batch, head_num, ...) -&gt; (batch, layer_num * head_num, ...)</span>
            <span class="n">att_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">att</span><span class="p">[</span><span class="s2">&quot;encdec&quot;</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">att_guid_loss</span> <span class="o">=</span> <span class="n">att_guid_loss_fn</span><span class="p">(</span><span class="n">att_tensor</span><span class="p">,</span> <span class="n">text_len</span><span class="p">,</span> <span class="n">enc_feat_len</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">att_guid_loss</span>
            <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="o">=</span><span class="n">att_guid_loss</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

        <span class="n">losses</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>
        <span class="c1"># .clone() here prevents the loss from being modified by accum_grad</span>
        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">metrics</span>

    <span class="k">def</span> <span class="nf">visualize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">sample_index</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">snapshot_interval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">epoch_records</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">domain</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">text_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="c1"># remove the padding zeros at the end of the input feat</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">feat</span><span class="p">)):</span>
            <span class="n">feat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">feat</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span> <span class="n">feat_len</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>

        <span class="c1"># visualization inference is default to be done by teacher-forcing</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visual_infer_conf</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">visual_infer_conf</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">teacher_forcing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># obtain the inference results</span>
        <span class="n">infer_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span>
            <span class="n">infer_conf</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">visual_infer_conf</span><span class="p">,</span>
            <span class="n">domain</span><span class="o">=</span><span class="n">domain</span><span class="p">,</span>
            <span class="n">return_att</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">feat</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span>
            <span class="n">feat_len</span><span class="o">=</span><span class="n">feat_len</span><span class="p">,</span>
            <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
            <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># --- snapshot the objective metrics --- #</span>
        <span class="n">vis_logs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># CER, WER, Confidence</span>
        <span class="n">materials</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="s2">&quot;cer&quot;</span><span class="p">,</span>
            <span class="s2">&quot;wer&quot;</span><span class="p">,</span>
            <span class="s2">&quot;ctc_cer&quot;</span><span class="p">,</span>
            <span class="s2">&quot;ctc_wer&quot;</span><span class="p">,</span>
            <span class="s2">&quot;accuracy&quot;</span><span class="p">,</span>
            <span class="s2">&quot;text_confid&quot;</span><span class="p">,</span>
            <span class="s2">&quot;ilm_text_ppl&quot;</span><span class="p">,</span>
        <span class="p">]:</span>
            <span class="k">if</span> <span class="n">metric</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">infer_results</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">continue</span>

            <span class="c1"># store each target metric into materials</span>
            <span class="k">if</span> <span class="n">metric</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">epoch_records</span><span class="p">[</span><span class="n">sample_index</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">epoch_records</span><span class="p">[</span><span class="n">sample_index</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">infer_results</span><span class="p">[</span><span class="n">metric</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">],</span> <span class="n">List</span><span class="p">):</span>
                <span class="n">infer_results</span><span class="p">[</span><span class="n">metric</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">infer_results</span><span class="p">[</span><span class="n">metric</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">]]</span>
            <span class="n">epoch_records</span><span class="p">[</span><span class="n">sample_index</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">infer_results</span><span class="p">[</span><span class="n">metric</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">materials</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch_records</span><span class="p">[</span><span class="n">sample_index</span><span class="p">][</span><span class="n">metric</span><span class="p">]</span>
        <span class="c1"># save the visualization log</span>
        <span class="n">vis_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="nb">dict</span><span class="p">(</span>
                <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;curve&quot;</span><span class="p">,</span>
                <span class="n">materials</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">materials</span><span class="p">),</span>
                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
                <span class="n">x_stride</span><span class="o">=</span><span class="n">snapshot_interval</span><span class="p">,</span>
                <span class="n">sep_save</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">subfolder_names</span><span class="o">=</span><span class="n">sample_index</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># --- snapshot the subjective metrics --- #</span>
        <span class="c1"># record the input audio and real text at the first snapshotting step</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">//</span> <span class="n">snapshot_interval</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># snapshot input audio</span>
            <span class="n">vis_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="nb">dict</span><span class="p">(</span>
                    <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;audio&quot;</span><span class="p">,</span>
                    <span class="n">materials</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">input_audio</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">feat</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span>
                    <span class="n">sample_rate</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span><span class="p">,</span>
                    <span class="n">audio_format</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">audio_format</span><span class="p">,</span>
                    <span class="n">subfolder_names</span><span class="o">=</span><span class="n">sample_index</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="c1"># snapshot real text</span>
            <span class="n">vis_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="nb">dict</span><span class="p">(</span>
                    <span class="n">materials</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                        <span class="n">real_text</span><span class="o">=</span><span class="p">[</span>
                            <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tensor2text</span><span class="p">(</span><span class="n">text</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
                        <span class="p">]</span>
                    <span class="p">),</span>
                    <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
                    <span class="n">subfolder_names</span><span class="o">=</span><span class="n">sample_index</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># teacher-forcing text and CTC-decoding text</span>
        <span class="k">for</span> <span class="n">text_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;ctc_text&quot;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">text_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">infer_results</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">text_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">epoch_records</span><span class="p">[</span><span class="n">sample_index</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">epoch_records</span><span class="p">[</span><span class="n">sample_index</span><span class="p">][</span><span class="n">text_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">epoch_records</span><span class="p">[</span><span class="n">sample_index</span><span class="p">][</span><span class="n">text_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">infer_results</span><span class="p">[</span><span class="n">text_name</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="c1"># snapshot the information in the materials</span>
            <span class="n">vis_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="nb">dict</span><span class="p">(</span>
                    <span class="n">materials</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
                        <span class="n">hypo_text</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">epoch_records</span><span class="p">[</span><span class="n">sample_index</span><span class="p">][</span><span class="n">text_name</span><span class="p">])</span>
                    <span class="p">),</span>
                    <span class="n">plot_type</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
                    <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                    <span class="n">x_stride</span><span class="o">=</span><span class="n">snapshot_interval</span><span class="p">,</span>
                    <span class="n">subfolder_names</span><span class="o">=</span><span class="n">sample_index</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># hypothesis attention matrix</span>
        <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_reshape</span><span class="p">(</span><span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">matrix_snapshot</span><span class="p">(</span>
            <span class="n">vis_logs</span><span class="o">=</span><span class="n">vis_logs</span><span class="p">,</span>
            <span class="n">hypo_attention</span><span class="o">=</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]),</span>
            <span class="n">subfolder_names</span><span class="o">=</span><span class="n">sample_index</span><span class="p">,</span>
            <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">vis_logs</span>

    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">infer_conf</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
        <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">text</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">text_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">domain</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_att</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">decode_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">teacher_forcing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The inference function for ASR models. There are two steps in this function:</span>
<span class="sd">            1. Decode the input speech into hypothesis transcript</span>
<span class="sd">            2. Evaluate the hypothesis transcript by the ground-truth</span>

<span class="sd">        This function can be called for model evaluation, on-the-fly model visualization, and even pseudo transcript</span>
<span class="sd">        generation during training.</span>

<span class="sd">        Args:</span>
<span class="sd">            # --- Testing data arguments --- #</span>
<span class="sd">            feat: torch.Tensor</span>
<span class="sd">                The speech data to be inferred.</span>
<span class="sd">            feat_len: torch.Tensor</span>
<span class="sd">                The length of `feat`.</span>
<span class="sd">            text: torch.Tensor</span>
<span class="sd">                The ground-truth transcript for the input speech</span>
<span class="sd">            text_len: torch.Tensor</span>
<span class="sd">                The length of `text`.</span>
<span class="sd">            # --- Explicit inference arguments --- #</span>
<span class="sd">            domain: str = None</span>
<span class="sd">                This argument indicates which domain the input speech belongs to.</span>
<span class="sd">                It&#39;s used to indicate the `ASREncoder` member how to encode the input speech.</span>
<span class="sd">            return_att: bool = False</span>
<span class="sd">                Whether the attention matrix of the input speech is returned.</span>
<span class="sd">            decode_only: bool = False</span>
<span class="sd">                Whether skip the evaluation step and do the decoding step only.</span>
<span class="sd">            teacher_forcing: bool = True</span>
<span class="sd">                Whether you use the teacher-forcing technique to generate the hypothesis transcript.</span>
<span class="sd">            # --- Implicit inference arguments given by infer_cfg from runner.py --- #</span>
<span class="sd">            infer_conf: Dict</span>
<span class="sd">                The inference configuration given from the `infer_cfg` in your `exp_cfg`.</span>
<span class="sd">                For more details, please refer to speechain.infer_func.beam_search.beam_searching.</span>

<span class="sd">        Returns: Dict</span>
<span class="sd">            A Dict containing all the decoding and evaluation results.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">feat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">feat_len</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

        <span class="c1"># --- 0. Hyperparameter &amp; Model Preparation Stage --- #</span>
        <span class="c1"># in-place replace infer_conf to protect the original information</span>
        <span class="n">infer_conf</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">infer_conf</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;decode_only&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">decode_only</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;decode_only&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;teacher_forcing&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">teacher_forcing</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;teacher_forcing&quot;</span><span class="p">)</span>
        <span class="n">hypo_text</span><span class="p">,</span> <span class="n">hypo_text_len</span><span class="p">,</span> <span class="n">feat_token_len_ratio</span><span class="p">,</span> <span class="n">hypo_text_confid</span><span class="p">,</span> <span class="n">hypo_att</span> <span class="o">=</span> <span class="p">(</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="kc">None</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># only initialize the language model when lm_weight is given as a positive float number</span>
        <span class="k">if</span> <span class="s2">&quot;lm_weight&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">infer_conf</span><span class="p">[</span><span class="s2">&quot;lm_weight&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
                <span class="s2">&quot;If you want to use ASR-LM joint decoding, &quot;</span>
                <span class="s2">&quot;please give lm_model_cfg and lm_model_path in model[&#39;customize_conf&#39;]!&quot;</span>
            <span class="p">)</span>
            <span class="c1"># lazily initialize the language model only at the first time</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;lm&quot;</span><span class="p">):</span>
                <span class="c1"># use the built-in lm configuration if lm_model_cfg is not given</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">result_path</span><span class="p">,</span> <span class="s2">&quot;lm_model_cfg.yaml&quot;</span>
                    <span class="p">)</span>

                <span class="c1"># get the Dict-like configuration for the language model</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="o">=</span> <span class="n">load_yaml</span><span class="p">(</span><span class="n">parse_path_args</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="p">))</span>
                <span class="k">if</span> <span class="s2">&quot;model&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>
                <span class="k">if</span> <span class="s2">&quot;module_conf&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="p">[</span><span class="s2">&quot;module_conf&quot;</span><span class="p">]</span>

                <span class="c1"># update the built-in configuration yaml file</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span>
                    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span><span class="p">,</span> <span class="s2">&quot;lm_model_cfg.yaml&quot;</span><span class="p">),</span>
                    <span class="s2">&quot;w&quot;</span><span class="p">,</span>
                    <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">,</span>
                <span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lm</span> <span class="o">=</span> <span class="n">LanguageModel</span><span class="p">(</span>
                    <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span>
                <span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># use the built-in lm model if lm_model_path is not given</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span><span class="p">,</span> <span class="s2">&quot;lm_model.pth&quot;</span><span class="p">)</span>

                <span class="c1"># load the parameters of the target lm</span>
                <span class="n">_lm_model_para</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
                    <span class="n">parse_path_args</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lm_model_path</span><span class="p">),</span> <span class="n">map_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
                <span class="p">)</span>
                <span class="n">lm_model_para</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">para</span> <span class="ow">in</span> <span class="n">_lm_model_para</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;lm.&quot;</span><span class="p">):</span>
                        <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;lm.&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">lm_model_para</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">para</span>

                <span class="c1"># update the built-in lm parameters and load them into the lm for inference</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
                    <span class="n">lm_model_para</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span><span class="p">,</span> <span class="s2">&quot;lm_model.pth&quot;</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lm</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">lm_model_para</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="c1"># --- 1. The 1st Pass: ASR Decoding by Beam Searching --- #</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">teacher_forcing</span><span class="p">:</span>
            <span class="c1"># copy the input data in advance for data safety</span>
            <span class="n">model_input</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">feat</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span><span class="o">=</span><span class="n">feat_len</span><span class="p">))</span>

            <span class="c1"># Encoding input speech</span>
            <span class="n">enc_feat</span><span class="p">,</span> <span class="n">enc_feat_mask</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">domain</span><span class="o">=</span><span class="n">domain</span><span class="p">,</span> <span class="o">**</span><span class="n">model_input</span><span class="p">)</span>

            <span class="c1"># generate the model hypothesis</span>
            <span class="n">infer_results</span> <span class="o">=</span> <span class="n">beam_searching</span><span class="p">(</span>
                <span class="n">enc_feat</span><span class="o">=</span><span class="n">enc_feat</span><span class="p">,</span>
                <span class="n">enc_feat_mask</span><span class="o">=</span><span class="n">enc_feat_mask</span><span class="p">,</span>
                <span class="n">asr_decode_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">,</span>
                <span class="n">ctc_decode_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ctc_layer</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;ctc_layer&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">lm_decode_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lm</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;lm&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
                <span class="n">sos_eos</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">sos_eos_idx</span><span class="p">,</span>
                <span class="n">padding_idx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span><span class="p">,</span>
                <span class="o">**</span><span class="n">infer_conf</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">hypo_text</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;hypo_text&quot;</span><span class="p">]</span>
            <span class="n">hypo_text_len</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;hypo_text_len&quot;</span><span class="p">]</span>
            <span class="n">feat_token_len_ratio</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;feat_token_len_ratio&quot;</span><span class="p">]</span>
            <span class="n">hypo_text_confid</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;hypo_text_confid&quot;</span><span class="p">]</span>

        <span class="c1"># --- 2. The 2nd Pass: ASR Decoding by Teacher Forcing --- #</span>
        <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="ow">or</span> <span class="n">return_att</span><span class="p">:</span>
            <span class="c1"># copy the input data in advance for data safety</span>
            <span class="n">model_input</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span>
                <span class="nb">dict</span><span class="p">(</span>
                    <span class="n">feat</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span>
                    <span class="n">feat_len</span><span class="o">=</span><span class="n">feat_len</span><span class="p">,</span>
                    <span class="n">text</span><span class="o">=</span><span class="n">text</span> <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="k">else</span> <span class="n">hypo_text</span><span class="p">,</span>
                    <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span> <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="k">else</span> <span class="n">hypo_text_len</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">infer_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_forward</span><span class="p">(</span>
                <span class="n">return_att</span><span class="o">=</span><span class="n">return_att</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">domain</span><span class="p">,</span> <span class="o">**</span><span class="n">model_input</span>
            <span class="p">)</span>
            <span class="c1"># return the attention matrices</span>
            <span class="k">if</span> <span class="n">return_att</span><span class="p">:</span>
                <span class="n">hypo_att</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span>

            <span class="c1"># update the hypothesis text-related data in the teacher forcing mode</span>
            <span class="k">if</span> <span class="n">teacher_forcing</span><span class="p">:</span>
                <span class="n">tf_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span>
                    <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">,</span> <span class="n">forward_ctc</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">infer_results</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">tf_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                        <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span>
                        <span class="n">content</span><span class="o">=</span><span class="p">(</span>
                            <span class="n">content</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span> <span class="k">else</span> <span class="n">to_cpu</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
                        <span class="p">),</span>
                    <span class="p">)</span>

                <span class="c1"># the last token is meaningless because the text is padded with eos at the end</span>
                <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span>
                    <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">][:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
                <span class="p">)</span>
                <span class="n">hypo_text_prob</span><span class="p">,</span> <span class="n">hypo_text</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="c1"># the original text contains both sos at the beginning and eos at the end</span>
                <span class="n">hypo_text_len</span> <span class="o">=</span> <span class="n">text_len</span> <span class="o">-</span> <span class="mi">2</span>
                <span class="n">feat_token_len_ratio</span> <span class="o">=</span> <span class="n">feat_len</span> <span class="o">/</span> <span class="p">(</span><span class="n">hypo_text_len</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)</span>
                <span class="c1"># sum up the log-probability of all time steps to get the confidence</span>
                <span class="n">length_penalty</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">infer_conf</span><span class="p">[</span><span class="s2">&quot;length_penalty&quot;</span><span class="p">]</span>
                    <span class="k">if</span> <span class="s2">&quot;length_penalty&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                    <span class="k">else</span> <span class="mf">1.0</span>
                <span class="p">)</span>
                <span class="n">hypo_text_confid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">hypo_text_prob</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span>
                    <span class="n">hypo_text_len</span><span class="o">**</span><span class="n">length_penalty</span>
                <span class="p">)</span>

        <span class="c1"># turn the data all the unsupervised metrics into the cpu version (List)</span>
        <span class="c1"># consider one &lt;sos/eos&gt; at the end, so hypo_text_len is added to 1</span>
        <span class="n">hypo_text_len</span><span class="p">,</span> <span class="n">feat_token_len_ratio</span><span class="p">,</span> <span class="n">hypo_text_confid</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">to_cpu</span><span class="p">(</span><span class="n">hypo_text_len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">to_cpu</span><span class="p">(</span><span class="n">feat_token_len_ratio</span><span class="p">),</span>
            <span class="n">to_cpu</span><span class="p">(</span><span class="n">hypo_text_confid</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># --- 3. Unsupervised Metrics Calculation (ground-truth text is not involved here) --- #</span>
        <span class="c1"># recover the text tensors back to text strings (removing the padding and sos/eos tokens)</span>
        <span class="c1"># hypo_text = [self.tokenizer.tensor2text(hypo[(hypo != self.tokenizer.ignore_idx) &amp;</span>
        <span class="c1">#                                              (hypo != self.tokenizer.sos_eos_idx)]) for hypo in hypo_text]</span>
        <span class="n">hypo_text</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tensor2text</span><span class="p">(</span><span class="n">hypo</span><span class="p">)</span> <span class="k">for</span> <span class="n">hypo</span> <span class="ow">in</span> <span class="n">hypo_text</span><span class="p">]</span>

        <span class="c1"># in the decoding-only mode, only the hypothesis-related results will be returned</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="n">text</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">hypo_text</span><span class="p">),</span>
            <span class="n">text_len</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">hypo_text_len</span><span class="p">),</span>
            <span class="n">feat_token_len_ratio</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">feat_token_len_ratio</span><span class="p">),</span>
            <span class="n">text_confid</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">hypo_text_confid</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># add the attention matrix into the output Dict, only used for model visualization during training</span>
        <span class="c1"># because it will consume too much time for saving the attention matrices of all testing samples during testing</span>
        <span class="k">if</span> <span class="n">return_att</span><span class="p">:</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">att</span><span class="o">=</span><span class="n">hypo_att</span><span class="p">)</span>

        <span class="c1"># recover the text tensors back to text strings (removing the padding and sos/eos tokens)</span>
        <span class="n">text</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tensor2text</span><span class="p">(</span>
                <span class="n">real</span><span class="p">[</span>
                    <span class="p">(</span><span class="n">real</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span><span class="p">)</span>
                    <span class="o">&amp;</span> <span class="p">(</span><span class="n">real</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">sos_eos_idx</span><span class="p">)</span>
                <span class="p">]</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">real</span> <span class="ow">in</span> <span class="n">text</span>
        <span class="p">]</span>
        <span class="c1"># evaluation reports for all the testing instances</span>
        <span class="p">(</span>
            <span class="n">instance_report_dict</span><span class="p">,</span>
            <span class="n">align_table_list</span><span class="p">,</span>
            <span class="n">cer_list</span><span class="p">,</span>
            <span class="n">wer_list</span><span class="p">,</span>
            <span class="n">insertion_list</span><span class="p">,</span>
            <span class="n">deletion_list</span><span class="p">,</span>
            <span class="n">substitution_list</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="p">({},</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>
        <span class="c1"># loop each sentence</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)):</span>
            <span class="c1"># add the confidence into instance_reports.md</span>
            <span class="k">if</span> <span class="s2">&quot;Hypothesis Confidence&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Hypothesis Confidence&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Hypothesis Confidence&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">hypo_text_confid</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

            <span class="c1"># add the frame-token length ratio into instance_reports.md</span>
            <span class="k">if</span> <span class="s2">&quot;Feature-Token Length Ratio&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Feature-Token Length Ratio&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Feature-Token Length Ratio&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feat_token_len_ratio</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

            <span class="c1"># --- 4. Supervised Metrics Calculation (Reference is involved here)  --- #</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">decode_only</span><span class="p">:</span>
                <span class="c1"># obtain the cer and wer metrics</span>
                <span class="n">cer</span><span class="p">,</span> <span class="n">wer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">hypo_text</span><span class="o">=</span><span class="n">hypo_text</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">real_text</span><span class="o">=</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">i_num</span><span class="p">,</span> <span class="n">d_num</span><span class="p">,</span> <span class="n">s_num</span><span class="p">,</span> <span class="n">align_table</span> <span class="o">=</span> <span class="n">get_word_edit_alignment</span><span class="p">(</span>
                    <span class="n">hypo_text</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="p">)</span>

                <span class="c1"># record the string of hypothesis-reference alignment table</span>
                <span class="n">align_table_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">align_table</span><span class="p">)</span>

                <span class="c1"># record the CER value of the current data instance</span>
                <span class="n">cer_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cer</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="k">if</span> <span class="s2">&quot;CER&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;CER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;CER&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># record the WER value of the current data instance</span>
                <span class="n">wer_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wer</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="k">if</span> <span class="s2">&quot;WER&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;WER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;WER&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">wer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># record the word insertion value of the current data instance</span>
                <span class="n">insertion_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i_num</span><span class="p">)</span>
                <span class="k">if</span> <span class="s2">&quot;Word Insertion&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Word Insertion&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Word Insertion&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i_num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># record the word deletion value of the current data instance</span>
                <span class="n">deletion_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d_num</span><span class="p">)</span>
                <span class="k">if</span> <span class="s2">&quot;Word Deletion&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Word Deletion&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Word Deletion&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">d_num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># record the word substitution value of the current data instance</span>
                <span class="n">substitution_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s_num</span><span class="p">)</span>
                <span class="k">if</span> <span class="s2">&quot;Word Substitution&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Word Substitution&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Word Substitution&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">s_num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># register the instance reports and the strings of alignment tables for generating instance_reports.md</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_instance_reports</span><span class="p">(</span>
            <span class="n">md_list_dict</span><span class="o">=</span><span class="n">instance_report_dict</span><span class="p">,</span> <span class="n">extra_string_list</span><span class="o">=</span><span class="n">align_table_list</span>
        <span class="p">)</span>

        <span class="c1"># not return the supervised metrics in the decoding-only mode</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">decode_only</span><span class="p">:</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="n">cer</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">cer_list</span><span class="p">),</span>
                <span class="n">wer</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">wer_list</span><span class="p">),</span>
                <span class="n">insertion</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">insertion_list</span><span class="p">),</span>
                <span class="n">deletion</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">deletion_list</span><span class="p">),</span>
                <span class="n">substitution</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">substitution_list</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="model.ar_asr.ARASR.criterion_init" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">criterion_init</span><span class="p">(</span><span class="n">ce_loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ilm_loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ctc_loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">att_guid_loss</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<details class="this-function-initializes-all-the-necessary-_criterion_-members" open>
  <summary>This function initializes all the necessary <em>Criterion</em> members</summary>
  <ol>
<li><code>speechain.criterion.cross_entropy.CrossEntropy</code> for training loss calculation.</li>
<li><code>speechain.criterion.ctc.CTCLoss</code> for training loss calculation.</li>
<li><code>speechain.criterion.accuracy.Accuracy</code> for teacher-forcing validation accuracy calculation.</li>
<li><code>speechain.criterion.error_rate.ErrorRate</code> for evaluation CER &amp; WER calculation.</li>
</ol>
</details>

<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>ce_loss</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict[str, Any]
The arguments for CrossEntropy(). If not given, the default setting of CrossEntropy() will be used.
Please refer to speechain.criterion.cross_entropy.CrossEntropy for more details.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ilm_loss</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ctc_loss</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="typing.Any">Any</span>] or bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict[str, Any] or bool
The arguments for CTCLoss(). If not given, self.ctc_loss won't be initialized.
This argument can also be set to a bool value 'True'. If True, the default setting of CTCLoss()
will be used.
Please refer to speechain.criterion.ctc.CTCLoss for more details.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>att_guid_loss</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="typing.Any">Any</span>] or bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict[str, Any] or bool
The arguments for AttentionGuidance(). If not given, self.att_guid_loss won't be initialized.
This argument can also be set to a bool value 'True'. If True, the default setting of AttentionGuidance()
will be used.
Please refer to speechain.criterion.att_guid.AttentionGuidance for more details.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/ar_asr.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">criterion_init</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">ce_loss</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ilm_loss</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ctc_loss</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="ow">or</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">att_guid_loss</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="ow">or</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function initializes all the necessary _Criterion_ members:</span>
<span class="sd">        1. `speechain.criterion.cross_entropy.CrossEntropy` for training loss calculation.</span>
<span class="sd">        2. `speechain.criterion.ctc.CTCLoss` for training loss calculation.</span>
<span class="sd">        3. `speechain.criterion.accuracy.Accuracy` for teacher-forcing validation accuracy calculation.</span>
<span class="sd">        4. `speechain.criterion.error_rate.ErrorRate` for evaluation CER &amp; WER calculation.</span>

<span class="sd">    Args:</span>
<span class="sd">        ce_loss: Dict[str, Any]</span>
<span class="sd">            The arguments for CrossEntropy(). If not given, the default setting of CrossEntropy() will be used.</span>
<span class="sd">            Please refer to speechain.criterion.cross_entropy.CrossEntropy for more details.</span>
<span class="sd">        ilm_loss:</span>
<span class="sd">        ctc_loss: Dict[str, Any] or bool</span>
<span class="sd">            The arguments for CTCLoss(). If not given, self.ctc_loss won&#39;t be initialized.</span>
<span class="sd">            This argument can also be set to a bool value &#39;True&#39;. If True, the default setting of CTCLoss()</span>
<span class="sd">            will be used.</span>
<span class="sd">            Please refer to speechain.criterion.ctc.CTCLoss for more details.</span>
<span class="sd">        att_guid_loss: Dict[str, Any] or bool</span>
<span class="sd">            The arguments for AttentionGuidance(). If not given, self.att_guid_loss won&#39;t be initialized.</span>
<span class="sd">            This argument can also be set to a bool value &#39;True&#39;. If True, the default setting of AttentionGuidance()</span>
<span class="sd">            will be used.</span>
<span class="sd">            Please refer to speechain.criterion.att_guid.AttentionGuidance for more details.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># initialize cross-entropy loss for the encoder-decoder</span>
    <span class="k">if</span> <span class="n">ce_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ce_loss</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ce_loss</span> <span class="o">=</span> <span class="n">CrossEntropy</span><span class="p">(</span><span class="o">**</span><span class="n">ce_loss</span><span class="p">)</span>

    <span class="c1"># initialize cross-entropy loss for the internal LM</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># ilm_loss is default to be normalized by sentence lengths</span>
        <span class="k">if</span> <span class="n">ilm_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ilm_loss</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">length_normalized</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ilm_loss</span> <span class="o">=</span> <span class="n">CrossEntropy</span><span class="p">(</span><span class="o">**</span><span class="n">ilm_loss</span><span class="p">)</span>

    <span class="c1"># initialize ctc loss</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># if ctc_loss is given as True or None, the default arguments of CTCLoss will be used</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ctc_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
            <span class="n">ctc_loss</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="s2">&quot;cpu&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;For speeding up CTC calculation by CuDNN, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;please set the blank id to 0 (got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span><span class="si">}</span><span class="s2">).&quot;</span>
            <span class="p">)</span>

        <span class="n">ctc_loss</span><span class="p">[</span><span class="s2">&quot;blank&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ctc_loss</span> <span class="o">=</span> <span class="n">CTCLoss</span><span class="p">(</span><span class="o">**</span><span class="n">ctc_loss</span><span class="p">)</span>

    <span class="c1"># initialize attention guidance loss</span>
    <span class="k">if</span> <span class="n">att_guid_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># if att_guid_loss is given as True, the default arguments of AttentionGuidance will be used</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="n">att_guid_loss</span>
            <span class="p">),</span> <span class="s2">&quot;If you want to use the default setting of AttentionGuidance, please give att_guid_loss as True.&quot;</span>
            <span class="n">att_guid_loss</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="s2">&quot;encdec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span>
        <span class="p">),</span> <span class="s2">&quot;If you want to enable attention guidance for ASR training, please include &#39;encdec&#39; in return_att_type.&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span> <span class="o">=</span> <span class="n">AttentionGuidance</span><span class="p">(</span><span class="o">**</span><span class="n">att_guid_loss</span><span class="p">)</span>

    <span class="c1"># initialize teacher-forcing accuracy for validation</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">Accuracy</span><span class="p">()</span>

    <span class="c1"># initialize text perplexity calculator for internal LM if needed</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">perplexity</span> <span class="o">=</span> <span class="n">Perplexity</span><span class="p">()</span>

    <span class="c1"># initialize error rate (CER &amp; WER) for evaluation</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span> <span class="o">=</span> <span class="n">ErrorRate</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.ar_asr.ARASR.inference" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">inference</span><span class="p">(</span><span class="n">infer_conf</span><span class="p">,</span> <span class="n">feat</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feat_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_att</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">decode_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">teacher_forcing</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>The inference function for ASR models. There are two steps in this function:
    1. Decode the input speech into hypothesis transcript
    2. Evaluate the hypothesis transcript by the ground-truth</p>
<p>This function can be called for model evaluation, on-the-fly model visualization, and even pseudo transcript
generation during training.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>feat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor
The speech data to be inferred.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>feat_len</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor
The length of <code>feat</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>text</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor
The ground-truth transcript for the input speech</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>text_len</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor
The length of <code>text</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>domain</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>str = None
This argument indicates which domain the input speech belongs to.
It's used to indicate the <code>ASREncoder</code> member how to encode the input speech.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_att</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool = False
Whether the attention matrix of the input speech is returned.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>decode_only</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool = False
Whether skip the evaluation step and do the decoding step only.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>teacher_forcing</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool = True
Whether you use the teacher-forcing technique to generate the hypothesis transcript.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>infer_conf</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict
The inference configuration given from the <code>infer_cfg</code> in your <code>exp_cfg</code>.
For more details, please refer to speechain.infer_func.beam_search.beam_searching.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Dict</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Dict">Dict</span>[str, <span title="typing.Any">Any</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A Dict containing all the decoding and evaluation results.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/ar_asr.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inference</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">infer_conf</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">text</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">text_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">domain</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_att</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">decode_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">teacher_forcing</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The inference function for ASR models. There are two steps in this function:</span>
<span class="sd">        1. Decode the input speech into hypothesis transcript</span>
<span class="sd">        2. Evaluate the hypothesis transcript by the ground-truth</span>

<span class="sd">    This function can be called for model evaluation, on-the-fly model visualization, and even pseudo transcript</span>
<span class="sd">    generation during training.</span>

<span class="sd">    Args:</span>
<span class="sd">        # --- Testing data arguments --- #</span>
<span class="sd">        feat: torch.Tensor</span>
<span class="sd">            The speech data to be inferred.</span>
<span class="sd">        feat_len: torch.Tensor</span>
<span class="sd">            The length of `feat`.</span>
<span class="sd">        text: torch.Tensor</span>
<span class="sd">            The ground-truth transcript for the input speech</span>
<span class="sd">        text_len: torch.Tensor</span>
<span class="sd">            The length of `text`.</span>
<span class="sd">        # --- Explicit inference arguments --- #</span>
<span class="sd">        domain: str = None</span>
<span class="sd">            This argument indicates which domain the input speech belongs to.</span>
<span class="sd">            It&#39;s used to indicate the `ASREncoder` member how to encode the input speech.</span>
<span class="sd">        return_att: bool = False</span>
<span class="sd">            Whether the attention matrix of the input speech is returned.</span>
<span class="sd">        decode_only: bool = False</span>
<span class="sd">            Whether skip the evaluation step and do the decoding step only.</span>
<span class="sd">        teacher_forcing: bool = True</span>
<span class="sd">            Whether you use the teacher-forcing technique to generate the hypothesis transcript.</span>
<span class="sd">        # --- Implicit inference arguments given by infer_cfg from runner.py --- #</span>
<span class="sd">        infer_conf: Dict</span>
<span class="sd">            The inference configuration given from the `infer_cfg` in your `exp_cfg`.</span>
<span class="sd">            For more details, please refer to speechain.infer_func.beam_search.beam_searching.</span>

<span class="sd">    Returns: Dict</span>
<span class="sd">        A Dict containing all the decoding and evaluation results.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">feat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">feat_len</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="c1"># --- 0. Hyperparameter &amp; Model Preparation Stage --- #</span>
    <span class="c1"># in-place replace infer_conf to protect the original information</span>
    <span class="n">infer_conf</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">infer_conf</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;decode_only&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">decode_only</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;decode_only&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="s2">&quot;teacher_forcing&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">teacher_forcing</span> <span class="o">=</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;teacher_forcing&quot;</span><span class="p">)</span>
    <span class="n">hypo_text</span><span class="p">,</span> <span class="n">hypo_text_len</span><span class="p">,</span> <span class="n">feat_token_len_ratio</span><span class="p">,</span> <span class="n">hypo_text_confid</span><span class="p">,</span> <span class="n">hypo_att</span> <span class="o">=</span> <span class="p">(</span>
        <span class="kc">None</span><span class="p">,</span>
        <span class="kc">None</span><span class="p">,</span>
        <span class="kc">None</span><span class="p">,</span>
        <span class="kc">None</span><span class="p">,</span>
        <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># only initialize the language model when lm_weight is given as a positive float number</span>
    <span class="k">if</span> <span class="s2">&quot;lm_weight&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="ow">and</span> <span class="n">infer_conf</span><span class="p">[</span><span class="s2">&quot;lm_weight&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
            <span class="s2">&quot;If you want to use ASR-LM joint decoding, &quot;</span>
            <span class="s2">&quot;please give lm_model_cfg and lm_model_path in model[&#39;customize_conf&#39;]!&quot;</span>
        <span class="p">)</span>
        <span class="c1"># lazily initialize the language model only at the first time</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;lm&quot;</span><span class="p">):</span>
            <span class="c1"># use the built-in lm configuration if lm_model_cfg is not given</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">result_path</span><span class="p">,</span> <span class="s2">&quot;lm_model_cfg.yaml&quot;</span>
                <span class="p">)</span>

            <span class="c1"># get the Dict-like configuration for the language model</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="o">=</span> <span class="n">load_yaml</span><span class="p">(</span><span class="n">parse_path_args</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="p">))</span>
            <span class="k">if</span> <span class="s2">&quot;model&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="s2">&quot;module_conf&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="p">[</span><span class="s2">&quot;module_conf&quot;</span><span class="p">]</span>

            <span class="c1"># update the built-in configuration yaml file</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span>
                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span><span class="p">,</span> <span class="s2">&quot;lm_model_cfg.yaml&quot;</span><span class="p">),</span>
                <span class="s2">&quot;w&quot;</span><span class="p">,</span>
                <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">,</span>
            <span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lm</span> <span class="o">=</span> <span class="n">LanguageModel</span><span class="p">(</span>
                <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span>
            <span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># use the built-in lm model if lm_model_path is not given</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span><span class="p">,</span> <span class="s2">&quot;lm_model.pth&quot;</span><span class="p">)</span>

            <span class="c1"># load the parameters of the target lm</span>
            <span class="n">_lm_model_para</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
                <span class="n">parse_path_args</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lm_model_path</span><span class="p">),</span> <span class="n">map_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="n">lm_model_para</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">para</span> <span class="ow">in</span> <span class="n">_lm_model_para</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;lm.&quot;</span><span class="p">):</span>
                    <span class="n">key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;lm.&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">lm_model_para</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">para</span>

            <span class="c1"># update the built-in lm parameters and load them into the lm for inference</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
                <span class="n">lm_model_para</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span><span class="p">,</span> <span class="s2">&quot;lm_model.pth&quot;</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lm</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">lm_model_para</span><span class="p">)</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="c1"># --- 1. The 1st Pass: ASR Decoding by Beam Searching --- #</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">teacher_forcing</span><span class="p">:</span>
        <span class="c1"># copy the input data in advance for data safety</span>
        <span class="n">model_input</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">feat</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span><span class="o">=</span><span class="n">feat_len</span><span class="p">))</span>

        <span class="c1"># Encoding input speech</span>
        <span class="n">enc_feat</span><span class="p">,</span> <span class="n">enc_feat_mask</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">domain</span><span class="o">=</span><span class="n">domain</span><span class="p">,</span> <span class="o">**</span><span class="n">model_input</span><span class="p">)</span>

        <span class="c1"># generate the model hypothesis</span>
        <span class="n">infer_results</span> <span class="o">=</span> <span class="n">beam_searching</span><span class="p">(</span>
            <span class="n">enc_feat</span><span class="o">=</span><span class="n">enc_feat</span><span class="p">,</span>
            <span class="n">enc_feat_mask</span><span class="o">=</span><span class="n">enc_feat_mask</span><span class="p">,</span>
            <span class="n">asr_decode_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">,</span>
            <span class="n">ctc_decode_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ctc_layer</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;ctc_layer&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">lm_decode_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lm</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;lm&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
            <span class="n">sos_eos</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">sos_eos_idx</span><span class="p">,</span>
            <span class="n">padding_idx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span><span class="p">,</span>
            <span class="o">**</span><span class="n">infer_conf</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">hypo_text</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;hypo_text&quot;</span><span class="p">]</span>
        <span class="n">hypo_text_len</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;hypo_text_len&quot;</span><span class="p">]</span>
        <span class="n">feat_token_len_ratio</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;feat_token_len_ratio&quot;</span><span class="p">]</span>
        <span class="n">hypo_text_confid</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;hypo_text_confid&quot;</span><span class="p">]</span>

    <span class="c1"># --- 2. The 2nd Pass: ASR Decoding by Teacher Forcing --- #</span>
    <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="ow">or</span> <span class="n">return_att</span><span class="p">:</span>
        <span class="c1"># copy the input data in advance for data safety</span>
        <span class="n">model_input</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span>
            <span class="nb">dict</span><span class="p">(</span>
                <span class="n">feat</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span>
                <span class="n">feat_len</span><span class="o">=</span><span class="n">feat_len</span><span class="p">,</span>
                <span class="n">text</span><span class="o">=</span><span class="n">text</span> <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="k">else</span> <span class="n">hypo_text</span><span class="p">,</span>
                <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span> <span class="k">if</span> <span class="n">teacher_forcing</span> <span class="k">else</span> <span class="n">hypo_text_len</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">infer_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_forward</span><span class="p">(</span>
            <span class="n">return_att</span><span class="o">=</span><span class="n">return_att</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">domain</span><span class="p">,</span> <span class="o">**</span><span class="n">model_input</span>
        <span class="p">)</span>
        <span class="c1"># return the attention matrices</span>
        <span class="k">if</span> <span class="n">return_att</span><span class="p">:</span>
            <span class="n">hypo_att</span> <span class="o">=</span> <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span>

        <span class="c1"># update the hypothesis text-related data in the teacher forcing mode</span>
        <span class="k">if</span> <span class="n">teacher_forcing</span><span class="p">:</span>
            <span class="n">tf_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span>
                <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">,</span> <span class="n">forward_ctc</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">infer_results</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">tf_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">outputs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                    <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span>
                    <span class="n">content</span><span class="o">=</span><span class="p">(</span>
                        <span class="n">content</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">content</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span> <span class="k">else</span> <span class="n">to_cpu</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
                    <span class="p">),</span>
                <span class="p">)</span>

            <span class="c1"># the last token is meaningless because the text is padded with eos at the end</span>
            <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span>
                <span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">][:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
            <span class="p">)</span>
            <span class="n">hypo_text_prob</span><span class="p">,</span> <span class="n">hypo_text</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">infer_results</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># the original text contains both sos at the beginning and eos at the end</span>
            <span class="n">hypo_text_len</span> <span class="o">=</span> <span class="n">text_len</span> <span class="o">-</span> <span class="mi">2</span>
            <span class="n">feat_token_len_ratio</span> <span class="o">=</span> <span class="n">feat_len</span> <span class="o">/</span> <span class="p">(</span><span class="n">hypo_text_len</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">)</span>
            <span class="c1"># sum up the log-probability of all time steps to get the confidence</span>
            <span class="n">length_penalty</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">infer_conf</span><span class="p">[</span><span class="s2">&quot;length_penalty&quot;</span><span class="p">]</span>
                <span class="k">if</span> <span class="s2">&quot;length_penalty&quot;</span> <span class="ow">in</span> <span class="n">infer_conf</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                <span class="k">else</span> <span class="mf">1.0</span>
            <span class="p">)</span>
            <span class="n">hypo_text_confid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">hypo_text_prob</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span>
                <span class="n">hypo_text_len</span><span class="o">**</span><span class="n">length_penalty</span>
            <span class="p">)</span>

    <span class="c1"># turn the data all the unsupervised metrics into the cpu version (List)</span>
    <span class="c1"># consider one &lt;sos/eos&gt; at the end, so hypo_text_len is added to 1</span>
    <span class="n">hypo_text_len</span><span class="p">,</span> <span class="n">feat_token_len_ratio</span><span class="p">,</span> <span class="n">hypo_text_confid</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">to_cpu</span><span class="p">(</span><span class="n">hypo_text_len</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">to_cpu</span><span class="p">(</span><span class="n">feat_token_len_ratio</span><span class="p">),</span>
        <span class="n">to_cpu</span><span class="p">(</span><span class="n">hypo_text_confid</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># --- 3. Unsupervised Metrics Calculation (ground-truth text is not involved here) --- #</span>
    <span class="c1"># recover the text tensors back to text strings (removing the padding and sos/eos tokens)</span>
    <span class="c1"># hypo_text = [self.tokenizer.tensor2text(hypo[(hypo != self.tokenizer.ignore_idx) &amp;</span>
    <span class="c1">#                                              (hypo != self.tokenizer.sos_eos_idx)]) for hypo in hypo_text]</span>
    <span class="n">hypo_text</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tensor2text</span><span class="p">(</span><span class="n">hypo</span><span class="p">)</span> <span class="k">for</span> <span class="n">hypo</span> <span class="ow">in</span> <span class="n">hypo_text</span><span class="p">]</span>

    <span class="c1"># in the decoding-only mode, only the hypothesis-related results will be returned</span>
    <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
        <span class="n">text</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">hypo_text</span><span class="p">),</span>
        <span class="n">text_len</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">hypo_text_len</span><span class="p">),</span>
        <span class="n">feat_token_len_ratio</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">feat_token_len_ratio</span><span class="p">),</span>
        <span class="n">text_confid</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">hypo_text_confid</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c1"># add the attention matrix into the output Dict, only used for model visualization during training</span>
    <span class="c1"># because it will consume too much time for saving the attention matrices of all testing samples during testing</span>
    <span class="k">if</span> <span class="n">return_att</span><span class="p">:</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">att</span><span class="o">=</span><span class="n">hypo_att</span><span class="p">)</span>

    <span class="c1"># recover the text tensors back to text strings (removing the padding and sos/eos tokens)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="p">[</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">tensor2text</span><span class="p">(</span>
            <span class="n">real</span><span class="p">[</span>
                <span class="p">(</span><span class="n">real</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span><span class="p">)</span>
                <span class="o">&amp;</span> <span class="p">(</span><span class="n">real</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">sos_eos_idx</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">real</span> <span class="ow">in</span> <span class="n">text</span>
    <span class="p">]</span>
    <span class="c1"># evaluation reports for all the testing instances</span>
    <span class="p">(</span>
        <span class="n">instance_report_dict</span><span class="p">,</span>
        <span class="n">align_table_list</span><span class="p">,</span>
        <span class="n">cer_list</span><span class="p">,</span>
        <span class="n">wer_list</span><span class="p">,</span>
        <span class="n">insertion_list</span><span class="p">,</span>
        <span class="n">deletion_list</span><span class="p">,</span>
        <span class="n">substitution_list</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="p">({},</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>
    <span class="c1"># loop each sentence</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)):</span>
        <span class="c1"># add the confidence into instance_reports.md</span>
        <span class="k">if</span> <span class="s2">&quot;Hypothesis Confidence&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Hypothesis Confidence&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Hypothesis Confidence&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">hypo_text_confid</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="c1"># add the frame-token length ratio into instance_reports.md</span>
        <span class="k">if</span> <span class="s2">&quot;Feature-Token Length Ratio&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Feature-Token Length Ratio&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Feature-Token Length Ratio&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feat_token_len_ratio</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="c1"># --- 4. Supervised Metrics Calculation (Reference is involved here)  --- #</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">decode_only</span><span class="p">:</span>
            <span class="c1"># obtain the cer and wer metrics</span>
            <span class="n">cer</span><span class="p">,</span> <span class="n">wer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span><span class="p">(</span><span class="n">hypo_text</span><span class="o">=</span><span class="n">hypo_text</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">real_text</span><span class="o">=</span><span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">i_num</span><span class="p">,</span> <span class="n">d_num</span><span class="p">,</span> <span class="n">s_num</span><span class="p">,</span> <span class="n">align_table</span> <span class="o">=</span> <span class="n">get_word_edit_alignment</span><span class="p">(</span>
                <span class="n">hypo_text</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="p">)</span>

            <span class="c1"># record the string of hypothesis-reference alignment table</span>
            <span class="n">align_table_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">align_table</span><span class="p">)</span>

            <span class="c1"># record the CER value of the current data instance</span>
            <span class="n">cer_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cer</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="s2">&quot;CER&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;CER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;CER&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">cer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># record the WER value of the current data instance</span>
            <span class="n">wer_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">wer</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="s2">&quot;WER&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;WER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;WER&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">wer</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># record the word insertion value of the current data instance</span>
            <span class="n">insertion_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i_num</span><span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;Word Insertion&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Word Insertion&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Word Insertion&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i_num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># record the word deletion value of the current data instance</span>
            <span class="n">deletion_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d_num</span><span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;Word Deletion&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Word Deletion&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Word Deletion&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">d_num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># record the word substitution value of the current data instance</span>
            <span class="n">substitution_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s_num</span><span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;Word Substitution&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">instance_report_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Word Substitution&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">instance_report_dict</span><span class="p">[</span><span class="s2">&quot;Word Substitution&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">s_num</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># register the instance reports and the strings of alignment tables for generating instance_reports.md</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">register_instance_reports</span><span class="p">(</span>
        <span class="n">md_list_dict</span><span class="o">=</span><span class="n">instance_report_dict</span><span class="p">,</span> <span class="n">extra_string_list</span><span class="o">=</span><span class="n">align_table_list</span>
    <span class="p">)</span>

    <span class="c1"># not return the supervised metrics in the decoding-only mode</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">decode_only</span><span class="p">:</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="n">cer</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">cer_list</span><span class="p">),</span>
            <span class="n">wer</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">wer_list</span><span class="p">),</span>
            <span class="n">insertion</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">insertion_list</span><span class="p">),</span>
            <span class="n">deletion</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">deletion_list</span><span class="p">),</span>
            <span class="n">substitution</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s2">&quot;txt&quot;</span><span class="p">,</span> <span class="n">content</span><span class="o">=</span><span class="n">substitution_list</span><span class="p">),</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.ar_asr.ARASR.module_forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">module_forward</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feat</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feat_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_att</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>feat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch, feat_maxlen, feat_dim)
The input speech data. feat_dim = 1 in the case of raw speech waveforms.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>feat_len</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch,)
The lengths of input speech data</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>text</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch, text_maxlen)
The input text data with <sos/eos> at the beginning and end</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>text_len</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch,)
The lengths of input text data</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epoch</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The number of the current training epoch.
Mainly used for mean&amp;std calculation in the feature normalization</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>domain</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>str = None</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_att</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool
Controls whether the attention matrices of each layer in the encoder and decoder will be returned.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>kwargs</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Temporary register used to store the redundant arguments.</p>
              </div>
            </td>
            <td>
                  <code>{}</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/ar_asr.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">module_forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">text</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">text_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">domain</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_att</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        feat: (batch, feat_maxlen, feat_dim)</span>
<span class="sd">            The input speech data. feat_dim = 1 in the case of raw speech waveforms.</span>
<span class="sd">        feat_len: (batch,)</span>
<span class="sd">            The lengths of input speech data</span>
<span class="sd">        text: (batch, text_maxlen)</span>
<span class="sd">            The input text data with &lt;sos/eos&gt; at the beginning and end</span>
<span class="sd">        text_len: (batch,)</span>
<span class="sd">            The lengths of input text data</span>
<span class="sd">        epoch: int</span>
<span class="sd">            The number of the current training epoch.</span>
<span class="sd">            Mainly used for mean&amp;std calculation in the feature normalization</span>
<span class="sd">        domain: str = None</span>
<span class="sd">        return_att: bool</span>
<span class="sd">            Controls whether the attention matrices of each layer in the encoder and decoder will be returned.</span>
<span class="sd">        kwargs:</span>
<span class="sd">            Temporary register used to store the redundant arguments.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># para checking</span>
    <span class="k">assert</span> <span class="n">feat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">feat_len</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">assert</span> <span class="n">feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">text</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="n">feat_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">text_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span>
        <span class="mi">0</span>
    <span class="p">),</span> <span class="s2">&quot;The amounts of utterances and sentences are not equal to each other.&quot;</span>
    <span class="k">assert</span> <span class="n">feat_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span>
        <span class="mi">0</span>
    <span class="p">),</span> <span class="s2">&quot;The amounts of utterances and their lengths are not equal to each other.&quot;</span>
    <span class="k">assert</span> <span class="n">text_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="n">text</span><span class="o">.</span><span class="n">size</span><span class="p">(</span>
        <span class="mi">0</span>
    <span class="p">),</span> <span class="s2">&quot;The amounts of sentences and their lengths are not equal to each other.&quot;</span>

    <span class="c1"># remove the &lt;sos/eos&gt; at the end of each sentence</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">text_len</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
        <span class="n">text</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">text_len</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span>
    <span class="n">text</span><span class="p">,</span> <span class="n">text_len</span> <span class="o">=</span> <span class="n">text</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">text_len</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="c1"># --- 1. Encoder: Input Feature to Encoder Hidden Representation --- #</span>
    <span class="n">enc_returns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span>
        <span class="n">feat</span><span class="o">=</span><span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span><span class="o">=</span><span class="n">feat_len</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">domain</span>
    <span class="p">)</span>
    <span class="c1"># Transformer-based encoder additionally returns the encoder self-attention</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">enc_feat</span><span class="p">,</span> <span class="n">enc_feat_mask</span><span class="p">,</span> <span class="n">enc_attmat</span><span class="p">,</span> <span class="n">enc_hidden</span> <span class="o">=</span> <span class="n">enc_returns</span>
    <span class="c1"># RNN-based encoder doesn&#39;t return any attention</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="p">(</span><span class="n">enc_feat</span><span class="p">,</span> <span class="n">enc_feat_mask</span><span class="p">,</span> <span class="n">enc_hidden</span><span class="p">),</span> <span class="n">enc_attmat</span> <span class="o">=</span> <span class="n">enc_returns</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span>

    <span class="c1"># --- 2. Decoder: Encoder Hidden Representation to Decoder Hidden Representation --- #</span>
    <span class="n">dec_returns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
        <span class="n">enc_feat</span><span class="o">=</span><span class="n">enc_feat</span><span class="p">,</span> <span class="n">enc_feat_mask</span><span class="o">=</span><span class="n">enc_feat_mask</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span>
    <span class="p">)</span>
    <span class="c1"># Transformer-based decoder additionally returns the decoder self-attention</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dec_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">dec_feat</span><span class="p">,</span> <span class="n">dec_attmat</span><span class="p">,</span> <span class="n">encdec_attmat</span><span class="p">,</span> <span class="n">dec_hidden</span> <span class="o">=</span> <span class="n">dec_returns</span>
    <span class="c1"># RNN-based decoder only returns the encoder-decoder attention</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">dec_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="p">(</span><span class="n">dec_feat</span><span class="p">,</span> <span class="n">encdec_attmat</span><span class="p">,</span> <span class="n">dec_hidden</span><span class="p">),</span> <span class="n">dec_attmat</span> <span class="o">=</span> <span class="n">dec_returns</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span>

    <span class="c1"># initialize the asr output to be the decoder predictions</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">dec_feat</span><span class="p">)</span>

    <span class="c1"># --- 3.(optional) Decoder: Internal LM Estimation by zeroing Encoder Hidden Representation --- #</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_weight</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_sub_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">ilm_returns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
            <span class="n">enc_feat</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="n">enc_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">enc_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">enc_feat</span><span class="o">.</span><span class="n">device</span>
            <span class="p">),</span>
            <span class="n">enc_feat_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
                <span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                <span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
                <span class="mi">1</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
            <span class="n">text_len</span><span class="o">=</span><span class="n">text_len</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Transformer-based decoder additionally returns the decoder self-attention</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ilm_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">ilm_feat</span><span class="p">,</span> <span class="n">ilm_dec_attmat</span><span class="p">,</span> <span class="n">ilm_encdec_attmat</span><span class="p">,</span> <span class="n">ilm_hidden</span> <span class="o">=</span> <span class="n">ilm_returns</span>
        <span class="c1"># RNN-based decoder only returns the encoder-decoder attention</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">ilm_returns</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="p">(</span><span class="n">ilm_feat</span><span class="p">,</span> <span class="n">ilm_encdec_attmat</span><span class="p">,</span> <span class="n">ilm_hidden</span><span class="p">),</span> <span class="n">ilm_dec_attmat</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">ilm_returns</span><span class="p">,</span>
                <span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ilm_logits</span><span class="o">=</span><span class="n">ilm_feat</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_sub_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;logits&quot;</span><span class="p">]</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ilm_sub_weight</span> <span class="o">*</span> <span class="n">ilm_feat</span>

    <span class="c1"># --- 4.(optional) Encoder Hidden Representation to CTC Prediction --- #</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;ctc_layer&quot;</span><span class="p">):</span>
        <span class="n">ctc_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_layer</span><span class="p">(</span><span class="n">enc_feat</span><span class="p">)</span>
        <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="n">ctc_logits</span><span class="o">=</span><span class="n">ctc_logits</span><span class="p">,</span>
            <span class="n">enc_feat_len</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">shrink_attention</span><span class="p">(</span><span class="n">input_att_list</span><span class="p">):</span>
        <span class="c1"># pick up the target attention layers</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_att_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span>
        <span class="p">):</span>
            <span class="n">input_att_list</span> <span class="o">=</span> <span class="n">input_att_list</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span> <span class="p">:]</span>
        <span class="c1"># pick up the target attention heads</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
            <span class="ow">and</span> <span class="n">input_att_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span>
        <span class="p">):</span>
            <span class="n">input_att_list</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">att</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span><span class="p">]</span> <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">input_att_list</span>
            <span class="p">]</span>
        <span class="k">return</span> <span class="n">input_att_list</span>

    <span class="c1"># return the attention results if specified</span>
    <span class="k">if</span> <span class="n">return_att</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;att_guid_loss&quot;</span><span class="p">):</span>
        <span class="c1"># encoder-decoder attention</span>
        <span class="k">if</span> <span class="s2">&quot;encdec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">:</span>
            <span class="c1"># register the encoder-decoder attention</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">att</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">encdec</span><span class="o">=</span><span class="n">shrink_attention</span><span class="p">(</span><span class="n">encdec_attmat</span><span class="p">)))</span>
        <span class="c1"># encoder self-attention</span>
        <span class="k">if</span> <span class="n">enc_attmat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;enc&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">:</span>
            <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">enc</span><span class="o">=</span><span class="n">shrink_attention</span><span class="p">(</span><span class="n">enc_attmat</span><span class="p">))</span>
        <span class="c1"># decoder self-attention</span>
        <span class="k">if</span> <span class="n">dec_attmat</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;dec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">:</span>
            <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;att&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">dec</span><span class="o">=</span><span class="n">shrink_attention</span><span class="p">(</span><span class="n">dec_attmat</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="model.ar_asr.ARASR.module_init" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">module_init</span><span class="p">(</span><span class="n">token_type</span><span class="p">,</span> <span class="n">token_path</span><span class="p">,</span> <span class="n">enc_prenet</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">dec_emb</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">frontend</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">specaug</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ilm_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">ilm_sub_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">ctc_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">audio_format</span><span class="o">=</span><span class="s1">&#39;wav&#39;</span><span class="p">,</span> <span class="n">return_att_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_att_head_num</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">return_att_layer_num</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">lm_model_cfg</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lm_model_path</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>This initialization function contains 4 steps:
1. <code>Tokenizer</code> initialization.
2. <code>ASREncoder</code> initialization.
3. <code>ARASRDecoder</code> initialization.
4. (optional) 'CTC' layer initialization</p>
<p>The input arguments of this function are two-fold:
1. the ones from <code>customize_conf</code> of <code>model</code> in <code>train_cfg</code>
2. the ones from <code>module_conf</code> of <code>model</code> in <code>train_cfg</code></p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>frontend</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(optional)
The configuration of the acoustic feature extraction frontend in the <code>ASREncoder</code> member.
This argument must be given since our toolkit doesn't support time-domain ASR.
For more details about how to give <code>frontend</code>, please refer to speechain.module.encoder.asr.ASREncoder.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>normalize</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span> or bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(optional)
The configuration of the normalization layer in the <code>ASREncoder</code> member.
This argument can also be given as a bool value.
True means the default configuration and False means no normalization.
For more details about how to give <code>normalize</code>, please refer to
    speechain.module.norm.feat_norm.FeatureNormalization.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>specaug</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span> or bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(optional)
The configuration of the SpecAugment layer in the <code>ASREncoder</code> member.
This argument can also be given as a bool value.
True means the default configuration and False means no SpecAugment.
For more details about how to give <code>specaug</code>, please refer to
    speechain.module.augment.specaug.SpecAugment.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>enc_prenet</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(mandatory)
The configuration of the prenet in the <code>ASREncoder</code> member.
The encoder prenet embeds the input acoustic features into hidden embeddings before feeding them into
the encoder.
For more details about how to give <code>enc_prent</code>, please refer to speechain.module.encoder.asr.ASREncoder.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>encoder</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(mandatory)
The configuration of the encoder main body in the <code>ASREncoder</code> member.
The encoder embeds the hidden embeddings into the encoder representations at each time steps of the
input acoustic features.
For more details about how to give <code>encoder</code>, please refer to speechain.module.encoder.asr.ASREncoder.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dec_emb</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(mandatory)
The configuration of the embedding layer in the <code>ARASRDecoder</code> member.
The decoder prenet embeds the input token ids into hidden embeddings before feeding them into
the decoder.
For more details about how to give <code>dec_emb</code>, please refer to speechain.module.encoder.asr.ASREncoder.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>decoder</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(mandatory)
The configuration of the decoder main body in the <code>ARASRDecoder</code> member.
The decoder predicts the probability of the next token at each time steps based on the token embeddings.
For more details about how to give <code>decoder</code>, please refer to speechain.module.decoder.ar_asr.ARASRDecoder.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>token_type</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(mandatory)
The type of the built-in tokenizer.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>token_path</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(mandatory)
The path of the vocabulary for initializing the built-in tokenizer.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sample_rate</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int = 16000 (optional)
The sampling rate of the input speech.
Currently, it's used for acoustic feature extraction frontend initialization and tensorboard register of
the input speech for model visualization.
In the future, this argument will also be used to on-the-fly downsample the input speech.</p>
              </div>
            </td>
            <td>
                  <code>16000</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>audio_format</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(optional)
This argument is only used for input speech recording during model visualization.</p>
              </div>
            </td>
            <td>
                  <code>&#39;wav&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_att_type</code>
            </td>
            <td>
                  <code><span title="typing.List">List</span>[str] or str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List[str] or str = ['encdec', 'enc', 'dec']
The type of attentions you want to return for both attention guidance and attention visualization.
It can be given as a string (one type) or a list of strings (multiple types).
The type should be one of
    1. 'encdec': the encoder-decoder attention, shared by both Transformer and RNN
    2. 'enc': the encoder self-attention, only for Transformer
    3. 'dec': the decoder self-attention, only for Transformer</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_att_head_num</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int = -1
The number of returned attention heads. If -1, all the heads in an attention layer will be returned.
RNN can be considered to one-head attention, so return_att_head_num &gt; 1 is equivalent to 1 for RNN.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_att_layer_num</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int = 1
The number of returned attention layers. If -1, all the attention layers will be returned.
RNN can be considered to one-layer attention, so return_att_layer_num &gt; 1 is equivalent to 1 for RNN.</p>
              </div>
            </td>
            <td>
                  <code>2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lm_model_cfg</code>
            </td>
            <td>
                  <code><span title="typing.Dict">Dict</span> or str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Dict or str
The configuration for the language model used for joint decoding.
Can be either a Dict or a string indicating where the .yaml model configuration file is placed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lm_model_path</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>str
The string indicating where the .pth model parameter file is placed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/model/ar_asr.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">module_init</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">token_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">token_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">enc_prenet</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">encoder</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">dec_emb</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">decoder</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">frontend</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">normalize</span><span class="p">:</span> <span class="n">Dict</span> <span class="ow">or</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">specaug</span><span class="p">:</span> <span class="n">Dict</span> <span class="ow">or</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ilm_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">ilm_sub_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">ctc_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16000</span><span class="p">,</span>
    <span class="n">audio_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;wav&quot;</span><span class="p">,</span>
    <span class="n">return_att_type</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="ow">or</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_att_head_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">return_att_layer_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">lm_model_cfg</span><span class="p">:</span> <span class="n">Dict</span> <span class="ow">or</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">lm_model_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This initialization function contains 4 steps:</span>
<span class="sd">    1. `Tokenizer` initialization.</span>
<span class="sd">    2. `ASREncoder` initialization.</span>
<span class="sd">    3. `ARASRDecoder` initialization.</span>
<span class="sd">    4. (optional) &#39;CTC&#39; layer initialization</span>

<span class="sd">    The input arguments of this function are two-fold:</span>
<span class="sd">    1. the ones from `customize_conf` of `model` in `train_cfg`</span>
<span class="sd">    2. the ones from `module_conf` of `model` in `train_cfg`</span>

<span class="sd">    Args:</span>
<span class="sd">        # --- module_conf arguments --- #</span>
<span class="sd">        frontend: (optional)</span>
<span class="sd">            The configuration of the acoustic feature extraction frontend in the `ASREncoder` member.</span>
<span class="sd">            This argument must be given since our toolkit doesn&#39;t support time-domain ASR.</span>
<span class="sd">            For more details about how to give `frontend`, please refer to speechain.module.encoder.asr.ASREncoder.</span>
<span class="sd">        normalize: (optional)</span>
<span class="sd">            The configuration of the normalization layer in the `ASREncoder` member.</span>
<span class="sd">            This argument can also be given as a bool value.</span>
<span class="sd">            True means the default configuration and False means no normalization.</span>
<span class="sd">            For more details about how to give `normalize`, please refer to</span>
<span class="sd">                speechain.module.norm.feat_norm.FeatureNormalization.</span>
<span class="sd">        specaug: (optional)</span>
<span class="sd">            The configuration of the SpecAugment layer in the `ASREncoder` member.</span>
<span class="sd">            This argument can also be given as a bool value.</span>
<span class="sd">            True means the default configuration and False means no SpecAugment.</span>
<span class="sd">            For more details about how to give `specaug`, please refer to</span>
<span class="sd">                speechain.module.augment.specaug.SpecAugment.</span>
<span class="sd">        enc_prenet: (mandatory)</span>
<span class="sd">            The configuration of the prenet in the `ASREncoder` member.</span>
<span class="sd">            The encoder prenet embeds the input acoustic features into hidden embeddings before feeding them into</span>
<span class="sd">            the encoder.</span>
<span class="sd">            For more details about how to give `enc_prent`, please refer to speechain.module.encoder.asr.ASREncoder.</span>
<span class="sd">        encoder: (mandatory)</span>
<span class="sd">            The configuration of the encoder main body in the `ASREncoder` member.</span>
<span class="sd">            The encoder embeds the hidden embeddings into the encoder representations at each time steps of the</span>
<span class="sd">            input acoustic features.</span>
<span class="sd">            For more details about how to give `encoder`, please refer to speechain.module.encoder.asr.ASREncoder.</span>
<span class="sd">        dec_emb: (mandatory)</span>
<span class="sd">            The configuration of the embedding layer in the `ARASRDecoder` member.</span>
<span class="sd">            The decoder prenet embeds the input token ids into hidden embeddings before feeding them into</span>
<span class="sd">            the decoder.</span>
<span class="sd">            For more details about how to give `dec_emb`, please refer to speechain.module.encoder.asr.ASREncoder.</span>
<span class="sd">        decoder: (mandatory)</span>
<span class="sd">            The configuration of the decoder main body in the `ARASRDecoder` member.</span>
<span class="sd">            The decoder predicts the probability of the next token at each time steps based on the token embeddings.</span>
<span class="sd">            For more details about how to give `decoder`, please refer to speechain.module.decoder.ar_asr.ARASRDecoder.</span>
<span class="sd">        # --- customize_conf arguments --- #</span>
<span class="sd">        token_type: (mandatory)</span>
<span class="sd">            The type of the built-in tokenizer.</span>
<span class="sd">        token_path: (mandatory)</span>
<span class="sd">            The path of the vocabulary for initializing the built-in tokenizer.</span>
<span class="sd">        sample_rate: int = 16000 (optional)</span>
<span class="sd">            The sampling rate of the input speech.</span>
<span class="sd">            Currently, it&#39;s used for acoustic feature extraction frontend initialization and tensorboard register of</span>
<span class="sd">            the input speech for model visualization.</span>
<span class="sd">            In the future, this argument will also be used to on-the-fly downsample the input speech.</span>
<span class="sd">        audio_format: (optional)</span>
<span class="sd">            This argument is only used for input speech recording during model visualization.</span>
<span class="sd">        return_att_type: List[str] or str = [&#39;encdec&#39;, &#39;enc&#39;, &#39;dec&#39;]</span>
<span class="sd">            The type of attentions you want to return for both attention guidance and attention visualization.</span>
<span class="sd">            It can be given as a string (one type) or a list of strings (multiple types).</span>
<span class="sd">            The type should be one of</span>
<span class="sd">                1. &#39;encdec&#39;: the encoder-decoder attention, shared by both Transformer and RNN</span>
<span class="sd">                2. &#39;enc&#39;: the encoder self-attention, only for Transformer</span>
<span class="sd">                3. &#39;dec&#39;: the decoder self-attention, only for Transformer</span>
<span class="sd">        return_att_head_num: int = -1</span>
<span class="sd">            The number of returned attention heads. If -1, all the heads in an attention layer will be returned.</span>
<span class="sd">            RNN can be considered to one-head attention, so return_att_head_num &gt; 1 is equivalent to 1 for RNN.</span>
<span class="sd">        return_att_layer_num: int = 1</span>
<span class="sd">            The number of returned attention layers. If -1, all the attention layers will be returned.</span>
<span class="sd">            RNN can be considered to one-layer attention, so return_att_layer_num &gt; 1 is equivalent to 1 for RNN.</span>
<span class="sd">        lm_model_cfg: Dict or str</span>
<span class="sd">            The configuration for the language model used for joint decoding.</span>
<span class="sd">            Can be either a Dict or a string indicating where the .yaml model configuration file is placed.</span>
<span class="sd">        lm_model_path: str</span>
<span class="sd">            The string indicating where the .pth model parameter file is placed.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># --- 1. Module-independent Initialization --- #</span>
    <span class="c1"># initialize the tokenizer</span>
    <span class="k">if</span> <span class="n">token_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;char&quot;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">CharTokenizer</span><span class="p">(</span><span class="n">token_path</span><span class="p">,</span> <span class="n">copy_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">token_type</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;sentencepiece&quot;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">SentencePieceTokenizer</span><span class="p">(</span>
            <span class="n">token_path</span><span class="p">,</span> <span class="n">copy_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">result_path</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unknown token_type </span><span class="si">{</span><span class="n">token_type</span><span class="si">}</span><span class="s2">. &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Currently, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> supports one of [&#39;char&#39;, &#39;sentencepiece&#39;].&quot;</span>
        <span class="p">)</span>

    <span class="c1"># initialize the sampling rate, mainly used for visualizing the input audio during training</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">audio_format</span> <span class="o">=</span> <span class="n">audio_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="c1"># attention-related</span>
    <span class="k">if</span> <span class="n">return_att_type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;encdec&quot;</span><span class="p">,</span> <span class="s2">&quot;enc&quot;</span><span class="p">,</span> <span class="s2">&quot;dec&quot;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">return_att_type</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">return_att_type</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span>
            <span class="k">else</span> <span class="p">[</span><span class="n">return_att_type</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">)):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;enc&quot;</span><span class="p">,</span> <span class="s2">&quot;dec&quot;</span><span class="p">,</span> <span class="s2">&quot;encdec&quot;</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The elements of your input return_att_type must be one of [&#39;enc&#39;, &#39;dec&#39;, &#39;encdec&#39;], &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">!&quot;</span>
            <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">return_att_head_num</span> <span class="o">=</span> <span class="n">return_att_head_num</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">return_att_layer_num</span> <span class="o">=</span> <span class="n">return_att_layer_num</span>

    <span class="c1"># language model-related, used for lazy initialization during inference</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_cfg</span> <span class="o">=</span> <span class="n">lm_model_cfg</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lm_model_path</span> <span class="o">=</span> <span class="n">lm_model_path</span>

    <span class="c1"># --- 2. Module Initialization --- #</span>
    <span class="c1"># --- 2.1 Encoder construction --- #</span>
    <span class="c1"># the sampling rate will be first initialized</span>
    <span class="k">if</span> <span class="s2">&quot;sr&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">frontend</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">frontend</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">][</span><span class="s2">&quot;sr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span>
    <span class="c1"># update the sampling rate into the ASR Model object</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sample_rate</span> <span class="o">=</span> <span class="n">frontend</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">][</span><span class="s2">&quot;sr&quot;</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">ASREncoder</span><span class="p">(</span>
        <span class="n">frontend</span><span class="o">=</span><span class="n">frontend</span><span class="p">,</span>
        <span class="n">normalize</span><span class="o">=</span><span class="n">normalize</span><span class="p">,</span>
        <span class="n">specaug</span><span class="o">=</span><span class="n">specaug</span><span class="p">,</span>
        <span class="n">prenet</span><span class="o">=</span><span class="n">enc_prenet</span><span class="p">,</span>
        <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
        <span class="n">distributed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># --- 2.2 CTC layer construction (optional) --- #</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ctc_weight</span> <span class="o">=</span> <span class="n">ctc_weight</span>
    <span class="k">assert</span> <span class="n">ctc_weight</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;ctc_weight cannot be lower than 0!&quot;</span>
    <span class="k">if</span> <span class="n">ctc_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ctc_layer</span> <span class="o">=</span> <span class="n">TokenPostnet</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span>
            <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># --- 2.3 Decoder construction --- #</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ilm_weight</span> <span class="o">=</span> <span class="n">ilm_weight</span>
    <span class="k">assert</span> <span class="n">ilm_weight</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;ilm_weight cannot be lower than 0!&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ilm_sub_weight</span> <span class="o">=</span> <span class="n">ilm_sub_weight</span>
    <span class="k">assert</span> <span class="n">ilm_sub_weight</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;ilm_sub_weight cannot be lower than 0!&quot;</span>
    <span class="c1"># the vocabulary size is given by the built-in tokenizer instead of the input configuration</span>
    <span class="k">if</span> <span class="s2">&quot;vocab_size&quot;</span> <span class="ow">in</span> <span class="n">dec_emb</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">dec_emb</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">][</span><span class="s2">&quot;vocab_size&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Your input vocabulary size is different from the one obtained from the built-in &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;tokenizer (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="si">}</span><span class="s2">). The latter one will be used to initialize the &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;decoder for correctness.&quot;</span>
            <span class="p">)</span>
        <span class="n">dec_emb</span><span class="p">[</span><span class="s2">&quot;conf&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;vocab_size&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">ARASRDecoder</span><span class="p">(</span>
        <span class="n">vocab_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding</span><span class="o">=</span><span class="n">dec_emb</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="model.ar_asr.MultiDataLoaderARASR" class="doc doc-heading">
            <code>MultiDataLoaderARASR</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="model.ar_asr.ARASR" href="#model.ar_asr.ARASR">ARASR</a></code></p>


        <p>Auto-Regressive ASR model trained by multiple dataloaders.</p>






              <details class="quote">
                <summary>Source code in <code>speechain/model/ar_asr.py</code></summary>
                <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">MultiDataLoaderARASR</span><span class="p">(</span><span class="n">ARASR</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Auto-Regressive ASR model trained by multiple dataloaders.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">criterion_init</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">loss_weights</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ce_loss</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ctc_loss</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">att_guid_loss</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>

        <span class="c1"># register the weight for each loss if loss_weights is given</span>
        <span class="k">if</span> <span class="n">loss_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">loss_name</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">loss_weights</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="mi">0</span> <span class="o">&lt;</span> <span class="n">weight</span> <span class="o">&lt;</span> <span class="mi">1</span>
                <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Your input weight should be a float number in (0, 1), but got loss_weights[</span><span class="si">{</span><span class="n">loss_name</span><span class="si">}</span><span class="s2">]=</span><span class="si">{</span><span class="n">weight</span><span class="si">}</span><span class="s2">!&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="p">[</span><span class="n">loss_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight</span>

        <span class="k">def</span> <span class="nf">recur_init_loss_by_dict</span><span class="p">(</span><span class="n">loss_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">loss_class</span><span class="p">):</span>
            <span class="n">leaf_num</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="p">[</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">loss_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
            <span class="p">)</span>
            <span class="c1"># all the items in loss_dict are not Dict mean that the loss function is shared by all the dataloaders</span>
            <span class="k">if</span> <span class="n">leaf_num</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_dict</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">loss_class</span><span class="p">(</span><span class="o">**</span><span class="n">loss_dict</span><span class="p">)</span>
            <span class="c1"># no item in loss_dict is Dict mean that each dataloader has its own loss function</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;loss_weights&quot;</span><span class="p">):</span>
                    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_dict</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span>
                    <span class="p">),</span> <span class="s2">&quot;The key number in the xxx_loss should match the one in the loss_weights&quot;</span>

                <span class="n">nested_loss</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">conf</span> <span class="ow">in</span> <span class="n">loss_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;loss_weights&quot;</span><span class="p">):</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
                        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;The key name </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> doesn&#39;t match anyone in the loss_weights!&quot;</span>
                    <span class="n">nested_loss</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_class</span><span class="p">(</span><span class="o">**</span><span class="n">conf</span><span class="p">)</span> <span class="k">if</span> <span class="n">conf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
                <span class="k">return</span> <span class="n">nested_loss</span>

        <span class="c1"># cross-entropy will be initialized no matter whether ce_loss is given or not</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ce_loss</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">recur_init_loss_by_dict</span><span class="p">(</span><span class="n">ce_loss</span><span class="p">,</span> <span class="n">CrossEntropy</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ce_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">CrossEntropy</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># only initialize ctc loss if it is given</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ctc_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
                <span class="n">ctc_loss</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="k">if</span> <span class="n">ctc_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">ctc_loss</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ctc_loss</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="nb">bool</span><span class="p">):</span>
                        <span class="n">ctc_loss</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">ctc_loss</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">else</span> <span class="kc">None</span>
                    <span class="k">if</span> <span class="n">ctc_loss</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="s2">&quot;cpu&quot;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;For speeding up CTC calculation by CuDNN, &quot;</span>
                                <span class="sa">f</span><span class="s2">&quot;please set the blank id to 0 (got </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span><span class="si">}</span><span class="s2">).&quot;</span>
                            <span class="p">)</span>
                        <span class="n">ctc_loss</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s2">&quot;blank&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">ignore_idx</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ctc_loss</span> <span class="o">=</span> <span class="n">recur_init_loss_by_dict</span><span class="p">(</span><span class="n">ctc_loss</span><span class="p">,</span> <span class="n">CTCLoss</span><span class="p">)</span>

        <span class="c1"># only initialize attention-guidance loss if it is given</span>
        <span class="k">if</span> <span class="n">att_guid_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="s2">&quot;encdec&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_att_type</span>
            <span class="p">),</span> <span class="s2">&quot;If you want to enable attention guidance for ASR training, please include &#39;encdec&#39; in return_att_type.&quot;</span>

            <span class="c1"># if att_guid_loss is given as True, the default arguments of AttentionGuidance will be used</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="n">att_guid_loss</span>
                <span class="p">),</span> <span class="s2">&quot;If you want to use the default setting of AttentionGuidance, please give att_guid_loss as True.&quot;</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span> <span class="o">=</span> <span class="n">recur_init_loss_by_dict</span><span class="p">(</span>
                    <span class="n">att_guid_loss</span><span class="p">,</span> <span class="n">AttentionGuidance</span>
                <span class="p">)</span>
            <span class="c1"># att_guid_loss is True, intialize the default AttentionGuidance criterion</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span> <span class="o">=</span> <span class="n">AttentionGuidance</span><span class="p">()</span>

        <span class="c1"># initialize teacher-forcing accuracy for validation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">Accuracy</span><span class="p">()</span>

        <span class="c1"># initialize error rate (CER &amp; WER) for evaluation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">error_rate</span> <span class="o">=</span> <span class="n">ErrorRate</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">module_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">batch_data</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>

        <span class="c1"># whether the input batch_data is generated by multiple dataloaders</span>
        <span class="n">multi_flag</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
        <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>

        <span class="c1"># Single-dataloader scenario</span>
        <span class="c1"># probably for the validation stage of in-domain semi-supervised ASR where we only have one data-label pair</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">multi_flag</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDataLoaderARASR</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">module_forward</span><span class="p">(</span><span class="o">**</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="c1"># Multi-dataloader scenario</span>
        <span class="c1"># For semi-supervised training or validation of out-domain semi-supervised ASR where we may have multiple</span>
        <span class="c1"># data-label pairs in a single batch, we need to go through forward function once for each pair.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># pop the non-Dict arguments from the input batch data</span>
            <span class="n">general_args</span><span class="p">,</span> <span class="n">data_keys</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(),</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch_data</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">data_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_data</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">Dict</span><span class="p">):</span>
                    <span class="n">general_args</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

            <span class="c1"># otherwise, go through the normal training process once for all the sub-batches</span>
            <span class="c1"># (each sub-batch corresponds to a dataloader)</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="n">domain</span><span class="p">:</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDataLoaderARASR</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">module_forward</span><span class="p">(</span>
                    <span class="n">domain</span><span class="o">=</span><span class="n">domain</span><span class="p">,</span> <span class="o">**</span><span class="n">general_args</span><span class="p">,</span> <span class="o">**</span><span class="n">domain_data</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">domain</span><span class="p">,</span> <span class="n">domain_data</span> <span class="ow">in</span> <span class="n">batch_data</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>

    <span class="k">def</span> <span class="nf">criterion_forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">data_output_dict</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]):</span>

        <span class="c1"># whether the input data_output_dict is generated by multiple dataloaders</span>
        <span class="n">multi_flag</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">data_output_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
        <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_output_dict</span><span class="p">)</span>

        <span class="c1"># Single-dataloader scenario</span>
        <span class="c1"># probably for the validation stage of in-domain semi-supervised ASR where we only have one data-label pair</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">multi_flag</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDataLoaderARASR</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span>
                <span class="o">**</span><span class="n">data_output_dict</span>
            <span class="p">)</span>
        <span class="c1"># Multi-dataloader scenario</span>
        <span class="c1"># For semi-supervised training or validation of out-domain semi-supervised ASR where we may have multiple</span>
        <span class="c1"># data-label pairs in a single batch, we need to go through forward function once for each pair.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">domain_list</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(),</span> <span class="nb">dict</span><span class="p">(),</span> <span class="nb">list</span><span class="p">(</span><span class="n">data_output_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span><span class="p">:</span>
                <span class="c1"># initialize the cross-entropy loss function</span>
                <span class="n">ce_loss_fn</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ce_loss</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ce_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span>
                    <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">ce_loss</span>
                <span class="p">)</span>
                <span class="c1"># initialize the ctc loss function only if ctc_loss is created</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;ctc_loss&quot;</span><span class="p">):</span>
                    <span class="n">ctc_loss_fn</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">ctc_loss</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ctc_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span>
                        <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">ctc_loss</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">ctc_loss_fn</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="c1"># initialize the attention-guidance loss function only if att_guid_loss is created</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;att_guid_loss&quot;</span><span class="p">):</span>
                    <span class="n">att_guid_loss_fn</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span>
                        <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">att_guid_loss</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">att_guid_loss_fn</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="c1"># call the criterion_forward() of the parent class by the initialized loss functions</span>
                <span class="n">_criteria</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDataLoaderARASR</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">criterion_forward</span><span class="p">(</span>
                    <span class="n">ce_loss_fn</span><span class="o">=</span><span class="n">ce_loss_fn</span><span class="p">,</span>
                    <span class="n">ctc_loss_fn</span><span class="o">=</span><span class="n">ctc_loss_fn</span><span class="p">,</span>
                    <span class="n">att_guid_loss_fn</span><span class="o">=</span><span class="n">att_guid_loss_fn</span><span class="p">,</span>
                    <span class="o">**</span><span class="n">data_output_dict</span><span class="p">[</span><span class="n">domain</span><span class="p">],</span>
                <span class="p">)</span>

                <span class="c1"># update loss and metric Dicts during training</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                    <span class="c1"># update the losses and metrics Dicts by the domain name at the beginning</span>
                    <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="o">**</span><span class="p">{</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">_key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">_value</span>
                            <span class="k">for</span> <span class="n">_key</span><span class="p">,</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">_criteria</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                    <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="o">**</span><span class="p">{</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">_key</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">_value</span>
                            <span class="k">for</span> <span class="n">_key</span><span class="p">,</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">_criteria</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                <span class="c1"># only update metric Dict during validation</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="o">**</span><span class="p">{</span>
                            <span class="p">(</span>
                                <span class="n">_key</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">domain_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">_key</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="p">):</span> <span class="n">_value</span>
                            <span class="k">for</span> <span class="n">_key</span><span class="p">,</span> <span class="n">_value</span> <span class="ow">in</span> <span class="n">_criteria</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                        <span class="p">}</span>
                    <span class="p">)</span>

            <span class="c1"># calculate the overall weighted loss during training</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="c1"># normalize losses of all the domains by the given loss_weights</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;loss_weights&quot;</span><span class="p">):</span>
                    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                        <span class="n">domain_list</span>
                    <span class="p">),</span> <span class="s2">&quot;There is a number mismatch of the domains between your data_cfg and train_cfg.&quot;</span>
                    <span class="k">assert</span> <span class="nb">sum</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">domain</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span><span class="p">]</span>
                    <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                        <span class="n">domain_list</span>
                    <span class="p">),</span> <span class="s2">&quot;There is a name mismatch of the domains between your data_cfg and train_cfg.&quot;</span>
                    <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="n">loss</span><span class="o">=</span><span class="nb">sum</span><span class="p">(</span>
                            <span class="p">[</span>
                                <span class="n">losses</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_loss&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span>
                                <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span>
                            <span class="p">]</span>
                        <span class="p">)</span>
                        <span class="o">/</span> <span class="nb">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_weights</span><span class="p">[</span><span class="n">domain</span><span class="p">]</span> <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span><span class="p">])</span>
                    <span class="p">)</span>
                <span class="c1"># average losses of all the domains if loss_weights is not given</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="n">loss</span><span class="o">=</span><span class="nb">sum</span><span class="p">([</span><span class="n">losses</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">domain</span><span class="si">}</span><span class="s2">_loss&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">domain</span> <span class="ow">in</span> <span class="n">domain_list</span><span class="p">])</span>
                        <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">domain_list</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">metrics</span>

    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">infer_conf</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="o">**</span><span class="n">test_batch</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>

        <span class="n">multi_flag</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
            <span class="p">[</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Dict</span><span class="p">)</span> <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
        <span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span>
        <span class="c1"># no sub-Dict means one normal supervised dataloader, go through the inference function of ASR</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">multi_flag</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDataLoaderARASR</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span>
                <span class="n">infer_conf</span><span class="o">=</span><span class="n">infer_conf</span><span class="p">,</span> <span class="o">**</span><span class="n">test_batch</span>
            <span class="p">)</span>

        <span class="c1"># sub-Dict means that the domain information is given for ASR inference</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
            <span class="p">),</span> <span class="s2">&quot;If you want to evaluate the ASR model by multiple domains, please evaluate them one by one.&quot;</span>
            <span class="k">for</span> <span class="n">domain</span><span class="p">,</span> <span class="n">domain_batch</span> <span class="ow">in</span> <span class="n">test_batch</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">MultiDataLoaderARASR</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span>
                    <span class="n">infer_conf</span><span class="o">=</span><span class="n">infer_conf</span><span class="p">,</span> <span class="n">domain</span><span class="o">=</span><span class="n">domain</span><span class="p">,</span> <span class="o">**</span><span class="n">domain_batch</span>
                <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.88dd0f4e.min.js"></script>
      
    
  </body>
</html>