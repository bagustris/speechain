
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Documentation for Speechain Toolkit">
      
      
      
      
        <link rel="prev" href="../">
      
      
        <link rel="next" href="../ctc_decoding/">
      
      
      <link rel="icon" href="../../../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.49">
    
    
      
        <title>beam_search - Speechain</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../css/code_select.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#infer_func.beam_search" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Speechain" class="md-header__button md-logo" aria-label="Speechain" data-md-component="logo">
      
  <img src="../../../img/speechain_inverted.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Speechain
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              beam_search
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/bagustris/speechain" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Speechain" class="md-nav__button md-logo" aria-label="Speechain" data-md-component="logo">
      
  <img src="../../../img/speechain_inverted.png" alt="logo">

    </a>
    Speechain
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/bagustris/speechain" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../recipes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Recipes
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ASR
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TTS
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../handbook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Handbook
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../criterion/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    criterion
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_1" id="__nav_7_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_1">
            <span class="md-nav__icon md-icon"></span>
            criterion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/accuracy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    accuracy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/att_guid/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    att_guid
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/bce_logits/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bce_logits
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/cross_entropy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cross_entropy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/ctc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctc
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/error_rate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    error_rate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/fbeta_score/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    fbeta_score
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/least_error/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    least_error
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../criterion/perplexity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    perplexity
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../dataset/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    dataset
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_2" id="__nav_7_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_2">
            <span class="md-nav__icon md-icon"></span>
            dataset
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/speech_text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_text
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    infer_func
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_3" id="__nav_7_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7_3">
            <span class="md-nav__icon md-icon"></span>
            infer_func
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    beam_search
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    beam_search
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#infer_func.beam_search" class="md-nav__link">
    <span class="md-ellipsis">
      beam_search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#infer_func.beam_search.BeamHypotheses" class="md-nav__link">
    <span class="md-ellipsis">
      BeamHypotheses
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BeamHypotheses">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#infer_func.beam_search.BeamHypotheses.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#infer_func.beam_search.BeamHypotheses.__len__" class="md-nav__link">
    <span class="md-ellipsis">
      __len__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#infer_func.beam_search.BeamHypotheses.add" class="md-nav__link">
    <span class="md-ellipsis">
      add
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#infer_func.beam_search.BeamHypotheses.is_done" class="md-nav__link">
    <span class="md-ellipsis">
      is_done
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#infer_func.beam_search.beam_searching" class="md-nav__link">
    <span class="md-ellipsis">
      beam_searching
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ctc_decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctc_decoding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tts_decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tts_decoding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../iterator/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    iterator
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_4" id="__nav_7_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_4">
            <span class="md-nav__icon md-icon"></span>
            iterator
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../iterator/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../iterator/block/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    block
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../model/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    model
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_5" id="__nav_7_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_5">
            <span class="md-nav__icon md-icon"></span>
            model
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model/ar_asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model/ar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_tts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model/lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    lm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model/nar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nar_tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    module
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6" id="__nav_7_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6">
            <span class="md-nav__icon md-icon"></span>
            module
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/augment/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    augment
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_2" id="__nav_7_6_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_2">
            <span class="md-nav__icon md-icon"></span>
            augment
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/augment/specaug/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    specaug
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/conformer/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    conformer
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_3" id="__nav_7_6_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_3">
            <span class="md-nav__icon md-icon"></span>
            conformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/conformer/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/conformer/encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/conformer/pos_enc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pos_enc
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/decoder/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    decoder
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_4" id="__nav_7_6_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_4">
            <span class="md-nav__icon md-icon"></span>
            decoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/decoder/ar_asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/decoder/ar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_tts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/decoder/nar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nar_tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/encoder/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    encoder
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_5" id="__nav_7_6_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_5">
            <span class="md-nav__icon md-icon"></span>
            encoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/speaker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speaker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/test_speaker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    test_speaker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/encoder/tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/frontend/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    frontend
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_6" id="__nav_7_6_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_6">
            <span class="md-nav__icon md-icon"></span>
            frontend
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/delta_feat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    delta_feat
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/linear2mel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear2mel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/speech2linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech2linear
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/frontend/speech2mel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech2mel
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/norm/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    norm
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_7" id="__nav_7_6_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_7">
            <span class="md-nav__icon md-icon"></span>
            norm
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/norm/feat_norm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feat_norm
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/postnet/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    postnet
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_8" id="__nav_7_6_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_8">
            <span class="md-nav__icon md-icon"></span>
            postnet
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/postnet/conv1d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv1d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/postnet/token/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    token
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_9" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/prenet/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    prenet
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_9" id="__nav_7_6_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_9">
            <span class="md-nav__icon md-icon"></span>
            prenet
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/conv1d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv1d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/conv2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv2d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/embed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    embed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/spk_embed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    spk_embed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/prenet/var_pred/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    var_pred
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_10" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/standalone/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    standalone
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_10" id="__nav_7_6_10_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_10">
            <span class="md-nav__icon md-icon"></span>
            standalone
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/standalone/lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    lm
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_11" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/transformer/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    transformer
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_11" id="__nav_7_6_11_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_11">
            <span class="md-nav__icon md-icon"></span>
            transformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    decoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/feed_forward/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feed_forward
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/transformer/pos_enc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pos_enc
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_6_12" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../module/vocoder/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    vocoder
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_6_12" id="__nav_7_6_12_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_7_6_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6_12">
            <span class="md-nav__icon md-icon"></span>
            vocoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/vocoder/hifigan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    hifigan
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../module/vocoder/test_hifigan/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    test_hifigan
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../monitor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    monitor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_8" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../optim_sche/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    optim_sche
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_8" id="__nav_7_8_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_8">
            <span class="md-nav__icon md-icon"></span>
            optim_sche
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optim_sche/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optim_sche/exp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    exp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../optim_sche/noam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    noam
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_9" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../pyscripts/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    pyscripts
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_9" id="__nav_7_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_9">
            <span class="md-nav__icon md-icon"></span>
            pyscripts
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/empty_file_checker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    empty_file_checker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/folder_summarizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    folder_summarizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/model_para_renamer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    model_para_renamer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/phn_duaration_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phn_duaration_visualizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/text_dist_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_dist_visualizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pyscripts/wavlen_dist_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wavlen_dist_visualizer
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../runner/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    runner
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../snapshooter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    snapshooter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_12" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../tokenizer/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    tokenizer
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_12" id="__nav_7_12_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_12">
            <span class="md-nav__icon md-icon"></span>
            tokenizer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/char/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    char
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/g2p/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    g2p
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenizer/sp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sp
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7_13" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../utilbox/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    utilbox
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7_13" id="__nav_7_13_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_13">
            <span class="md-nav__icon md-icon"></span>
            utilbox
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/data_loading_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_loading_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/data_saving_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_saving_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/dump_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    dump_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/eval_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    eval_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/feat_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feat_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/humanfriendly/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    humanfriendly
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/import_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    import_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/log_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    log_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/md_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    md_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/regex_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    regex_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/sb_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sb_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/spk_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    spk_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/tensor_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tensor_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/test_humanfriendly/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    test_humanfriendly
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/text_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/train_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    train_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/type_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    type_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilbox/yaml_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    yaml_util
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#infer_func.beam_search" class="md-nav__link">
    <span class="md-ellipsis">
      beam_search
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#infer_func.beam_search.BeamHypotheses" class="md-nav__link">
    <span class="md-ellipsis">
      BeamHypotheses
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BeamHypotheses">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#infer_func.beam_search.BeamHypotheses.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#infer_func.beam_search.BeamHypotheses.__len__" class="md-nav__link">
    <span class="md-ellipsis">
      __len__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#infer_func.beam_search.BeamHypotheses.add" class="md-nav__link">
    <span class="md-ellipsis">
      add
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#infer_func.beam_search.BeamHypotheses.is_done" class="md-nav__link">
    <span class="md-ellipsis">
      is_done
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#infer_func.beam_search.beam_searching" class="md-nav__link">
    <span class="md-ellipsis">
      beam_searching
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>beam_search</h1>

<div class="doc doc-object doc-module">



<a id="infer_func.beam_search"></a>
    <div class="doc doc-contents first">

        <p>Author: Heli Qi
Affiliation: NAIST
Date: 2022.07</p>
<p>Modified from
https://github.com/huggingface/transformers/blob/518bd02c9b71291333ef374f055a4d1ac3042654/src/transformers/generation_beam_search.py</p>








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="infer_func.beam_search.BeamHypotheses" class="doc doc-heading">
            <code>BeamHypotheses</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code>object</code></p>


        <p>Beam Hypothesis Container.</p>






              <details class="quote">
                <summary>Source code in <code>speechain/infer_func/beam_search.py</code></summary>
                <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">BeamHypotheses</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Beam Hypothesis Container.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beam_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">length_penalty</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize n-best list of hypotheses.</span>

<span class="sd">        Args:</span>
<span class="sd">            beam_size: int</span>
<span class="sd">                The number of beams used in this container</span>
<span class="sd">            max_length: int</span>
<span class="sd">                The maximal length of the generated hypotheses</span>
<span class="sd">            length_penalty: float</span>
<span class="sd">                The penalty you put on the hypothesis lengths.</span>
<span class="sd">                The larger length_penalty is, the longer your hypotheses will be.</span>
<span class="sd">                length_penalty=1 means no penalty on lengths.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># static variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># ignoring bos_token</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span> <span class="o">=</span> <span class="n">beam_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length_penalty</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">length_penalty</span>  <span class="c1"># length_penalty=1 means no penalty on length</span>
        <span class="p">)</span>

        <span class="c1"># dynamic variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beams</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">worst_score</span> <span class="o">=</span> <span class="mf">1e9</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Number of hypotheses generated so far.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beams</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hyp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">sum_logprobs</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add a new hypothesis to the container.</span>

<span class="sd">        Args:</span>
<span class="sd">            hyp: (hypo_len,)</span>
<span class="sd">                The generated hypothesis transcript.</span>
<span class="sd">            sum_logprobs: float</span>
<span class="sd">                The sum of log probability of each token prediction in the hypothesis.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># normalize the sum of log probability by the hypothesis length</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">sum_logprobs</span> <span class="o">/</span> <span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">hyp</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_penalty</span><span class="p">)</span>

        <span class="c1"># some beams remain undone or the score is better than the worst score so far</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span> <span class="ow">or</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">worst_score</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">beams</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">score</span><span class="p">,</span> <span class="n">hyp</span><span class="p">))</span>

            <span class="c1"># remove the worst hypothesis and update the worst score</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span><span class="p">:</span>
                <span class="n">sorted_scores</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
                    <span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beams</span><span class="p">)]</span>
                <span class="p">)</span>
                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">beams</span><span class="p">[</span><span class="n">sorted_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">worst_score</span> <span class="o">=</span> <span class="n">sorted_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="c1"># update the worst score</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">worst_score</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">worst_score</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">is_done</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">best_sum_logprobs</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">curr_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        whether the beam searching of this container is done or not</span>

<span class="sd">        Args:</span>
<span class="sd">            best_sum_logprobs: float</span>
<span class="sd">                The best log-prob sum we get in the current time step</span>
<span class="sd">            curr_len: int</span>
<span class="sd">                The length of the current input hypothesis</span>

<span class="sd">        Returns:</span>
<span class="sd">            A flag that indicates whether the beam searching of this container is done.</span>
<span class="sd">            True means the container already has &#39;beam_size&#39; hypotheses and the current hypothesis is not better than anyone of them.</span>
<span class="sd">            False means either the container has some empty beams or the current input hypothesis is better than the worst hypothesis.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># some beams are empty</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="c1"># no beam is empty</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">curr_len</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">curr_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span>
            <span class="n">curr_score</span> <span class="o">=</span> <span class="n">best_sum_logprobs</span> <span class="o">/</span> <span class="p">((</span><span class="n">curr_len</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_penalty</span><span class="p">)</span>

            <span class="c1"># whether the current score is worse than the worst score</span>
            <span class="k">return</span> <span class="n">curr_score</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">worst_score</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="infer_func.beam_search.BeamHypotheses.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">beam_size</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">length_penalty</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Initialize n-best list of hypotheses.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>beam_size</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The number of beams used in this container</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_length</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The maximal length of the generated hypotheses</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>length_penalty</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float
The penalty you put on the hypothesis lengths.
The larger length_penalty is, the longer your hypotheses will be.
length_penalty=1 means no penalty on lengths.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/infer_func/beam_search.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beam_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">length_penalty</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize n-best list of hypotheses.</span>

<span class="sd">    Args:</span>
<span class="sd">        beam_size: int</span>
<span class="sd">            The number of beams used in this container</span>
<span class="sd">        max_length: int</span>
<span class="sd">            The maximal length of the generated hypotheses</span>
<span class="sd">        length_penalty: float</span>
<span class="sd">            The penalty you put on the hypothesis lengths.</span>
<span class="sd">            The larger length_penalty is, the longer your hypotheses will be.</span>
<span class="sd">            length_penalty=1 means no penalty on lengths.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># static variables</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># ignoring bos_token</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span> <span class="o">=</span> <span class="n">beam_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">length_penalty</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">length_penalty</span>  <span class="c1"># length_penalty=1 means no penalty on length</span>
    <span class="p">)</span>

    <span class="c1"># dynamic variables</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">beams</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">worst_score</span> <span class="o">=</span> <span class="mf">1e9</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="infer_func.beam_search.BeamHypotheses.__len__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__len__</span><span class="p">()</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Number of hypotheses generated so far.</p>

            <details class="quote">
              <summary>Source code in <code>speechain/infer_func/beam_search.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Number of hypotheses generated so far.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beams</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="infer_func.beam_search.BeamHypotheses.add" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">add</span><span class="p">(</span><span class="n">hyp</span><span class="p">,</span> <span class="n">sum_logprobs</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Add a new hypothesis to the container.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>hyp</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(hypo_len,)
The generated hypothesis transcript.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sum_logprobs</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float
The sum of log probability of each token prediction in the hypothesis.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/infer_func/beam_search.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hyp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">sum_logprobs</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Add a new hypothesis to the container.</span>

<span class="sd">    Args:</span>
<span class="sd">        hyp: (hypo_len,)</span>
<span class="sd">            The generated hypothesis transcript.</span>
<span class="sd">        sum_logprobs: float</span>
<span class="sd">            The sum of log probability of each token prediction in the hypothesis.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># normalize the sum of log probability by the hypothesis length</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">sum_logprobs</span> <span class="o">/</span> <span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">hyp</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_penalty</span><span class="p">)</span>

    <span class="c1"># some beams remain undone or the score is better than the worst score so far</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span> <span class="ow">or</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">worst_score</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beams</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">score</span><span class="p">,</span> <span class="n">hyp</span><span class="p">))</span>

        <span class="c1"># remove the worst hypothesis and update the worst score</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span><span class="p">:</span>
            <span class="n">sorted_scores</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span>
                <span class="p">[(</span><span class="n">s</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beams</span><span class="p">)]</span>
            <span class="p">)</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">beams</span><span class="p">[</span><span class="n">sorted_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">worst_score</span> <span class="o">=</span> <span class="n">sorted_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># update the worst score</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">worst_score</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">worst_score</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="infer_func.beam_search.BeamHypotheses.is_done" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">is_done</span><span class="p">(</span><span class="n">best_sum_logprobs</span><span class="p">,</span> <span class="n">curr_len</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>whether the beam searching of this container is done or not</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>best_sum_logprobs</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float
The best log-prob sum we get in the current time step</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>curr_len</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The length of the current input hypothesis</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A flag that indicates whether the beam searching of this container is done.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>True means the container already has 'beam_size' hypotheses and the current hypothesis is not better than anyone of them.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>False means either the container has some empty beams or the current input hypothesis is better than the worst hypothesis.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/infer_func/beam_search.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">is_done</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">best_sum_logprobs</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">curr_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    whether the beam searching of this container is done or not</span>

<span class="sd">    Args:</span>
<span class="sd">        best_sum_logprobs: float</span>
<span class="sd">            The best log-prob sum we get in the current time step</span>
<span class="sd">        curr_len: int</span>
<span class="sd">            The length of the current input hypothesis</span>

<span class="sd">    Returns:</span>
<span class="sd">        A flag that indicates whether the beam searching of this container is done.</span>
<span class="sd">        True means the container already has &#39;beam_size&#39; hypotheses and the current hypothesis is not better than anyone of them.</span>
<span class="sd">        False means either the container has some empty beams or the current input hypothesis is better than the worst hypothesis.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># some beams are empty</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">beam_size</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="c1"># no beam is empty</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">curr_len</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">curr_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span>
        <span class="n">curr_score</span> <span class="o">=</span> <span class="n">best_sum_logprobs</span> <span class="o">/</span> <span class="p">((</span><span class="n">curr_len</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">length_penalty</span><span class="p">)</span>

        <span class="c1"># whether the current score is worse than the worst score</span>
        <span class="k">return</span> <span class="n">curr_score</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">worst_score</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>


<div class="doc doc-object doc-function">


<h2 id="infer_func.beam_search.beam_searching" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">beam_searching</span><span class="p">(</span><span class="n">enc_feat</span><span class="p">,</span> <span class="n">enc_feat_mask</span><span class="p">,</span> <span class="n">asr_decode_fn</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">sos_eos</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">beam_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">min_f2t_ratio</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">length_penalty</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">eos_filtering</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eos_threshold</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">ctc_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">ctc_decode_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ctc_temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">lm_weight</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">lm_temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">lm_decode_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lm_window_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ilm_sub_weight</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sent_per_beam</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h2>


    <div class="doc doc-contents ">

        <p>Batch version of beam searching to enable parallel computation. The basic idea is reshaping batch_size sentences
into (batch_size * beam_size) sentences.</p>
<p>However, the hypothesis text probabilities calculated by a batch of inputs and a single input are slightly
different due to the model accuracy. in rare cases, the best hypothesis with the highest probability may be different
when the beam searching process is performed in the batch level.</p>
<p>Therefore, batch-level beam searching is mainly used to speed up the pseudo text generation. For model visualization
during training or evaluation after training, we recommend you to perform the beam searching for each single input.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>enc_feat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch_size, feat_maxlen, enc_dim)
The final hidden representations from the encoder.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>enc_feat_mask</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch_size, 1, feat_maxlen)
The masks for the encoder representations.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>asr_decode_fn</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The function that decodes the hypothesis for one time step and get the next prediction.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>vocab_size</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The number of tokens in the vocabulary dictionary</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sos_eos</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The index of the <sos/eos> token.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>padding_idx</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The index of the padding token.</p>
              </div>
            </td>
            <td>
                  <code>0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>beam_size</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The number of beams used for each hypothesis sentence.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>min_f2t_ratio</code>
            </td>
            <td>
                  <code>float or int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float
The ratio of the hypothesis max length to encoder representation length (feat_maxlen).
Postive values mean the relative ratio.
Negative values mean the absolute max length of the hypothesis sentence.</p>
              </div>
            </td>
            <td>
                  <code>3.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>length_penalty</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float
The hypothesis score is divided by its length to prevent the short hypothesis.
length_penalty is the penalty on the hypothesis length.
The larger the value is, the longer hypothesis you will get.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>temperature</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float
The temperature coefficient used for calculating the log-softmax probability for the ASR decoder. The
higher temperature is (&gt;1), the more even token probability distribution you will get. Vice versa for the
lower temperature (&lt;1). Usually, raising the temperature up helps ASR in better decoding. The temperature
value needs to be tuned on your validation sets. The common practice is to start from 1.5 and search other
values in (1.0, 2.0).</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eos_filtering</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool
Controls whether the eos filtering is performed.
If True, the algorithm will only emit an eos when the eos probability is larger than some times the
maximum probability of the other tokens.
This function is default to be off since it may reversely aggravate the n-gram phrase repeating problem.
It's better to turn it on only when your model suffers from meeting eos very early on many testing cases.
reference: 'Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions'
    Section 3.1.2 in https://arxiv.org/pdf/1904.02619</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>eos_threshold</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float
The eos filtering threshold used for eos filtering. This threshold will be multiplied with the
maximum probability of the other tokens when deciding whether to emit an eos. The larger this threshold is (&gt;1),
the easier the hypothesis emits an eos. Vice versa for the smaller temperature (&lt;1).
The default value 1.5 comes from the reference paper above.</p>
              </div>
            </td>
            <td>
                  <code>1.5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ctc_weight</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float = 0.0
The weight putted on the CTC scores at each decoding step.</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ctc_decode_fn</code>
            </td>
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>= None
The CTC forward function for decoding the encoder hidden features.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lm_weight</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float = 0.0
The weight putted on the LM scores at each decoding step.</p>
              </div>
            </td>
            <td>
                  <code>0.2</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lm_temperature</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float = 1.0
The temperature coefficient used for calculating the log-softmax probability for the LM decoder.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lm_decode_fn</code>
            </td>
            <td>
                  <code><span title="speechain.model.lm.LM">LM</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>LM = None
The LM forward function for decoding the current partial hypothesis.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>ilm_sub_weight</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float = 0.0
The weight putted on the subtraction of the inner LM of the ASR model. The inner LM subtraction is used for
ASR-LM decoding. ilm_sub_weight is better to be tuned in [0.5*lm_weight, lm_weight].</p>
              </div>
            </td>
            <td>
                  <code>0.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sent_per_beam</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The number of sentences in each beam that are returned in this function.
sent_per_beam &gt; 1 is mainly used for data augmentation (under development).</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/infer_func/beam_search.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">beam_searching</span><span class="p">(</span>
    <span class="n">enc_feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">enc_feat_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">asr_decode_fn</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">sos_eos</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">padding_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">beam_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">min_f2t_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="ow">or</span> <span class="nb">int</span> <span class="o">=</span> <span class="mf">3.0</span><span class="p">,</span>
    <span class="n">length_penalty</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">eos_filtering</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">eos_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.5</span><span class="p">,</span>
    <span class="n">ctc_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">ctc_decode_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">ctc_temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">lm_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
    <span class="n">lm_temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">lm_decode_fn</span><span class="p">:</span> <span class="n">LM</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">lm_window_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ilm_sub_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">sent_per_beam</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Batch version of beam searching to enable parallel computation. The basic idea is reshaping batch_size sentences</span>
<span class="sd">    into (batch_size * beam_size) sentences.</span>

<span class="sd">    However, the hypothesis text probabilities calculated by a batch of inputs and a single input are slightly</span>
<span class="sd">    different due to the model accuracy. in rare cases, the best hypothesis with the highest probability may be different</span>
<span class="sd">    when the beam searching process is performed in the batch level.</span>

<span class="sd">    Therefore, batch-level beam searching is mainly used to speed up the pseudo text generation. For model visualization</span>
<span class="sd">    during training or evaluation after training, we recommend you to perform the beam searching for each single input.</span>

<span class="sd">    Args:</span>
<span class="sd">        enc_feat: (batch_size, feat_maxlen, enc_dim)</span>
<span class="sd">            The final hidden representations from the encoder.</span>
<span class="sd">        enc_feat_mask: (batch_size, 1, feat_maxlen)</span>
<span class="sd">            The masks for the encoder representations.</span>
<span class="sd">        asr_decode_fn:</span>
<span class="sd">            The function that decodes the hypothesis for one time step and get the next prediction.</span>
<span class="sd">        vocab_size: int</span>
<span class="sd">            The number of tokens in the vocabulary dictionary</span>
<span class="sd">        sos_eos: int</span>
<span class="sd">            The index of the &lt;sos/eos&gt; token.</span>
<span class="sd">        padding_idx: int</span>
<span class="sd">            The index of the padding token.</span>
<span class="sd">        beam_size: int</span>
<span class="sd">            The number of beams used for each hypothesis sentence.</span>
<span class="sd">        min_f2t_ratio: float</span>
<span class="sd">            The ratio of the hypothesis max length to encoder representation length (feat_maxlen).</span>
<span class="sd">            Postive values mean the relative ratio.</span>
<span class="sd">            Negative values mean the absolute max length of the hypothesis sentence.</span>
<span class="sd">        length_penalty: float</span>
<span class="sd">            The hypothesis score is divided by its length to prevent the short hypothesis.</span>
<span class="sd">            length_penalty is the penalty on the hypothesis length.</span>
<span class="sd">            The larger the value is, the longer hypothesis you will get.</span>
<span class="sd">        temperature: float</span>
<span class="sd">            The temperature coefficient used for calculating the log-softmax probability for the ASR decoder. The</span>
<span class="sd">            higher temperature is (&gt;1), the more even token probability distribution you will get. Vice versa for the</span>
<span class="sd">            lower temperature (&lt;1). Usually, raising the temperature up helps ASR in better decoding. The temperature</span>
<span class="sd">            value needs to be tuned on your validation sets. The common practice is to start from 1.5 and search other</span>
<span class="sd">            values in (1.0, 2.0).</span>
<span class="sd">        eos_filtering: bool</span>
<span class="sd">            Controls whether the eos filtering is performed.</span>
<span class="sd">            If True, the algorithm will only emit an eos when the eos probability is larger than some times the</span>
<span class="sd">            maximum probability of the other tokens.</span>
<span class="sd">            This function is default to be off since it may reversely aggravate the n-gram phrase repeating problem.</span>
<span class="sd">            It&#39;s better to turn it on only when your model suffers from meeting eos very early on many testing cases.</span>
<span class="sd">            reference: &#39;Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions&#39;</span>
<span class="sd">                Section 3.1.2 in https://arxiv.org/pdf/1904.02619</span>
<span class="sd">        eos_threshold: float</span>
<span class="sd">            The eos filtering threshold used for eos filtering. This threshold will be multiplied with the</span>
<span class="sd">            maximum probability of the other tokens when deciding whether to emit an eos. The larger this threshold is (&gt;1),</span>
<span class="sd">            the easier the hypothesis emits an eos. Vice versa for the smaller temperature (&lt;1).</span>
<span class="sd">            The default value 1.5 comes from the reference paper above.</span>
<span class="sd">        ctc_weight: float = 0.0</span>
<span class="sd">            The weight putted on the CTC scores at each decoding step.</span>
<span class="sd">        ctc_decode_fn: = None</span>
<span class="sd">            The CTC forward function for decoding the encoder hidden features.</span>
<span class="sd">        lm_weight: float = 0.0</span>
<span class="sd">            The weight putted on the LM scores at each decoding step.</span>
<span class="sd">        lm_temperature: float = 1.0</span>
<span class="sd">            The temperature coefficient used for calculating the log-softmax probability for the LM decoder.</span>
<span class="sd">        lm_decode_fn: LM = None</span>
<span class="sd">            The LM forward function for decoding the current partial hypothesis.</span>
<span class="sd">        ilm_sub_weight: float = 0.0</span>
<span class="sd">            The weight putted on the subtraction of the inner LM of the ASR model. The inner LM subtraction is used for</span>
<span class="sd">            ASR-LM decoding. ilm_sub_weight is better to be tuned in [0.5*lm_weight, lm_weight].</span>
<span class="sd">        sent_per_beam: int</span>
<span class="sd">            The number of sentences in each beam that are returned in this function.</span>
<span class="sd">            sent_per_beam &gt; 1 is mainly used for data augmentation (under development).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># --- 0. Arguments Checking --- #</span>
    <span class="k">if</span> <span class="n">sent_per_beam</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Currently, sent_per_beam &gt; 1 is not supported....&quot;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">ctc_weight</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;ctc_weight should be a non-negative float number, but got ctc_weight=</span><span class="si">{</span><span class="n">ctc_weight</span><span class="si">}</span><span class="s2">!&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">lm_weight</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;lm_weight should be a non-negative float number, but got lm_weight=</span><span class="si">{</span><span class="n">lm_weight</span><span class="si">}</span><span class="s2">!&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="mf">0.0</span> <span class="o">&lt;=</span> <span class="n">ilm_sub_weight</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;ilm_sub_weight should be a non-negative float number, but got ilm_sub_weight=</span><span class="si">{</span><span class="n">ilm_sub_weight</span><span class="si">}</span><span class="s2">!&quot;</span>

    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">ctc_temperature</span> <span class="o">&gt;</span> <span class="mf">0.0</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;ctc_temperature should be a positive float number, but got ctc_temperature=</span><span class="si">{</span><span class="n">ctc_temperature</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">temperature</span> <span class="o">&gt;</span> <span class="mf">0.0</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;temperature should be a positive float number, but got temperature=</span><span class="si">{</span><span class="n">temperature</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">lm_temperature</span> <span class="o">&gt;</span> <span class="mf">0.0</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;lm_temperature should be a positive float number, but got lm_temperature=</span><span class="si">{</span><span class="n">lm_temperature</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># --- 1. Reference Initialization --- #</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">enc_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">enc_feat_len</span> <span class="o">=</span> <span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># hypo_maxlen is uniformly calculated for all the sentences by the longest utterance</span>
    <span class="c1"># Since the utterances in a batch usually have the similar lengths, it won&#39;t be a big problem for text decoding</span>
    <span class="n">feat_maxlen</span> <span class="o">=</span> <span class="n">enc_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hypo_maxlen</span> <span class="o">=</span> <span class="p">(</span>
        <span class="nb">int</span><span class="p">(</span><span class="n">feat_maxlen</span> <span class="o">/</span> <span class="n">min_f2t_ratio</span><span class="p">)</span> <span class="k">if</span> <span class="n">min_f2t_ratio</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">int</span><span class="p">(</span><span class="o">-</span><span class="n">min_f2t_ratio</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">cuda_device</span> <span class="o">=</span> <span class="n">enc_feat</span><span class="o">.</span><span class="n">device</span>
    <span class="k">if</span> <span class="n">sos_eos</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sos_eos</span> <span class="o">=</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="c1"># --- 2. Encoder Feature Reshaping --- #</span>
    <span class="c1"># (batch_size, feat_maxlen, edim) -&gt; (batch_size, 1, feat_maxlen , edim)</span>
    <span class="n">enc_feat</span> <span class="o">=</span> <span class="n">enc_feat</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
    <span class="c1"># (batch_size, 1, feat_maxlen , edim) -&gt; (batch_size, beam_size, feat_maxlen, edim)</span>
    <span class="n">enc_feat</span> <span class="o">=</span> <span class="n">enc_feat</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">beam_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># (batch_size, beam_size, feat_maxlen, edim) -&gt; (batch_size × beam_size, feat_maxlen, edim)</span>
    <span class="n">enc_feat</span> <span class="o">=</span> <span class="n">enc_feat</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">enc_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">enc_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

    <span class="c1"># (batch_size, 1, feat_maxlen) -&gt; (batch_size, 1, 1, feat_maxlen)</span>
    <span class="n">enc_feat_mask</span> <span class="o">=</span> <span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
    <span class="c1"># (batch_size, 1, 1, feat_maxlen) -&gt; (batch_size, beam_size, 1, feat_maxlen)</span>
    <span class="n">enc_feat_mask</span> <span class="o">=</span> <span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">beam_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># (batch_size, beam_size, 1, feat_maxlen) -&gt; (batch_size × beam_size, 1, feat_maxlen)</span>
    <span class="n">enc_feat_mask</span> <span class="o">=</span> <span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
        <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

    <span class="c1"># --- 3. CTC Initialization --- #</span>
    <span class="k">if</span> <span class="n">ctc_decode_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ctc_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">ctc_logits</span> <span class="o">=</span> <span class="n">ctc_decode_fn</span><span class="p">(</span><span class="n">enc_feat</span><span class="p">)</span>
        <span class="c1"># CTC should not have any predictions on the sos_eos token</span>
        <span class="n">ctc_logits</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">sos_eos</span><span class="p">]</span> <span class="o">=</span> <span class="n">minus_inf</span>
        <span class="n">ctc_scorer</span> <span class="o">=</span> <span class="n">CTCPrefixScorer</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">ctc_logits</span> <span class="o">/</span> <span class="n">ctc_temperature</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">enc_lens</span><span class="o">=</span><span class="n">make_len_from_mask</span><span class="p">(</span><span class="n">enc_feat_mask</span><span class="p">),</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">beam_size</span><span class="o">=</span><span class="n">beam_size</span><span class="p">,</span>
            <span class="n">blank_index</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">,</span>
            <span class="n">eos_index</span><span class="o">=</span><span class="n">sos_eos</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ctc_scorer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">ctc_memory</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># --- 4. Registers Initialization --- #</span>
    <span class="c1"># build a hypothesis container for each sentence in the batch</span>
    <span class="n">generated_hyps</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">BeamHypotheses</span><span class="p">(</span><span class="n">beam_size</span><span class="p">,</span> <span class="n">hypo_maxlen</span><span class="p">,</span> <span class="n">length_penalty</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="c1"># Done flags for all sentences in the batch</span>
    <span class="n">done</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>
    <span class="c1"># scores of all beam containers (batch_size × beam_size,)</span>
    <span class="n">beam_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
        <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">beam_size</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cuda_device</span>
    <span class="p">)</span>
    <span class="n">beam_scores</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
    <span class="c1"># keep only the first to make sure no redundancy.</span>
    <span class="n">beam_scores</span><span class="o">.</span><span class="n">index_fill_</span><span class="p">(</span>
        <span class="mi">0</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cuda_device</span><span class="p">)</span> <span class="o">*</span> <span class="n">beam_size</span><span class="p">,</span> <span class="mf">0.0</span>
    <span class="p">)</span>

    <span class="c1"># start tokens for all sentences in a batch (batch_size × beam_size, 1)</span>
    <span class="n">hypo_text</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
        <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">beam_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">sos_eos</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cuda_device</span>
    <span class="p">)</span>
    <span class="n">hypo_text_len</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
        <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">beam_size</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cuda_device</span>
    <span class="p">)</span>

    <span class="c1"># --- 5. Beam Searching Algorithm --- #</span>
    <span class="k">while</span> <span class="n">hypo_text_len</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">hypo_maxlen</span><span class="p">:</span>
        <span class="c1"># --- 5.1. Attention-based Decoder Forward --- #</span>
        <span class="c1"># (batch_size × beam_size, curr_len) -&gt; (batch_size × beam_size, curr_len, vocab_size)</span>
        <span class="n">curr_outputs</span> <span class="o">=</span> <span class="n">asr_decode_fn</span><span class="p">(</span>
            <span class="n">enc_feat</span><span class="o">=</span><span class="n">enc_feat</span><span class="p">,</span>
            <span class="n">enc_feat_mask</span><span class="o">=</span><span class="n">enc_feat_mask</span><span class="p">,</span>
            <span class="n">text</span><span class="o">=</span><span class="n">hypo_text</span><span class="p">,</span>
            <span class="n">text_len</span><span class="o">=</span><span class="n">hypo_text_len</span><span class="p">,</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="c1"># (batch_size × beam_size, curr_len, vocab_size) -&gt; (batch_size × beam_size, vocab_size)</span>
        <span class="n">curr_outputs</span> <span class="o">=</span> <span class="n">curr_outputs</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">next_token_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">curr_outputs</span> <span class="o">/</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># --- 5.2. CTC Scorer Forward --- #</span>
        <span class="k">if</span> <span class="n">ctc_scorer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># block blank token</span>
            <span class="n">next_token_scores</span><span class="p">[:,</span> <span class="n">padding_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">minus_inf</span>
            <span class="n">ctc_token_scores</span><span class="p">,</span> <span class="n">ctc_memory</span> <span class="o">=</span> <span class="n">ctc_scorer</span><span class="o">.</span><span class="n">forward_step</span><span class="p">(</span>
                <span class="n">g</span><span class="o">=</span><span class="n">hypo_text</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:],</span> <span class="n">state</span><span class="o">=</span><span class="n">ctc_memory</span>
            <span class="p">)</span>
            <span class="n">next_token_scores</span> <span class="o">=</span> <span class="p">(</span>
                <span class="mi">1</span> <span class="o">-</span> <span class="n">ctc_weight</span>
            <span class="p">)</span> <span class="o">*</span> <span class="n">next_token_scores</span> <span class="o">+</span> <span class="n">ctc_weight</span> <span class="o">*</span> <span class="n">ctc_token_scores</span>

        <span class="c1"># --- 5.3. LM Forward --- #</span>
        <span class="k">if</span> <span class="n">lm_decode_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">lm_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># (batch_size × beam_size, curr_len) -&gt; (batch_size × beam_size, curr_len, vocab_size)</span>
            <span class="n">lm_outputs</span> <span class="o">=</span> <span class="n">lm_decode_fn</span><span class="p">(</span>
                <span class="n">text</span><span class="o">=</span><span class="p">(</span>
                    <span class="n">hypo_text</span>
                    <span class="k">if</span> <span class="n">lm_window_size</span> <span class="ow">is</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="n">hypo_text</span><span class="p">[:,</span> <span class="o">-</span><span class="n">lm_window_size</span><span class="p">:]</span>
                <span class="p">),</span>
                <span class="n">text_len</span><span class="o">=</span><span class="p">(</span>
                    <span class="n">hypo_text_len</span>
                    <span class="k">if</span> <span class="n">lm_window_size</span> <span class="ow">is</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">hypo_text_len</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="n">lm_window_size</span><span class="p">)</span>
                <span class="p">),</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="c1"># (batch_size × beam_size, curr_len, vocab_size) -&gt; (batch_size × beam_size, vocab_size)</span>
            <span class="n">lm_next_token_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span>
                <span class="n">lm_outputs</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">/</span> <span class="n">lm_temperature</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
            <span class="p">)</span>
            <span class="n">next_token_scores</span> <span class="o">=</span> <span class="n">next_token_scores</span> <span class="o">+</span> <span class="n">lm_weight</span> <span class="o">*</span> <span class="n">lm_next_token_scores</span>

            <span class="c1"># --- 5.3.1. Internal LM Subtraction (only available in LM forward) --- #</span>
            <span class="k">if</span> <span class="n">ilm_sub_weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># (batch_size × beam_size, curr_len) -&gt; (batch_size × beam_size, curr_len, vocab_size)</span>
                <span class="n">ilm_outputs</span> <span class="o">=</span> <span class="n">asr_decode_fn</span><span class="p">(</span>
                    <span class="c1"># enc_feat=torch.zeros_like(enc_feat),</span>
                    <span class="n">enc_feat</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                        <span class="n">enc_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">enc_feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">enc_feat</span><span class="o">.</span><span class="n">device</span>
                    <span class="p">),</span>
                    <span class="c1"># enc_feat_mask=enc_feat_mask,</span>
                    <span class="n">enc_feat_mask</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
                        <span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                        <span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
                        <span class="mi">1</span><span class="p">,</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
                        <span class="n">device</span><span class="o">=</span><span class="n">enc_feat_mask</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="c1"># the window size of internal LM is set to the same one with the external LM</span>
                    <span class="n">text</span><span class="o">=</span><span class="p">(</span>
                        <span class="n">hypo_text</span>
                        <span class="k">if</span> <span class="n">lm_window_size</span> <span class="ow">is</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="n">hypo_text</span><span class="p">[:,</span> <span class="o">-</span><span class="n">lm_window_size</span><span class="p">:]</span>
                    <span class="p">),</span>
                    <span class="n">text_len</span><span class="o">=</span><span class="p">(</span>
                        <span class="n">hypo_text_len</span>
                        <span class="k">if</span> <span class="n">lm_window_size</span> <span class="ow">is</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">hypo_text_len</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="n">lm_window_size</span><span class="p">)</span>
                    <span class="p">),</span>
                <span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
                <span class="c1"># (batch_size × beam_size, curr_len, vocab_size) -&gt; (batch_size × beam_size, vocab_size)</span>
                <span class="n">ilm_next_token_scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">ilm_outputs</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">next_token_scores</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">next_token_scores</span> <span class="o">-</span> <span class="n">ilm_sub_weight</span> <span class="o">*</span> <span class="n">ilm_next_token_scores</span>
                <span class="p">)</span>

        <span class="c1"># Calculate the score of the obtained token sequences so far</span>
        <span class="n">next_scores</span> <span class="o">=</span> <span class="n">next_token_scores</span> <span class="o">+</span> <span class="n">beam_scores</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span>
            <span class="n">next_token_scores</span>
        <span class="p">)</span>

        <span class="c1"># Arrange all beams of the same sentence into a single row to pick up the best predictions across all beams.</span>
        <span class="c1"># (batch_size × beam_size, vocab_size) -&gt; (batch_size, beam_size × vocab_size)</span>
        <span class="n">next_scores</span> <span class="o">=</span> <span class="n">next_scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Pick up beam_size × (beam_size + 1) tokens from (beam_size * vocab_size) candidates for algorithm robustness</span>
        <span class="c1"># mainly two usage:</span>
        <span class="c1">#   1. for different tokens of each beam in the first time step</span>
        <span class="c1">#   2. when meeting an eos token, complement the beams with the rest predictions</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">beam_size</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;=</span> <span class="n">vocab_size</span>
        <span class="p">),</span> <span class="s2">&quot;beam_size cannot be larger than vocab_size - 1 (exclude &lt;sos/eos&gt;)!&quot;</span>
        <span class="c1"># next_scores, next_tokens = torch.topk(next_scores, beam_size * (beam_size + 1), dim=1, largest=True, sorted=True)</span>
        <span class="n">next_scores</span><span class="p">,</span> <span class="n">next_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span>
            <span class="n">next_scores</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">beam_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">largest</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">sorted</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="c1"># batch-level beam results for all sentence, each element is a tri-tuple (score, token_id, effective_beam_id)</span>
        <span class="n">next_batch_beam</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># looping each sentence in a batch</span>
        <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
            <span class="c1"># if the current sentence is already finished, adding a padding token and continue</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]:</span>
                <span class="c1"># for the finished sentence, the padding token is added</span>
                <span class="n">next_batch_beam</span><span class="o">.</span><span class="n">extend</span><span class="p">([(</span><span class="mi">0</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span> <span class="o">*</span> <span class="n">beam_size</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="c1"># sentence-level beam results for all beams in the current sentence,</span>
            <span class="c1"># each element is a tri-tuple (score, token_id, effective_beam_id)</span>
            <span class="n">next_sent_beam</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="c1"># looping each beam, there are (beam_size * batch_size) candidate predictions in total.</span>
            <span class="k">for</span> <span class="n">beam_token_rank</span><span class="p">,</span> <span class="p">(</span><span class="n">beam_token_id</span><span class="p">,</span> <span class="n">beam_token_score</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="nb">zip</span><span class="p">(</span><span class="n">next_tokens</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">],</span> <span class="n">next_scores</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">])</span>
            <span class="p">):</span>
                <span class="c1"># the index number of the beam in a single sentence, range from 0 to beam_size-1</span>
                <span class="c1"># beam_id = beam_token_id // vocab_size</span>
                <span class="n">beam_id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">beam_token_id</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="o">=</span><span class="s2">&quot;floor&quot;</span><span class="p">)</span>
                <span class="c1"># the index number of the real token, range from 0 to vocab_size-1</span>
                <span class="n">token_id</span> <span class="o">=</span> <span class="n">beam_token_id</span> <span class="o">%</span> <span class="n">vocab_size</span>
                <span class="c1"># the index number of the beam across the current batch</span>
                <span class="c1"># ∈ {batch_idx * beam_size, ..., (batch_idx + 1) * beam_size - 1}</span>
                <span class="n">effective_beam_id</span> <span class="o">=</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="n">beam_size</span> <span class="o">+</span> <span class="n">beam_id</span>

                <span class="c1"># if the eos token is met, the predictions will be either saved as a hypothesis or simple removed.</span>
                <span class="k">if</span> <span class="n">token_id</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">sos_eos</span><span class="p">:</span>
                    <span class="c1"># the top beam_size elements in next_tokens have the largest prob,</span>
                    <span class="c1"># so the ones other than the first beam_size elements will be ignored even though eos is met.</span>
                    <span class="k">if</span> <span class="n">beam_token_rank</span> <span class="o">&gt;=</span> <span class="n">beam_size</span><span class="p">:</span>
                        <span class="k">continue</span>
                    <span class="c1"># conduct EOS filtering</span>
                    <span class="k">elif</span> <span class="n">eos_filtering</span><span class="p">:</span>
                        <span class="n">eos_score</span> <span class="o">=</span> <span class="n">next_token_scores</span><span class="p">[</span><span class="n">effective_beam_id</span><span class="p">][</span><span class="n">sos_eos</span><span class="p">]</span>
                        <span class="c1"># the largest token score other than eos is the reference score</span>
                        <span class="n">vocab_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
                        <span class="n">ref_score</span> <span class="o">=</span> <span class="n">next_token_scores</span><span class="p">[</span><span class="n">effective_beam_id</span><span class="p">][</span>
                            <span class="n">vocab_idx</span> <span class="o">!=</span> <span class="n">sos_eos</span>
                        <span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
                        <span class="c1"># only consider the eos whose score is larger than eos_threshold * reference score</span>
                        <span class="k">if</span> <span class="n">eos_score</span> <span class="o">&lt;=</span> <span class="n">eos_threshold</span> <span class="o">*</span> <span class="n">ref_score</span><span class="p">:</span>
                            <span class="k">continue</span>

                    <span class="n">generated_hyps</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
                        <span class="n">hyp</span><span class="o">=</span><span class="n">hypo_text</span><span class="p">[</span><span class="n">effective_beam_id</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span>
                        <span class="n">sum_logprobs</span><span class="o">=</span><span class="n">beam_token_score</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                    <span class="p">)</span>
                <span class="c1"># add the predictions into the temporary results.</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># # make sure that different tokens are selected for different beams in the first time step</span>
                    <span class="c1"># add_flag = True</span>
                    <span class="c1"># if hypo_text_len.max() == 1 and len(next_sent_beam) != 0:</span>
                    <span class="c1">#     for item in next_sent_beam:</span>
                    <span class="c1">#         if item[1] == token_id or item[2] == effective_beam_id:</span>
                    <span class="c1">#             add_flag = False</span>
                    <span class="c1">#             break</span>
                    <span class="c1"># if add_flag:</span>
                    <span class="c1">#     next_sent_beam.append((beam_token_score, token_id, effective_beam_id))</span>
                    <span class="n">next_sent_beam</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">beam_token_score</span><span class="p">,</span> <span class="n">token_id</span><span class="p">,</span> <span class="n">effective_beam_id</span><span class="p">)</span>
                    <span class="p">)</span>

                <span class="c1"># only get beam_size predictions from beam_size * beam_size candidates</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">next_sent_beam</span><span class="p">)</span> <span class="o">==</span> <span class="n">beam_size</span><span class="p">:</span>
                    <span class="k">break</span>

            <span class="c1"># update the done flag of the current sentence</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">done</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]:</span>
                <span class="n">done</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">generated_hyps</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">is_done</span><span class="p">(</span>
                    <span class="n">best_sum_logprobs</span><span class="o">=</span><span class="n">next_scores</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                    <span class="n">curr_len</span><span class="o">=</span><span class="n">hypo_text_len</span><span class="p">[</span>
                        <span class="n">batch_idx</span> <span class="o">*</span> <span class="n">beam_size</span> <span class="p">:</span> <span class="p">(</span><span class="n">batch_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">beam_size</span>
                    <span class="p">]</span>
                    <span class="o">.</span><span class="n">max</span><span class="p">()</span>
                    <span class="o">.</span><span class="n">item</span><span class="p">()</span>
                    <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="n">next_batch_beam</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">next_sent_beam</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">done</span><span class="p">):</span>
            <span class="k">break</span>

        <span class="c1"># Summary of the results of the selected predictions for all beams in the current time step</span>
        <span class="c1"># (batch_size * beam_size), beam score and beam index</span>
        <span class="n">beam_scores</span> <span class="o">=</span> <span class="n">beam_scores</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">next_batch_beam</span><span class="p">])</span>
        <span class="n">beam_tokens</span> <span class="o">=</span> <span class="n">hypo_text</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">next_batch_beam</span><span class="p">])</span>
        <span class="n">beam_idx</span> <span class="o">=</span> <span class="n">hypo_text</span><span class="o">.</span><span class="n">new</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">next_batch_beam</span><span class="p">])</span>

        <span class="c1"># Update the length of generated sentences</span>
        <span class="n">hypo_text</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">hypo_text</span><span class="p">[</span><span class="n">beam_idx</span><span class="p">],</span> <span class="n">beam_tokens</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">hypo_text_len</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">hypo_text</span> <span class="o">!=</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># align encoder_out with input_tokens</span>
        <span class="n">enc_feat</span><span class="p">,</span> <span class="n">enc_feat_mask</span> <span class="o">=</span> <span class="n">enc_feat</span><span class="p">[</span><span class="n">beam_idx</span><span class="p">],</span> <span class="n">enc_feat_mask</span><span class="p">[</span><span class="n">beam_idx</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">ctc_memory</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">token_idx</span> <span class="o">=</span> <span class="n">beam_tokens</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">beam_size</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">beam_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cuda_device</span><span class="p">)</span> <span class="o">*</span> <span class="n">vocab_size</span>
            <span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">ctc_memory</span> <span class="o">=</span> <span class="n">ctc_scorer</span><span class="o">.</span><span class="n">permute_mem</span><span class="p">(</span><span class="n">ctc_memory</span><span class="p">,</span> <span class="n">beam_idx</span><span class="p">,</span> <span class="n">token_idx</span><span class="p">)</span>

    <span class="c1"># --- 6. Post-processing --- #</span>
    <span class="c1"># for the predictions that end without an eos token at the end because of the max length</span>
    <span class="k">for</span> <span class="n">batch_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="c1"># skip the sentences that get enough hypotheses ending with eos</span>
        <span class="k">if</span> <span class="n">done</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]:</span>
            <span class="k">continue</span>
        <span class="c1"># check whether they can be added into final beam searching results</span>
        <span class="k">for</span> <span class="n">beam_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">beam_size</span><span class="p">):</span>
            <span class="n">effective_beam_id</span> <span class="o">=</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="n">beam_size</span> <span class="o">+</span> <span class="n">beam_id</span>
            <span class="n">final_score</span> <span class="o">=</span> <span class="n">beam_scores</span><span class="p">[</span><span class="n">effective_beam_id</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">final_tokens</span> <span class="o">=</span> <span class="n">hypo_text</span><span class="p">[</span><span class="n">effective_beam_id</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="n">generated_hyps</span><span class="p">[</span><span class="n">batch_idx</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">final_tokens</span><span class="p">,</span> <span class="n">final_score</span><span class="p">)</span>

    <span class="c1"># --- 7. Length Calculation --- #</span>
    <span class="n">hypo_text_len</span> <span class="o">=</span> <span class="n">hypo_text_len</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">sent_per_beam</span><span class="p">)</span>
    <span class="n">hypo_text_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">hypo_text_confid</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># looping each sentence in the current batch</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">hypotheses</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">generated_hyps</span><span class="p">):</span>
        <span class="n">sorted_hyps</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">hypotheses</span><span class="o">.</span><span class="n">beams</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1"># looping each beam for the given sentence</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sent_per_beam</span><span class="p">):</span>
            <span class="n">effective_batch_idx</span> <span class="o">=</span> <span class="n">sent_per_beam</span> <span class="o">*</span> <span class="n">i</span> <span class="o">+</span> <span class="n">j</span>
            <span class="n">_hypo</span> <span class="o">=</span> <span class="n">sorted_hyps</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>

            <span class="c1"># remove the sos tokens at the beginning of hyp</span>
            <span class="n">best_hyp</span> <span class="o">=</span> <span class="n">_hypo</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">hypo_text_len</span><span class="p">[</span><span class="n">effective_batch_idx</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">best_hyp</span><span class="p">)</span>
            <span class="n">hypo_text_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_hyp</span><span class="p">)</span>
            <span class="n">hypo_text_confid</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_hypo</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># --- 8. Padding --- #</span>
    <span class="c1"># some sentences are shorter than the maximal length</span>
    <span class="k">if</span> <span class="n">hypo_text_len</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">!=</span> <span class="n">hypo_text_len</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">():</span>
        <span class="n">sent_max_len</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">hypo_text_len</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">hypo_maxlen</span><span class="p">)</span>
        <span class="n">hypo_text</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
            <span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">sent_per_beam</span><span class="p">,</span> <span class="n">sent_max_len</span><span class="p">),</span>
            <span class="n">padding_idx</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">cuda_device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hypo_text_list</span><span class="p">)):</span>
            <span class="c1"># padding pseudo transcripts</span>
            <span class="n">hypo_text</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span> <span class="n">hypo_text_len</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">hypo_text_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="c1"># all the sentences are equally long</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">hypo_text</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">hypo_text_list</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cuda_device</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">hypo_text</span><span class="o">=</span><span class="n">hypo_text</span><span class="p">,</span>
        <span class="n">hypo_text_len</span><span class="o">=</span><span class="n">hypo_text_len</span><span class="p">,</span>
        <span class="n">feat_token_len_ratio</span><span class="o">=</span><span class="n">enc_feat_len</span> <span class="o">/</span> <span class="p">(</span><span class="n">hypo_text_len</span> <span class="o">+</span> <span class="mf">1e-10</span><span class="p">),</span>
        <span class="n">hypo_text_confid</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">hypo_text_confid</span><span class="p">),</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": [], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.88dd0f4e.min.js"></script>
      
    
  </body>
</html>