
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Documentation for Speechain Toolkit">
      
      
      
      
        <link rel="prev" href="../../postnet/token/">
      
      
        <link rel="next" href="../conv2d/">
      
      
      <link rel="icon" href="../../../../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>conv1d - Speechain</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../../css/code_select.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#module.prenet.conv1d" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Speechain" class="md-header__button md-logo" aria-label="Speechain" data-md-component="logo">
      
  <img src="../../../../img/speechain.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Speechain
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              conv1d
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/bagustris/speechain" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Speechain" class="md-nav__button md-logo" aria-label="Speechain" data-md-component="logo">
      
  <img src="../../../../img/speechain.png" alt="logo">

    </a>
    Speechain
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/bagustris/speechain" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ASR
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TTS
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    criterion
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1">
            <span class="md-nav__icon md-icon"></span>
            criterion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/accuracy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    accuracy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/att_guid/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    att_guid
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/bce_logits/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bce_logits
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/cross_entropy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cross_entropy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/ctc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctc
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/error_rate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    error_rate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/fbeta_score/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    fbeta_score
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/least_error/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    least_error
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/perplexity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    perplexity
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../dataset/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    dataset
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            dataset
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/speech_text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_text
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    infer_func
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            infer_func
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../infer_func/beam_search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam_search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../infer_func/ctc_decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctc_decoding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../infer_func/tts_decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tts_decoding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    iterator
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            iterator
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../iterator/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../iterator/block/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    block
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_5" >
        
          
          <label class="md-nav__link" for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    model
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            model
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../model/ar_asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../model/ar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_tts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../model/lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    lm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../model/nar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nar_tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6" checked>
        
          
          <label class="md-nav__link" for="__nav_5_6" id="__nav_5_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    module
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_6">
            <span class="md-nav__icon md-icon"></span>
            module
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_2" >
        
          
          <label class="md-nav__link" for="__nav_5_6_2" id="__nav_5_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    augment
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_2">
            <span class="md-nav__icon md-icon"></span>
            augment
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../augment/specaug/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    specaug
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_3" >
        
          
          <label class="md-nav__link" for="__nav_5_6_3" id="__nav_5_6_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    conformer
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_3">
            <span class="md-nav__icon md-icon"></span>
            conformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../conformer/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../conformer/encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../conformer/pos_enc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pos_enc
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_4" >
        
          
          <label class="md-nav__link" for="__nav_5_6_4" id="__nav_5_6_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    decoder
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_4">
            <span class="md-nav__icon md-icon"></span>
            decoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../decoder/ar_asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../decoder/ar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_tts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../decoder/nar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nar_tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_5" >
        
          
          <label class="md-nav__link" for="__nav_5_6_5" id="__nav_5_6_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    encoder
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_5">
            <span class="md-nav__icon md-icon"></span>
            encoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../encoder/asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../encoder/tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_6" >
        
          
          <label class="md-nav__link" for="__nav_5_6_6" id="__nav_5_6_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    frontend
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_6">
            <span class="md-nav__icon md-icon"></span>
            frontend
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../frontend/delta_feat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    delta_feat
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../frontend/linear2mel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear2mel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../frontend/speech2linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech2linear
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../frontend/speech2mel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech2mel
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_7" >
        
          
          <label class="md-nav__link" for="__nav_5_6_7" id="__nav_5_6_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    norm
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_7">
            <span class="md-nav__icon md-icon"></span>
            norm
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../norm/feat_norm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feat_norm
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_8" >
        
          
          <label class="md-nav__link" for="__nav_5_6_8" id="__nav_5_6_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    postnet
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_8">
            <span class="md-nav__icon md-icon"></span>
            postnet
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../postnet/conv1d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv1d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../postnet/token/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    token
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_9" checked>
        
          
          <label class="md-nav__link" for="__nav_5_6_9" id="__nav_5_6_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    prenet
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_9_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_6_9">
            <span class="md-nav__icon md-icon"></span>
            prenet
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    conv1d
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    conv1d
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#module.prenet.conv1d" class="md-nav__link">
    <span class="md-ellipsis">
      conv1d
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module.prenet.conv1d.Conv1dEv" class="md-nav__link">
    <span class="md-ellipsis">
      Conv1dEv
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Conv1dEv">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#module.prenet.conv1d.Conv1dEv.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.prenet.conv1d.Conv1dEv.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module.prenet.conv1d.Conv1dPrenet" class="md-nav__link">
    <span class="md-ellipsis">
      Conv1dPrenet
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Conv1dPrenet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#module.prenet.conv1d.Conv1dPrenet.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.prenet.conv1d.Conv1dPrenet.module_init" class="md-nav__link">
    <span class="md-ellipsis">
      module_init
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../conv2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv2d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../embed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    embed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../spk_embed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    spk_embed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../var_pred/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    var_pred
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_10" >
        
          
          <label class="md-nav__link" for="__nav_5_6_10" id="__nav_5_6_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    standalone
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_10">
            <span class="md-nav__icon md-icon"></span>
            standalone
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../standalone/lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    lm
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_11" >
        
          
          <label class="md-nav__link" for="__nav_5_6_11" id="__nav_5_6_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    transformer
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_11">
            <span class="md-nav__icon md-icon"></span>
            transformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    decoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/feed_forward/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feed_forward
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/pos_enc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pos_enc
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../monitor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    monitor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_8" >
        
          
          <label class="md-nav__link" for="__nav_5_8" id="__nav_5_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    optim_sche
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_8">
            <span class="md-nav__icon md-icon"></span>
            optim_sche
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../optim_sche/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../optim_sche/exp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    exp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../optim_sche/noam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    noam
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9" >
        
          
          <label class="md-nav__link" for="__nav_5_9" id="__nav_5_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    pyscripts
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9">
            <span class="md-nav__icon md-icon"></span>
            pyscripts
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pyscripts/empty_file_checker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    empty_file_checker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pyscripts/folder_summarizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    folder_summarizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pyscripts/model_para_renamer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    model_para_renamer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pyscripts/phn_duaration_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phn_duaration_visualizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pyscripts/text_dist_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_dist_visualizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pyscripts/wavlen_dist_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wavlen_dist_visualizer
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../runner/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    runner
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../snapshooter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    snapshooter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_12" >
        
          
          <label class="md-nav__link" for="__nav_5_12" id="__nav_5_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    tokenizer
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_12">
            <span class="md-nav__icon md-icon"></span>
            tokenizer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tokenizer/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tokenizer/char/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    char
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tokenizer/g2p/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    g2p
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tokenizer/sp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sp
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_13" >
        
          
          <label class="md-nav__link" for="__nav_5_13" id="__nav_5_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    utilbox
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_13">
            <span class="md-nav__icon md-icon"></span>
            utilbox
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/data_loading_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_loading_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/data_saving_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_saving_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/dump_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    dump_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/eval_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    eval_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/feat_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feat_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/import_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    import_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/log_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    log_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/md_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    md_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/regex_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    regex_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/sb_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sb_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/spk_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    spk_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/tensor_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tensor_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/text_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/train_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    train_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/type_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    type_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/yaml_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    yaml_util
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#module.prenet.conv1d" class="md-nav__link">
    <span class="md-ellipsis">
      conv1d
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module.prenet.conv1d.Conv1dEv" class="md-nav__link">
    <span class="md-ellipsis">
      Conv1dEv
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Conv1dEv">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#module.prenet.conv1d.Conv1dEv.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.prenet.conv1d.Conv1dEv.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module.prenet.conv1d.Conv1dPrenet" class="md-nav__link">
    <span class="md-ellipsis">
      Conv1dPrenet
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Conv1dPrenet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#module.prenet.conv1d.Conv1dPrenet.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.prenet.conv1d.Conv1dPrenet.module_init" class="md-nav__link">
    <span class="md-ellipsis">
      module_init
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>conv1d</h1>

<div class="doc doc-object doc-module">



<a id="module.prenet.conv1d"></a>
    <div class="doc doc-contents first">

        <p>Author: Sashi Novitasari
Affiliation: NAIST (-2022)
Date: 2022.08</p>
<p>Author: Heli Qi
Affiliation: NAIST
Date: 2022.09</p>








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="module.prenet.conv1d.Conv1dEv" class="doc doc-heading">
            <code>Conv1dEv</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


        <p>A 1D convolutional layer with support for different padding modes.</p>


<p><span class="doc-section-title">Attributes:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code><span title="module.prenet.conv1d.Conv1dEv.cutoff">cutoff</span></code></td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Indicates whether the output should be cut off for the 'same' padding mode.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="module.prenet.conv1d.Conv1dEv.causal_padding">causal_padding</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Additional padding required for the 'causal' padding mode.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="module.prenet.conv1d.Conv1dEv.dilation">dilation</span></code></td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The dilation rate of the convolutional layer.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code><span title="module.prenet.conv1d.Conv1dEv.conv_lyr">conv_lyr</span></code></td>
            <td>
                  <code><span title="torch.nn.Conv1d">Conv1d</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The 1D convolutional layer.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>






              <details class="quote">
                <summary>Source code in <code>speechain/module/prenet/conv1d.py</code></summary>
                <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Conv1dEv</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A 1D convolutional layer with support for different padding modes.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        cutoff (bool):</span>
<span class="sd">            Indicates whether the output should be cut off for the &#39;same&#39; padding mode.</span>
<span class="sd">        causal_padding (int):</span>
<span class="sd">            Additional padding required for the &#39;causal&#39; padding mode.</span>
<span class="sd">        dilation (int):</span>
<span class="sd">            The dilation rate of the convolutional layer.</span>
<span class="sd">        conv_lyr (torch.nn.Conv1d):</span>
<span class="sd">            The 1D convolutional layer.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">dilation</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">padding_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;same&quot;</span><span class="p">,</span>
        <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">use_weight_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the Conv1dEv module with the specified parameters.</span>

<span class="sd">        Args:</span>
<span class="sd">            in_channels (int):</span>
<span class="sd">                Number of channels in the input feature.</span>
<span class="sd">            out_channels (int):</span>
<span class="sd">                Number of channels produced by the convolution.</span>
<span class="sd">            kernel_size (int):</span>
<span class="sd">                Size of the convolutional kernel.</span>
<span class="sd">            stride (int, optional):</span>
<span class="sd">                Stride of the convolution. Defaults to 1.</span>
<span class="sd">            dilation (int, optional):</span>
<span class="sd">                The dilation rate of the kernel. Defaults to 1.</span>
<span class="sd">            padding_mode (str, optional):</span>
<span class="sd">                Padding mode. Supported values are &#39;valid&#39;, &#39;full&#39;, &#39;same&#39; and &#39;causal&#39;. Defaults to &#39;same&#39;.</span>
<span class="sd">            bias (bool, optional):</span>
<span class="sd">                If True, adds a learnable bias to the output. Defaults to True.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If an unsupported padding mode is specified.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">causal_padding</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="n">dilation</span>

        <span class="c1"># no padding is used</span>
        <span class="k">if</span> <span class="n">padding_mode</span> <span class="o">==</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># full padding</span>
        <span class="k">elif</span> <span class="n">padding_mode</span> <span class="o">==</span> <span class="s2">&quot;full&quot;</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="n">dilation</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># same padding, the output is the same in dimension with input</span>
        <span class="k">elif</span> <span class="n">padding_mode</span> <span class="o">==</span> <span class="s2">&quot;same&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">stride</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Stride should be 1 for &#39;same&#39; padding mode&quot;</span>
            <span class="k">if</span> <span class="n">kernel_size</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">padding</span> <span class="o">=</span> <span class="n">dilation</span> <span class="o">*</span> <span class="n">kernel_size</span> <span class="o">//</span> <span class="mi">2</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">padding</span> <span class="o">=</span> <span class="n">dilation</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="c1"># causal padding</span>
        <span class="k">elif</span> <span class="n">padding_mode</span> <span class="o">==</span> <span class="s2">&quot;causal&quot;</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">causal_padding</span> <span class="o">=</span> <span class="n">dilation</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Unsupported padding mode. Supported modes are &#39;valid&#39;, &#39;full&#39;, &#39;same&#39; and &#39;causal&#39;.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">conv_lyr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
            <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
            <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
            <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">use_weight_norm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">conv_lyr</span> <span class="o">=</span> <span class="n">weight_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_lyr</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Performs a forward pass through the convolutional layer.</span>

<span class="sd">        Args:</span>
<span class="sd">            feat (torch.Tensor):</span>
<span class="sd">                The input feature tensor. Shape: (batch, feat_dim, feat_maxlen).</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor:</span>
<span class="sd">                The output tensor. Shape: (batch, out_channels, output_len).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># attach additional paddings at the end for the &#39;causal&#39; padding mode</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">causal_padding</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">causal_padding</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_lyr</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
        <span class="c1"># cut off the redundant tails for the &#39;same&#39; padding mode</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">output</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="module.prenet.conv1d.Conv1dEv.__init__" class="doc doc-heading">
            <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_weight_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Initializes the Conv1dEv module with the specified parameters.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>in_channels</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of channels in the input feature.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>out_channels</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of channels produced by the convolution.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>kernel_size</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Size of the convolutional kernel.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stride</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Stride of the convolution. Defaults to 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dilation</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The dilation rate of the kernel. Defaults to 1.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>padding_mode</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Padding mode. Supported values are 'valid', 'full', 'same' and 'causal'. Defaults to 'same'.</p>
              </div>
            </td>
            <td>
                  <code>&#39;same&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>bias</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, adds a learnable bias to the output. Defaults to True.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>ValueError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If an unsupported padding mode is specified.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/module/prenet/conv1d.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">padding_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;same&quot;</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">use_weight_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initializes the Conv1dEv module with the specified parameters.</span>

<span class="sd">    Args:</span>
<span class="sd">        in_channels (int):</span>
<span class="sd">            Number of channels in the input feature.</span>
<span class="sd">        out_channels (int):</span>
<span class="sd">            Number of channels produced by the convolution.</span>
<span class="sd">        kernel_size (int):</span>
<span class="sd">            Size of the convolutional kernel.</span>
<span class="sd">        stride (int, optional):</span>
<span class="sd">            Stride of the convolution. Defaults to 1.</span>
<span class="sd">        dilation (int, optional):</span>
<span class="sd">            The dilation rate of the kernel. Defaults to 1.</span>
<span class="sd">        padding_mode (str, optional):</span>
<span class="sd">            Padding mode. Supported values are &#39;valid&#39;, &#39;full&#39;, &#39;same&#39; and &#39;causal&#39;. Defaults to &#39;same&#39;.</span>
<span class="sd">        bias (bool, optional):</span>
<span class="sd">            If True, adds a learnable bias to the output. Defaults to True.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If an unsupported padding mode is specified.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">causal_padding</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dilation</span> <span class="o">=</span> <span class="n">dilation</span>

    <span class="c1"># no padding is used</span>
    <span class="k">if</span> <span class="n">padding_mode</span> <span class="o">==</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># full padding</span>
    <span class="k">elif</span> <span class="n">padding_mode</span> <span class="o">==</span> <span class="s2">&quot;full&quot;</span><span class="p">:</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="n">dilation</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># same padding, the output is the same in dimension with input</span>
    <span class="k">elif</span> <span class="n">padding_mode</span> <span class="o">==</span> <span class="s2">&quot;same&quot;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">stride</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Stride should be 1 for &#39;same&#39; padding mode&quot;</span>
        <span class="k">if</span> <span class="n">kernel_size</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="n">dilation</span> <span class="o">*</span> <span class="n">kernel_size</span> <span class="o">//</span> <span class="mi">2</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="n">dilation</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="c1"># causal padding</span>
    <span class="k">elif</span> <span class="n">padding_mode</span> <span class="o">==</span> <span class="s2">&quot;causal&quot;</span><span class="p">:</span>
        <span class="n">padding</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">causal_padding</span> <span class="o">=</span> <span class="n">dilation</span> <span class="o">*</span> <span class="p">(</span><span class="n">kernel_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Unsupported padding mode. Supported modes are &#39;valid&#39;, &#39;full&#39;, &#39;same&#39; and &#39;causal&#39;.&quot;</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">conv_lyr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">dilation</span><span class="o">=</span><span class="n">dilation</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">use_weight_norm</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_lyr</span> <span class="o">=</span> <span class="n">weight_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_lyr</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="module.prenet.conv1d.Conv1dEv.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">

        <p>Performs a forward pass through the convolutional layer.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>feat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input feature tensor. Shape: (batch, feat_dim, feat_maxlen).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>torch.Tensor:
The output tensor. Shape: (batch, out_channels, output_len).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/module/prenet/conv1d.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs a forward pass through the convolutional layer.</span>

<span class="sd">    Args:</span>
<span class="sd">        feat (torch.Tensor):</span>
<span class="sd">            The input feature tensor. Shape: (batch, feat_dim, feat_maxlen).</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor:</span>
<span class="sd">            The output tensor. Shape: (batch, out_channels, output_len).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># attach additional paddings at the end for the &#39;causal&#39; padding mode</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">causal_padding</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">causal_padding</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_lyr</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
    <span class="c1"># cut off the redundant tails for the &#39;same&#39; padding mode</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cutoff</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">dilation</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">output</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="module.prenet.conv1d.Conv1dPrenet" class="doc doc-heading">
            <code>Conv1dPrenet</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="speechain.module.abs.Module">Module</span></code></p>


        <p>The Conv1d prenet. Usually used before the TTS encoder.
This prenet is made up of two parts:
    1. (mandatory) The Conv1d part contains one or more Conv1d blocks which are composed of the components below
        1. (mandatory) a Conv1d layer
        2. (optional) a BatchNorm1d layer
        3. (optional) an activation function
        4. (optional) a Dropout layer.
    2. (optional) The Linear part contains one or more Linear blocks which are composed of the components below
        1. (mandatory) a Linear layer
        2. (optional) an activation function
        3. (optional) a Dropout layer.</p>


<details class="reference" open>
  <summary>Reference</summary>
  <p>Neural Speech Synthesis with Transformer Network
https://ojs.aaai.org/index.php/AAAI/article/view/4642/4520</p>
</details>





              <details class="quote">
                <summary>Source code in <code>speechain/module/prenet/conv1d.py</code></summary>
                <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">Conv1dPrenet</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The Conv1d prenet. Usually used before the TTS encoder.</span>
<span class="sd">    This prenet is made up of two parts:</span>
<span class="sd">        1. (mandatory) The Conv1d part contains one or more Conv1d blocks which are composed of the components below</span>
<span class="sd">            1. (mandatory) a Conv1d layer</span>
<span class="sd">            2. (optional) a BatchNorm1d layer</span>
<span class="sd">            3. (optional) an activation function</span>
<span class="sd">            4. (optional) a Dropout layer.</span>
<span class="sd">        2. (optional) The Linear part contains one or more Linear blocks which are composed of the components below</span>
<span class="sd">            1. (mandatory) a Linear layer</span>
<span class="sd">            2. (optional) an activation function</span>
<span class="sd">            3. (optional) a Dropout layer.</span>

<span class="sd">    Reference:</span>
<span class="sd">        Neural Speech Synthesis with Transformer Network</span>
<span class="sd">        https://ojs.aaai.org/index.php/AAAI/article/view/4642/4520</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">module_init</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">feat_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">conv_dims</span><span class="p">:</span> <span class="nb">int</span> <span class="ow">or</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">],</span>
        <span class="n">conv_kernel</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">conv_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">conv_batchnorm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">conv_activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ReLU&quot;</span><span class="p">,</span>
        <span class="n">conv_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="ow">or</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lnr_dims</span><span class="p">:</span> <span class="nb">int</span> <span class="ow">or</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">lnr_activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lnr_dropout</span><span class="p">:</span> <span class="nb">int</span> <span class="ow">or</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">zero_centered</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            feat_dim: int</span>
<span class="sd">                The dimension of input acoustic feature tensors.</span>
<span class="sd">                Used for calculating the in_features of the first Linear layer.</span>
<span class="sd">            conv_dims: List[int] or int</span>
<span class="sd">                The values of out_channels of each Conv1d layer.</span>
<span class="sd">                If a list of integers is given, multiple Conv1d layers will be initialized.</span>
<span class="sd">                If an integer is given, there will be only one Conv1d layer</span>
<span class="sd">            conv_kernel: int</span>
<span class="sd">                The value of kernel_size of all Conv1d layers.</span>
<span class="sd">            conv_stride: int</span>
<span class="sd">                The value of stride of all Conv1d layers.</span>
<span class="sd">            conv_batchnorm: bool</span>
<span class="sd">                Whether a BatchNorm1d layer is added right after a Conv1d layer</span>
<span class="sd">            conv_activation: str</span>
<span class="sd">                The type of the activation function after all Conv1d layers.</span>
<span class="sd">                None means no activation function is needed.</span>
<span class="sd">            conv_dropout: float or List[float]</span>
<span class="sd">                The values of p rate of the Dropout layer after each Linear layer.</span>
<span class="sd">            lnr_dims: int or List[int]</span>
<span class="sd">                The values of out_features of each Linear layer.</span>
<span class="sd">                The first value in the List represents the out_features of the first Linear layer.</span>
<span class="sd">                -1: same size as the last convolutional layer&#39;s dim</span>
<span class="sd">            lnr_activation: str</span>
<span class="sd">                The type of the activation function after all Linear layers.</span>
<span class="sd">                None means no activation function is needed.</span>
<span class="sd">            lnr_dropout: float or List[float]</span>
<span class="sd">                The values of p rate of the Dropout layer after each Linear layer.</span>
<span class="sd">            zero_centered: bool</span>
<span class="sd">                Whether the output of this module is centered at 0.</span>
<span class="sd">                If the specified activation function changes the centroid of the output distribution, e.g. ReLU and</span>
<span class="sd">                LeakyReLU, the activation function won&#39;t be attached to the final Linear layer if zer_centered is set</span>
<span class="sd">                to True.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># --- 0. Argument Checking --- #</span>
        <span class="c1"># Convolution arguments checking</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">conv_dims</span><span class="p">,</span> <span class="p">(</span><span class="n">List</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="p">),</span> <span class="s2">&quot;The dimensions of convolutional layers must be given as a list of integers or an integer!&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">conv_kernel</span><span class="p">,</span> <span class="nb">int</span>
        <span class="p">),</span> <span class="s2">&quot;The sizes of convolutional kernels must be given as an integer!&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">conv_stride</span><span class="p">,</span> <span class="nb">int</span>
        <span class="p">),</span> <span class="s2">&quot;The lengths of convolutional strides must be given as an integer!&quot;</span>
        <span class="k">if</span> <span class="n">conv_dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">conv_dropout</span><span class="p">,</span> <span class="p">(</span><span class="n">List</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
            <span class="p">),</span> <span class="s2">&quot;The dropout rates of convolutional layers must be given as a list of integers or an integer!&quot;</span>

        <span class="c1"># Linear arguments checking</span>
        <span class="k">if</span> <span class="n">lnr_dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">lnr_dropout</span><span class="p">,</span> <span class="p">(</span><span class="n">List</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
            <span class="p">),</span> <span class="s2">&quot;The dropout rates of linear layers must be given as a list of integers or an integer!&quot;</span>
        <span class="k">if</span> <span class="n">lnr_dims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                <span class="n">lnr_dims</span><span class="p">,</span> <span class="p">(</span><span class="n">List</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
            <span class="p">),</span> <span class="s2">&quot;The dimensions of linear layers must be given as a list of integers or an integer!&quot;</span>

        <span class="c1"># input_size initialization</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">feat_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">feat_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

        <span class="c1"># --- 1. Convolutional Part Initialization --- #</span>
        <span class="c1"># register convolution arguments</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_dims</span> <span class="o">=</span> <span class="n">conv_dims</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">conv_dims</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">conv_dims</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_kernel</span> <span class="o">=</span> <span class="n">conv_kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_stride</span> <span class="o">=</span> <span class="n">conv_stride</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_dropout</span> <span class="o">=</span> <span class="n">conv_dropout</span>

        <span class="c1"># Conv1d blocks construction</span>
        <span class="n">_prev_dim</span> <span class="o">=</span> <span class="n">feat_dim</span>
        <span class="n">_tmp_conv</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_dims</span><span class="p">)):</span>
            <span class="n">_tmp_conv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="c1"># don&#39;t include bias in the convolutional layer if it is followed by a batchnorm layer</span>
                <span class="c1"># reference: https://stackoverflow.com/questions/46256747/can-not-use-both-bias-and-batch-normalization-in-convolution-layers</span>
                <span class="n">Conv1dEv</span><span class="p">(</span>
                    <span class="n">in_channels</span><span class="o">=</span><span class="n">_prev_dim</span><span class="p">,</span>
                    <span class="n">out_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_dims</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_kernel</span><span class="p">,</span>
                    <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_stride</span><span class="p">,</span>
                    <span class="n">padding_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span>
                    <span class="n">bias</span><span class="o">=</span><span class="ow">not</span> <span class="n">conv_batchnorm</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="c1"># BatchNorm is better to be placed before activation</span>
            <span class="c1"># reference: https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout</span>
            <span class="k">if</span> <span class="n">conv_batchnorm</span><span class="p">:</span>
                <span class="n">_tmp_conv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
            <span class="k">if</span> <span class="n">conv_activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># no &#39;ReLU&#39;-series activation is added for the last layer if zero_centered is specified</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_dims</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">lnr_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="p">(</span>
                    <span class="n">zero_centered</span> <span class="ow">and</span> <span class="s2">&quot;ReLU&quot;</span> <span class="ow">in</span> <span class="n">conv_activation</span>
                <span class="p">):</span>
                    <span class="n">_tmp_conv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="p">,</span> <span class="n">conv_activation</span><span class="p">)())</span>
            <span class="k">if</span> <span class="n">conv_dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_tmp_conv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span>
                        <span class="n">p</span><span class="o">=</span><span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">conv_dropout</span>
                            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_dropout</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span>
                            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_dropout</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="n">_prev_dim</span> <span class="o">=</span> <span class="n">conv_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">_tmp_conv</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">_prev_dim</span>

        <span class="c1"># --- 2. Linear Part Initialization --- #</span>
        <span class="k">if</span> <span class="n">lnr_dims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lnr_dims</span> <span class="o">=</span> <span class="n">lnr_dims</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lnr_dims</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">lnr_dims</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lnr_dims</span><span class="p">)):</span>
                <span class="n">_prev_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">lnr_dims</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">lnr_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                    <span class="n">lnr_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">_prev_dim</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">LinearPrenet</span><span class="p">(</span>
                <span class="n">feat_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span>
                <span class="n">lnr_dims</span><span class="o">=</span><span class="n">lnr_dims</span><span class="p">,</span>
                <span class="n">lnr_activation</span><span class="o">=</span><span class="n">lnr_activation</span><span class="p">,</span>
                <span class="n">lnr_dropout</span><span class="o">=</span><span class="n">lnr_dropout</span><span class="p">,</span>
                <span class="n">zero_centered</span><span class="o">=</span><span class="n">zero_centered</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">output_size</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            feat: (batch, feat_maxlen, feat_dim)</span>
<span class="sd">                The input feature tensors.</span>
<span class="sd">            feat_len: (batch,)</span>
<span class="sd">                The length of each feature tensor.</span>

<span class="sd">        Returns: feat, feat_len</span>
<span class="sd">            The embedded feature vectors with their lengths.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># forward the convolutional layers</span>
        <span class="c1"># (batch, feat_maxlen, feat_dim) -&gt; (batch, feat_dim, feat_maxlen)</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># (batch, feat_dim, feat_maxlen) -&gt; (batch, conv_dim, feat_maxlen)</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
        <span class="c1"># (batch, conv_dim, feat_maxlen) -&gt; (batch, feat_maxlen, conv_dim)</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># forward the linear layers</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">):</span>
            <span class="c1"># (batch, feat_maxlen, conv_dim) -&gt; (batch, feat_maxlen, lnr_dim)</span>
            <span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span><span class="p">)</span>

        <span class="c1"># return both feat &amp; feat_len for the compatibility with other prenet</span>
        <span class="k">return</span> <span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="module.prenet.conv1d.Conv1dPrenet.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>feat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch, feat_maxlen, feat_dim)
The input feature tensors.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>feat_len</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch,)
The length of each feature tensor.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">feat, feat_len</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The embedded feature vectors with their lengths.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/module/prenet/conv1d.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        feat: (batch, feat_maxlen, feat_dim)</span>
<span class="sd">            The input feature tensors.</span>
<span class="sd">        feat_len: (batch,)</span>
<span class="sd">            The length of each feature tensor.</span>

<span class="sd">    Returns: feat, feat_len</span>
<span class="sd">        The embedded feature vectors with their lengths.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># forward the convolutional layers</span>
    <span class="c1"># (batch, feat_maxlen, feat_dim) -&gt; (batch, feat_dim, feat_maxlen)</span>
    <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c1"># (batch, feat_dim, feat_maxlen) -&gt; (batch, conv_dim, feat_maxlen)</span>
    <span class="n">feat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
    <span class="c1"># (batch, conv_dim, feat_maxlen) -&gt; (batch, feat_maxlen, conv_dim)</span>
    <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># forward the linear layers</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">):</span>
        <span class="c1"># (batch, feat_maxlen, conv_dim) -&gt; (batch, feat_maxlen, lnr_dim)</span>
        <span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span><span class="p">)</span>

    <span class="c1"># return both feat &amp; feat_len for the compatibility with other prenet</span>
    <span class="k">return</span> <span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="module.prenet.conv1d.Conv1dPrenet.module_init" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">module_init</span><span class="p">(</span><span class="n">feat_dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">conv_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">],</span> <span class="n">conv_kernel</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">conv_stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">conv_batchnorm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">conv_activation</span><span class="o">=</span><span class="s1">&#39;ReLU&#39;</span><span class="p">,</span> <span class="n">conv_dropout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lnr_dims</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">lnr_activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lnr_dropout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">zero_centered</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>feat_dim</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The dimension of input acoustic feature tensors.
Used for calculating the in_features of the first Linear layer.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>conv_dims</code>
            </td>
            <td>
                  <code>int or <span title="typing.List">List</span>[int]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>List[int] or int
The values of out_channels of each Conv1d layer.
If a list of integers is given, multiple Conv1d layers will be initialized.
If an integer is given, there will be only one Conv1d layer</p>
              </div>
            </td>
            <td>
                  <code>[512, 512, 512]</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>conv_kernel</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The value of kernel_size of all Conv1d layers.</p>
              </div>
            </td>
            <td>
                  <code>5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>conv_stride</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The value of stride of all Conv1d layers.</p>
              </div>
            </td>
            <td>
                  <code>1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>conv_batchnorm</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool
Whether a BatchNorm1d layer is added right after a Conv1d layer</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>conv_activation</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>str
The type of the activation function after all Conv1d layers.
None means no activation function is needed.</p>
              </div>
            </td>
            <td>
                  <code>&#39;ReLU&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>conv_dropout</code>
            </td>
            <td>
                  <code>float or <span title="typing.List">List</span>[float]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float or List[float]
The values of p rate of the Dropout layer after each Linear layer.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lnr_dims</code>
            </td>
            <td>
                  <code>int or <span title="typing.List">List</span>[int]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int or List[int]
The values of out_features of each Linear layer.
The first value in the List represents the out_features of the first Linear layer.
-1: same size as the last convolutional layer's dim</p>
              </div>
            </td>
            <td>
                  <code>-1</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lnr_activation</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>str
The type of the activation function after all Linear layers.
None means no activation function is needed.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lnr_dropout</code>
            </td>
            <td>
                  <code>int or <span title="typing.List">List</span>[int]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float or List[float]
The values of p rate of the Dropout layer after each Linear layer.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>zero_centered</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool
Whether the output of this module is centered at 0.
If the specified activation function changes the centroid of the output distribution, e.g. ReLU and
LeakyReLU, the activation function won't be attached to the final Linear layer if zer_centered is set
to True.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/module/prenet/conv1d.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">module_init</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">feat_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">conv_dims</span><span class="p">:</span> <span class="nb">int</span> <span class="ow">or</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">],</span>
    <span class="n">conv_kernel</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
    <span class="n">conv_stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">conv_batchnorm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">conv_activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ReLU&quot;</span><span class="p">,</span>
    <span class="n">conv_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="ow">or</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">lnr_dims</span><span class="p">:</span> <span class="nb">int</span> <span class="ow">or</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">lnr_activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">lnr_dropout</span><span class="p">:</span> <span class="nb">int</span> <span class="ow">or</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_centered</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        feat_dim: int</span>
<span class="sd">            The dimension of input acoustic feature tensors.</span>
<span class="sd">            Used for calculating the in_features of the first Linear layer.</span>
<span class="sd">        conv_dims: List[int] or int</span>
<span class="sd">            The values of out_channels of each Conv1d layer.</span>
<span class="sd">            If a list of integers is given, multiple Conv1d layers will be initialized.</span>
<span class="sd">            If an integer is given, there will be only one Conv1d layer</span>
<span class="sd">        conv_kernel: int</span>
<span class="sd">            The value of kernel_size of all Conv1d layers.</span>
<span class="sd">        conv_stride: int</span>
<span class="sd">            The value of stride of all Conv1d layers.</span>
<span class="sd">        conv_batchnorm: bool</span>
<span class="sd">            Whether a BatchNorm1d layer is added right after a Conv1d layer</span>
<span class="sd">        conv_activation: str</span>
<span class="sd">            The type of the activation function after all Conv1d layers.</span>
<span class="sd">            None means no activation function is needed.</span>
<span class="sd">        conv_dropout: float or List[float]</span>
<span class="sd">            The values of p rate of the Dropout layer after each Linear layer.</span>
<span class="sd">        lnr_dims: int or List[int]</span>
<span class="sd">            The values of out_features of each Linear layer.</span>
<span class="sd">            The first value in the List represents the out_features of the first Linear layer.</span>
<span class="sd">            -1: same size as the last convolutional layer&#39;s dim</span>
<span class="sd">        lnr_activation: str</span>
<span class="sd">            The type of the activation function after all Linear layers.</span>
<span class="sd">            None means no activation function is needed.</span>
<span class="sd">        lnr_dropout: float or List[float]</span>
<span class="sd">            The values of p rate of the Dropout layer after each Linear layer.</span>
<span class="sd">        zero_centered: bool</span>
<span class="sd">            Whether the output of this module is centered at 0.</span>
<span class="sd">            If the specified activation function changes the centroid of the output distribution, e.g. ReLU and</span>
<span class="sd">            LeakyReLU, the activation function won&#39;t be attached to the final Linear layer if zer_centered is set</span>
<span class="sd">            to True.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># --- 0. Argument Checking --- #</span>
    <span class="c1"># Convolution arguments checking</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">conv_dims</span><span class="p">,</span> <span class="p">(</span><span class="n">List</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
    <span class="p">),</span> <span class="s2">&quot;The dimensions of convolutional layers must be given as a list of integers or an integer!&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">conv_kernel</span><span class="p">,</span> <span class="nb">int</span>
    <span class="p">),</span> <span class="s2">&quot;The sizes of convolutional kernels must be given as an integer!&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="n">conv_stride</span><span class="p">,</span> <span class="nb">int</span>
    <span class="p">),</span> <span class="s2">&quot;The lengths of convolutional strides must be given as an integer!&quot;</span>
    <span class="k">if</span> <span class="n">conv_dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">conv_dropout</span><span class="p">,</span> <span class="p">(</span><span class="n">List</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="p">),</span> <span class="s2">&quot;The dropout rates of convolutional layers must be given as a list of integers or an integer!&quot;</span>

    <span class="c1"># Linear arguments checking</span>
    <span class="k">if</span> <span class="n">lnr_dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">lnr_dropout</span><span class="p">,</span> <span class="p">(</span><span class="n">List</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="p">),</span> <span class="s2">&quot;The dropout rates of linear layers must be given as a list of integers or an integer!&quot;</span>
    <span class="k">if</span> <span class="n">lnr_dims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">lnr_dims</span><span class="p">,</span> <span class="p">(</span><span class="n">List</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="p">),</span> <span class="s2">&quot;The dimensions of linear layers must be given as a list of integers or an integer!&quot;</span>

    <span class="c1"># input_size initialization</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">feat_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">feat_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="c1"># --- 1. Convolutional Part Initialization --- #</span>
    <span class="c1"># register convolution arguments</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv_dims</span> <span class="o">=</span> <span class="n">conv_dims</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">conv_dims</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">conv_dims</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv_kernel</span> <span class="o">=</span> <span class="n">conv_kernel</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv_stride</span> <span class="o">=</span> <span class="n">conv_stride</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv_dropout</span> <span class="o">=</span> <span class="n">conv_dropout</span>

    <span class="c1"># Conv1d blocks construction</span>
    <span class="n">_prev_dim</span> <span class="o">=</span> <span class="n">feat_dim</span>
    <span class="n">_tmp_conv</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_dims</span><span class="p">)):</span>
        <span class="n">_tmp_conv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="c1"># don&#39;t include bias in the convolutional layer if it is followed by a batchnorm layer</span>
            <span class="c1"># reference: https://stackoverflow.com/questions/46256747/can-not-use-both-bias-and-batch-normalization-in-convolution-layers</span>
            <span class="n">Conv1dEv</span><span class="p">(</span>
                <span class="n">in_channels</span><span class="o">=</span><span class="n">_prev_dim</span><span class="p">,</span>
                <span class="n">out_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_dims</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_kernel</span><span class="p">,</span>
                <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_stride</span><span class="p">,</span>
                <span class="n">padding_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="ow">not</span> <span class="n">conv_batchnorm</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># BatchNorm is better to be placed before activation</span>
        <span class="c1"># reference: https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout</span>
        <span class="k">if</span> <span class="n">conv_batchnorm</span><span class="p">:</span>
            <span class="n">_tmp_conv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
        <span class="k">if</span> <span class="n">conv_activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># no &#39;ReLU&#39;-series activation is added for the last layer if zero_centered is specified</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_dims</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">lnr_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="p">(</span>
                <span class="n">zero_centered</span> <span class="ow">and</span> <span class="s2">&quot;ReLU&quot;</span> <span class="ow">in</span> <span class="n">conv_activation</span>
            <span class="p">):</span>
                <span class="n">_tmp_conv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="p">,</span> <span class="n">conv_activation</span><span class="p">)())</span>
        <span class="k">if</span> <span class="n">conv_dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_tmp_conv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span>
                    <span class="n">p</span><span class="o">=</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">conv_dropout</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_dropout</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span>
                        <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_dropout</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="n">_prev_dim</span> <span class="o">=</span> <span class="n">conv_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">_tmp_conv</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">_prev_dim</span>

    <span class="c1"># --- 2. Linear Part Initialization --- #</span>
    <span class="k">if</span> <span class="n">lnr_dims</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lnr_dims</span> <span class="o">=</span> <span class="n">lnr_dims</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lnr_dims</span><span class="p">,</span> <span class="n">List</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">lnr_dims</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lnr_dims</span><span class="p">)):</span>
            <span class="n">_prev_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">lnr_dims</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">lnr_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">lnr_dims</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">_prev_dim</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">LinearPrenet</span><span class="p">(</span>
            <span class="n">feat_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span>
            <span class="n">lnr_dims</span><span class="o">=</span><span class="n">lnr_dims</span><span class="p">,</span>
            <span class="n">lnr_activation</span><span class="o">=</span><span class="n">lnr_activation</span><span class="p">,</span>
            <span class="n">lnr_dropout</span><span class="o">=</span><span class="n">lnr_dropout</span><span class="p">,</span>
            <span class="n">zero_centered</span><span class="o">=</span><span class="n">zero_centered</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">output_size</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": [], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>