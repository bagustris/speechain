
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Documentation for Speechain Toolkit">
      
      
      
      
        <link rel="prev" href="../../frontend/speech2mel/">
      
      
        <link rel="next" href="../../postnet/conv1d/">
      
      
      <link rel="icon" href="../../../../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>feat_norm - Speechain</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.6f8fc17f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../../css/code_select.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#module.norm.feat_norm" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Speechain" class="md-header__button md-logo" aria-label="Speechain" data-md-component="logo">
      
  <img src="../../../../img/speechain_inverted.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Speechain
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              feat_norm
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/bagustris/speechain" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Speechain" class="md-nav__button md-logo" aria-label="Speechain" data-md-component="logo">
      
  <img src="../../../../img/speechain_inverted.png" alt="logo">

    </a>
    Speechain
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/bagustris/speechain" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Datasets
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ASR
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TTS
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1" >
        
          
          <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    criterion
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_1">
            <span class="md-nav__icon md-icon"></span>
            criterion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/accuracy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    accuracy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/att_guid/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    att_guid
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/bce_logits/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    bce_logits
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/cross_entropy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    cross_entropy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/ctc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctc
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/error_rate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    error_rate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/fbeta_score/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    fbeta_score
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/least_error/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    least_error
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../criterion/perplexity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    perplexity
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../dataset/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    dataset
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            dataset
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../dataset/speech_text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech_text
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    infer_func
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            infer_func
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../infer_func/beam_search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    beam_search
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../infer_func/ctc_decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ctc_decoding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../infer_func/tts_decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tts_decoding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    iterator
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            iterator
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../iterator/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../iterator/block/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    block
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_5" >
        
          
          <label class="md-nav__link" for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    model
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            model
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../model/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../model/ar_asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../model/ar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_tts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../model/lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    lm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../model/nar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nar_tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6" checked>
        
          
          <label class="md-nav__link" for="__nav_5_6" id="__nav_5_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    module
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_6">
            <span class="md-nav__icon md-icon"></span>
            module
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_2" >
        
          
          <label class="md-nav__link" for="__nav_5_6_2" id="__nav_5_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    augment
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_2">
            <span class="md-nav__icon md-icon"></span>
            augment
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../augment/specaug/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    specaug
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_3" >
        
          
          <label class="md-nav__link" for="__nav_5_6_3" id="__nav_5_6_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    conformer
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_3">
            <span class="md-nav__icon md-icon"></span>
            conformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../conformer/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../conformer/encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../conformer/pos_enc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pos_enc
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_4" >
        
          
          <label class="md-nav__link" for="__nav_5_6_4" id="__nav_5_6_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    decoder
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_4">
            <span class="md-nav__icon md-icon"></span>
            decoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../decoder/ar_asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../decoder/ar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ar_tts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../decoder/nar_tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nar_tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_5" >
        
          
          <label class="md-nav__link" for="__nav_5_6_5" id="__nav_5_6_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    encoder
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_5">
            <span class="md-nav__icon md-icon"></span>
            encoder
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../encoder/asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    asr
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../encoder/tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tts
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_6" >
        
          
          <label class="md-nav__link" for="__nav_5_6_6" id="__nav_5_6_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    frontend
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_6">
            <span class="md-nav__icon md-icon"></span>
            frontend
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../frontend/delta_feat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    delta_feat
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../frontend/linear2mel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear2mel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../frontend/speech2linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech2linear
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../frontend/speech2mel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    speech2mel
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_7" checked>
        
          
          <label class="md-nav__link" for="__nav_5_6_7" id="__nav_5_6_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    norm
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_6_7">
            <span class="md-nav__icon md-icon"></span>
            norm
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    feat_norm
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    feat_norm
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#module.norm.feat_norm" class="md-nav__link">
    <span class="md-ellipsis">
      feat_norm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization" class="md-nav__link">
    <span class="md-ellipsis">
      FeatureNormalization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FeatureNormalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization.module_init" class="md-nav__link">
    <span class="md-ellipsis">
      module_init
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization.recover" class="md-nav__link">
    <span class="md-ellipsis">
      recover
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization.register_mean_std_batch" class="md-nav__link">
    <span class="md-ellipsis">
      register_mean_std_batch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization.sort_data_by_group" class="md-nav__link">
    <span class="md-ellipsis">
      sort_data_by_group
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization.update_aver_mean_std" class="md-nav__link">
    <span class="md-ellipsis">
      update_aver_mean_std
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_8" >
        
          
          <label class="md-nav__link" for="__nav_5_6_8" id="__nav_5_6_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    postnet
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_8">
            <span class="md-nav__icon md-icon"></span>
            postnet
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../postnet/conv1d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv1d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../postnet/token/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    token
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_9" >
        
          
          <label class="md-nav__link" for="__nav_5_6_9" id="__nav_5_6_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    prenet
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_9">
            <span class="md-nav__icon md-icon"></span>
            prenet
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../prenet/conv1d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv1d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../prenet/conv2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    conv2d
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../prenet/embed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    embed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../prenet/linear/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    linear
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../prenet/spk_embed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    spk_embed
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../prenet/var_pred/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    var_pred
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_10" >
        
          
          <label class="md-nav__link" for="__nav_5_6_10" id="__nav_5_6_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    standalone
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_10">
            <span class="md-nav__icon md-icon"></span>
            standalone
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../standalone/lm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    lm
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_6_11" >
        
          
          <label class="md-nav__link" for="__nav_5_6_11" id="__nav_5_6_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    transformer
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_6_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6_11">
            <span class="md-nav__icon md-icon"></span>
            transformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    attention
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    decoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/encoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    encoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/feed_forward/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feed_forward
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../transformer/pos_enc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    pos_enc
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../monitor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    monitor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_8" >
        
          
          <label class="md-nav__link" for="__nav_5_8" id="__nav_5_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    optim_sche
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_8">
            <span class="md-nav__icon md-icon"></span>
            optim_sche
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../optim_sche/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../optim_sche/exp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    exp
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../optim_sche/noam/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    noam
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_9" >
        
          
          <label class="md-nav__link" for="__nav_5_9" id="__nav_5_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    pyscripts
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_9">
            <span class="md-nav__icon md-icon"></span>
            pyscripts
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pyscripts/empty_file_checker/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    empty_file_checker
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pyscripts/folder_summarizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    folder_summarizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pyscripts/model_para_renamer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    model_para_renamer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pyscripts/phn_duaration_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    phn_duaration_visualizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pyscripts/text_dist_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_dist_visualizer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../pyscripts/wavlen_dist_visualizer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    wavlen_dist_visualizer
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../runner/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    runner
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../snapshooter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    snapshooter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_12" >
        
          
          <label class="md-nav__link" for="__nav_5_12" id="__nav_5_12_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    tokenizer
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_12">
            <span class="md-nav__icon md-icon"></span>
            tokenizer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tokenizer/abs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    abs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tokenizer/char/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    char
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tokenizer/g2p/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    g2p
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tokenizer/sp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sp
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_13" >
        
          
          <label class="md-nav__link" for="__nav_5_13" id="__nav_5_13_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    utilbox
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_13">
            <span class="md-nav__icon md-icon"></span>
            utilbox
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/data_loading_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_loading_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/data_saving_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    data_saving_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/dump_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    dump_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/eval_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    eval_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/feat_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    feat_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/import_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    import_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/log_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    log_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/md_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    md_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/regex_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    regex_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/sb_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    sb_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/spk_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    spk_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/tensor_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tensor_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/text_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    text_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/train_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    train_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/type_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    type_util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../utilbox/yaml_util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    yaml_util
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#module.norm.feat_norm" class="md-nav__link">
    <span class="md-ellipsis">
      feat_norm
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization" class="md-nav__link">
    <span class="md-ellipsis">
      FeatureNormalization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="FeatureNormalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization.module_init" class="md-nav__link">
    <span class="md-ellipsis">
      module_init
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization.recover" class="md-nav__link">
    <span class="md-ellipsis">
      recover
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization.register_mean_std_batch" class="md-nav__link">
    <span class="md-ellipsis">
      register_mean_std_batch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization.sort_data_by_group" class="md-nav__link">
    <span class="md-ellipsis">
      sort_data_by_group
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#module.norm.feat_norm.FeatureNormalization.update_aver_mean_std" class="md-nav__link">
    <span class="md-ellipsis">
      update_aver_mean_std
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>feat_norm</h1>

<div class="doc doc-object doc-module">



<a id="module.norm.feat_norm"></a>
    <div class="doc doc-contents first">

        <p>Author: Heli Qi
Affiliation: NAIST
Date: 2022.09</p>








  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="module.norm.feat_norm.FeatureNormalization" class="doc doc-heading">
            <code>FeatureNormalization</code>


</h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="speechain.module.abs.Module">Module</span></code></p>


        <p>The feature normalization frontend that makes every feature dimension the distribution with 0 mean and 1 variance.</p>
<p>As SpeechBrain, we also provide four kinds of feature normalization with different granularities.
    1. utterance-level normalization: the mean and std are calculated on each individual utterance.
    2. batch-level normalization: the mean and std are calculated on all the utterances in a training batch.
    3. group-level normalization: the mean and std are calculated on all the utterances in a group.
        The group here means where the utterance comes from, so it can be any kinds of data domains
        such as different speakers, genders, source and target domains in Domain Adaptation scenario, and so on...
    4. global-level normalization: the mean and std are calculated on all the utterances in the training set.</p>
<p>We approximate group-level and global-level mean &amp; std by taking their moving average during training.
Different from SpeechBrain, we initialize all the mean &amp; std variables lazily in the forward() function.
Another difference is that our moving average is calculated by each batch as BatchNorm does.</p>
<p>In the DDP mode, the mean &amp; std will be synchronized across all the processes before being used to normalize the
input utterances. The synchronization method is different in different scenarios.</p>
<ol>
<li>
<p>group-level normalization where each input utterance has different group id (group_ids = torch.Tensor,
    e.g. different utterances in a single batch may belong to different speakers).
    In this scenario, the mean &amp; std vectors of each utterance and the group ids will be gathered across all the
    processes. Then, the mean &amp; std vectors will be picked up depending on the group id and the mean &amp; std of the
    specific group will be calculated.</p>
</li>
<li>
<p>global-level normalization or group-level normalization where all the input utterances have the same group id
    (group_ids = str or int, e.g. all the utterances in the batch come from either the source domain or the target
    domain). In this scenario, the summation of mean &amp; std vectors will be gathered instead of all of them to reduce
    the data communication volume across all the processes. The real mean &amp; std vectors will be recovered by the
    batch size of each process.</p>
</li>
</ol>






              <details class="quote">
                <summary>Source code in <code>speechain/module/norm/feat_norm.py</code></summary>
                <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">FeatureNormalization</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The feature normalization frontend that makes every feature dimension the distribution with 0 mean and 1 variance.</span>

<span class="sd">    As SpeechBrain, we also provide four kinds of feature normalization with different granularities.</span>
<span class="sd">        1. utterance-level normalization: the mean and std are calculated on each individual utterance.</span>
<span class="sd">        2. batch-level normalization: the mean and std are calculated on all the utterances in a training batch.</span>
<span class="sd">        3. group-level normalization: the mean and std are calculated on all the utterances in a group.</span>
<span class="sd">            The group here means where the utterance comes from, so it can be any kinds of data domains</span>
<span class="sd">            such as different speakers, genders, source and target domains in Domain Adaptation scenario, and so on...</span>
<span class="sd">        4. global-level normalization: the mean and std are calculated on all the utterances in the training set.</span>

<span class="sd">    We approximate group-level and global-level mean &amp; std by taking their moving average during training.</span>
<span class="sd">    Different from SpeechBrain, we initialize all the mean &amp; std variables lazily in the forward() function.</span>
<span class="sd">    Another difference is that our moving average is calculated by each batch as BatchNorm does.</span>

<span class="sd">    In the DDP mode, the mean &amp; std will be synchronized across all the processes before being used to normalize the</span>
<span class="sd">    input utterances. The synchronization method is different in different scenarios.</span>

<span class="sd">    1. group-level normalization where each input utterance has different group id (group_ids = torch.Tensor,</span>
<span class="sd">        e.g. different utterances in a single batch may belong to different speakers).</span>
<span class="sd">        In this scenario, the mean &amp; std vectors of each utterance and the group ids will be gathered across all the</span>
<span class="sd">        processes. Then, the mean &amp; std vectors will be picked up depending on the group id and the mean &amp; std of the</span>
<span class="sd">        specific group will be calculated.</span>

<span class="sd">    2. global-level normalization or group-level normalization where all the input utterances have the same group id</span>
<span class="sd">        (group_ids = str or int, e.g. all the utterances in the batch come from either the source domain or the target</span>
<span class="sd">        domain). In this scenario, the summation of mean &amp; std vectors will be gathered instead of all of them to reduce</span>
<span class="sd">        the data communication volume across all the processes. The real mean &amp; std vectors will be recovered by the</span>
<span class="sd">        batch size of each process.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">module_init</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">norm_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;global&quot;</span><span class="p">,</span>
        <span class="n">mean_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">std_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">clamp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-10</span><span class="p">,</span>
        <span class="n">max_epoch_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            norm_type: str</span>
<span class="sd">                The type of feature normalization.</span>
<span class="sd">                The type must be one of &#39;utterance&#39;, &#39;batch&#39;, &#39;group&#39;, and &#39;global&#39;</span>
<span class="sd">            mean_norm: bool</span>
<span class="sd">                Controls whether the feature vectors will be normalized by their means</span>
<span class="sd">            std_norm: bool</span>
<span class="sd">                Controls whether the feature vectors will be normalized by their standard variance</span>
<span class="sd">            clamp: float</span>
<span class="sd">                Clamping threshold for the standard variance before division.</span>
<span class="sd">            max_epoch_num: int</span>
<span class="sd">                The maximum number of epochs used to calculate the moving average.</span>
<span class="sd">                Usually, the value of this argument is lower than a half of the number of warmup epochs.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">=</span> <span class="n">norm_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span> <span class="o">=</span> <span class="n">mean_norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span> <span class="o">=</span> <span class="n">std_norm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clamp</span> <span class="o">=</span> <span class="n">clamp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_epoch_num</span> <span class="o">=</span> <span class="n">max_epoch_num</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">group_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">str</span> <span class="ow">or</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            feat: (batch, length, channel) or (batch, length)</span>
<span class="sd">                The normalization will be done on the channel dimension.</span>
<span class="sd">                If the feat is in the shape of (batch, length), it will be extended to (batch, length, 1)</span>
<span class="sd">            feat_len: (batch)</span>
<span class="sd">            group_ids: (batch)</span>
<span class="sd">            epoch:</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;group&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">group_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
                <span class="s2">&quot;You are using group-level feature normalization, but group_ids is not given. &quot;</span>
                <span class="s2">&quot;Please check &#39;data_cfg&#39; in your configuration.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># para preparation</span>
        <span class="n">batch_size</span><span class="p">,</span> <span class="n">squeeze_flag</span> <span class="o">=</span> <span class="n">feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">feat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">feat</span><span class="p">,</span> <span class="n">squeeze_flag</span> <span class="o">=</span> <span class="n">feat</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">feat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> only accepts the input vectors in the shape of &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;(batch, length, channel) or (batch, length), but got shape=</span><span class="si">{</span><span class="n">feat</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">!&quot;</span>
            <span class="p">)</span>

        <span class="c1"># --- Mean and Standard Variance Initialization --- #</span>
        <span class="c1"># calculate the mean values of all channels of all the input utterances</span>
        <span class="n">curr_means</span> <span class="o">=</span> <span class="p">(</span>
            <span class="kc">None</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span>
            <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span><span class="n">feat</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span> <span class="n">feat_len</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># calculate the std values of all channels of all the input utterances</span>
        <span class="n">curr_stds</span> <span class="o">=</span> <span class="p">(</span>
            <span class="kc">None</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span>
            <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
                <span class="nb">input</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">feat</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span> <span class="n">feat_len</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>
                <span class="p">),</span>
                <span class="nb">min</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clamp</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># --- Perform Normalization based on Different branches --- #</span>
        <span class="c1"># utterance-level normalization or group-level normalization without group_ids</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;utterance&quot;</span><span class="p">:</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span> <span class="o">-</span> <span class="n">curr_means</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">curr_means</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">feat</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span> <span class="o">/</span> <span class="n">curr_stds</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">curr_stds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">feat</span>

        <span class="c1"># global-level &amp; batch-level &amp; group-level normalization (with group_ids)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># only gather the batch sizes from other processes in the DDP model of training</span>
            <span class="n">all_batch_size</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="n">all_batch_size</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">gather_scalars</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">feat</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span>
                    <span class="k">else</span> <span class="n">batch_size</span>
                <span class="p">)</span>

            <span class="c1"># group-level normalization with tensor group_ids (input utterances belong to different groups)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;group&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">group_ids</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="c1"># only update the mean and std of the specific group during training</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                    <span class="c1"># DDP mode</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
                        <span class="c1"># gather all the group ids from other processes</span>
                        <span class="n">all_group_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gather_vectors</span><span class="p">(</span><span class="n">group_ids</span><span class="p">,</span> <span class="n">all_batch_size</span><span class="p">)</span>
                        <span class="c1"># gather all the mean vectors from other processes</span>
                        <span class="n">all_curr_means</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="kc">None</span>
                            <span class="k">if</span> <span class="n">curr_means</span> <span class="ow">is</span> <span class="kc">None</span>
                            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">gather_matrices</span><span class="p">(</span><span class="n">curr_means</span><span class="p">,</span> <span class="n">all_batch_size</span><span class="p">)</span>
                        <span class="p">)</span>
                        <span class="c1"># gather all the std vectors from other processes</span>
                        <span class="n">all_curr_stds</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="kc">None</span>
                            <span class="k">if</span> <span class="n">curr_stds</span> <span class="ow">is</span> <span class="kc">None</span>
                            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">gather_matrices</span><span class="p">(</span><span class="n">curr_stds</span><span class="p">,</span> <span class="n">all_batch_size</span><span class="p">)</span>
                        <span class="p">)</span>
                    <span class="c1"># single-GPU mode</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># not perform gathering</span>
                        <span class="n">all_group_ids</span> <span class="o">=</span> <span class="n">group_ids</span>
                        <span class="n">all_curr_means</span> <span class="o">=</span> <span class="n">curr_means</span>
                        <span class="n">all_curr_stds</span> <span class="o">=</span> <span class="n">curr_stds</span>

                    <span class="c1"># record the mean of all groups in the current batch</span>
                    <span class="n">group_mean_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sort_data_by_group</span><span class="p">(</span>
                        <span class="n">raw_data</span><span class="o">=</span><span class="n">all_curr_means</span><span class="p">,</span> <span class="n">group_ids</span><span class="o">=</span><span class="n">all_group_ids</span>
                    <span class="p">)</span>

                    <span class="c1"># record the std of all groups in the current batch</span>
                    <span class="n">group_std_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sort_data_by_group</span><span class="p">(</span>
                        <span class="n">raw_data</span><span class="o">=</span><span class="n">all_curr_stds</span><span class="p">,</span> <span class="n">group_ids</span><span class="o">=</span><span class="n">all_group_ids</span>
                    <span class="p">)</span>

                    <span class="c1"># register the mean, std, and batch numbers into the buffer</span>
                    <span class="n">group_keys</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="nb">list</span><span class="p">(</span><span class="n">group_mean_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
                        <span class="k">if</span> <span class="n">group_mean_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="nb">list</span><span class="p">(</span><span class="n">group_std_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">group_id</span> <span class="ow">in</span> <span class="n">group_keys</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">register_mean_std_batch</span><span class="p">(</span>
                            <span class="n">curr_aver_mean</span><span class="o">=</span><span class="p">(</span>
                                <span class="n">group_mean_dict</span><span class="p">[</span><span class="n">group_id</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                                <span class="k">if</span> <span class="n">group_mean_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                                <span class="k">else</span> <span class="kc">None</span>
                            <span class="p">),</span>
                            <span class="n">curr_aver_std</span><span class="o">=</span><span class="p">(</span>
                                <span class="n">group_std_dict</span><span class="p">[</span><span class="n">group_id</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                                <span class="k">if</span> <span class="n">group_std_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                                <span class="k">else</span> <span class="kc">None</span>
                            <span class="p">),</span>
                            <span class="n">prefix</span><span class="o">=</span><span class="n">group_id</span><span class="p">,</span>
                            <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                        <span class="p">)</span>
                    <span class="c1"># update the average mean &amp; std of all the groups</span>
                    <span class="c1"># (i.e. the average distribution for unknown samples during inference)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">update_aver_mean_std</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

                <span class="c1"># During training, normalize the known features by the group mean &amp; std</span>
                <span class="c1"># During inference, normalize the unknown features by the average mean &amp; std of all groups</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
                    <span class="n">group_id</span> <span class="o">=</span> <span class="n">group_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="n">group_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span><span class="p">:</span>
                        <span class="n">feat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="s2">&quot;aver_mean&quot;</span><span class="p">)</span>
                            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">group_id</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span>
                            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">group_id</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span>
                        <span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span><span class="p">:</span>
                        <span class="n">feat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/=</span> <span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="s2">&quot;aver_std&quot;</span><span class="p">)</span>
                            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">group_id</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span>
                            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">group_id</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span>
                        <span class="p">)</span>

            <span class="c1"># batch-level &amp; global-level normalization (these two scenarios share the batch-level mean &amp; std)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># only calculate the batch-level mean and std during training</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                    <span class="c1"># gather the mean and std from the other processes in the DDP mode</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
                        <span class="c1"># gather the sums of batch means from all the processes</span>
                        <span class="n">batch_mean_sum</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">curr_means</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">curr_means</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
                        <span class="p">)</span>
                        <span class="n">all_batch_mean_sums</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">gather_vectors</span><span class="p">(</span><span class="n">batch_mean_sum</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">batch_mean_sum</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                            <span class="k">else</span> <span class="kc">None</span>
                        <span class="p">)</span>
                        <span class="n">batch_mean</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="kc">None</span>
                            <span class="k">if</span> <span class="n">all_batch_mean_sums</span> <span class="ow">is</span> <span class="kc">None</span>
                            <span class="k">else</span> <span class="n">all_batch_mean_sums</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">all_batch_size</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                        <span class="p">)</span>

                        <span class="c1"># gather the sums of batch stds from all the processes</span>
                        <span class="n">batch_std_sum</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">curr_stds</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">curr_stds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
                        <span class="p">)</span>
                        <span class="n">all_batch_std_sums</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">gather_vectors</span><span class="p">(</span><span class="n">batch_std_sum</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">batch_std_sum</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                            <span class="k">else</span> <span class="kc">None</span>
                        <span class="p">)</span>
                        <span class="n">batch_std</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="kc">None</span>
                            <span class="k">if</span> <span class="n">all_batch_std_sums</span> <span class="ow">is</span> <span class="kc">None</span>
                            <span class="k">else</span> <span class="n">all_batch_std_sums</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">all_batch_size</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                        <span class="p">)</span>

                    <span class="c1"># single-GPU mode</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">batch_mean</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">curr_means</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">curr_means</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
                        <span class="p">)</span>
                        <span class="n">batch_std</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">curr_stds</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">curr_stds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
                        <span class="p">)</span>

                <span class="c1"># do nothing for batch-level mean and std during evaluation</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">batch_mean</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">batch_std</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="c1"># batch-level normalization</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;batch&quot;</span><span class="p">:</span>
                    <span class="c1"># normalize the input utterances by the batch mean and std during training</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                        <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span> <span class="o">-</span> <span class="n">batch_mean</span> <span class="k">if</span> <span class="n">batch_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">feat</span>
                        <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span> <span class="o">/</span> <span class="n">batch_std</span> <span class="k">if</span> <span class="n">batch_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">feat</span>
                    <span class="c1"># normalize the input utterances by the utterance-specific mean and std during evaluation</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">feat</span> <span class="o">-</span> <span class="n">curr_means</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">curr_means</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                            <span class="k">else</span> <span class="n">feat</span>
                        <span class="p">)</span>
                        <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">feat</span> <span class="o">/</span> <span class="n">curr_stds</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">curr_stds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                            <span class="k">else</span> <span class="n">feat</span>
                        <span class="p">)</span>

                <span class="c1"># global-level normalization or</span>
                <span class="c1"># group-level normalization with str or int group_ids (input utterances belong to the same group)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;global&quot;</span><span class="p">,</span> <span class="s2">&quot;group&quot;</span><span class="p">],</span> <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;norm_type can only be one of &#39;utterance&#39;, &#39;batch&#39;, &#39;group&#39;, &#39;global&#39;, &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;but got norm_type=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span><span class="si">}</span><span class="s2">!&quot;</span>
                    <span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;group&quot;</span><span class="p">:</span>
                        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">group_ids</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">)),</span> <span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;If all the utterances in a single batch belong to the same group, &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;you should give group_ids as a string or integer. &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;But got type(group_ids)=</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">group_ids</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                        <span class="p">)</span>

                    <span class="c1"># only update the mean and std during training</span>
                    <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;global&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;global&quot;</span> <span class="k">else</span> <span class="n">group_ids</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">register_mean_std_batch</span><span class="p">(</span>
                            <span class="n">curr_aver_mean</span><span class="o">=</span><span class="n">batch_mean</span><span class="p">,</span>
                            <span class="n">curr_aver_std</span><span class="o">=</span><span class="n">batch_std</span><span class="p">,</span>
                            <span class="n">prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">,</span>
                            <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                        <span class="p">)</span>

                    <span class="c1"># if the group_ids is given as a string or int,</span>
                    <span class="c1"># we assume that there are no unknown testing samples during inference</span>
                    <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">feat</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">curr_means</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="n">feat</span>
                    <span class="p">)</span>
                    <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">feat</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">curr_stds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="n">feat</span>
                    <span class="p">)</span>

        <span class="k">return</span> <span class="n">feat</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">squeeze_flag</span> <span class="k">else</span> <span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">gather_scalars</span><span class="p">(</span><span class="n">scalar</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">:</span>
        <span class="c1"># gather the input scalars</span>
        <span class="n">all_scalars</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">())</span>
        <span class="p">]</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span>
            <span class="n">all_scalars</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="n">scalar</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">all_scalars</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">gather_vectors</span><span class="p">(</span>
        <span class="n">vector</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">all_batch_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># vectors of all the processes may have different length</span>
        <span class="k">if</span> <span class="n">all_batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">curr_batch_size</span> <span class="o">=</span> <span class="n">all_batch_size</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">max_batch_size</span> <span class="o">=</span> <span class="n">all_batch_size</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">curr_batch_size</span> <span class="o">&lt;</span> <span class="n">max_batch_size</span><span class="p">:</span>
                <span class="n">vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="n">vector</span><span class="p">,</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                            <span class="n">max_batch_size</span> <span class="o">-</span> <span class="n">curr_batch_size</span><span class="p">,</span>
                            <span class="n">dtype</span><span class="o">=</span><span class="n">vector</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                            <span class="n">device</span><span class="o">=</span><span class="n">vector</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                        <span class="p">),</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="n">all_vectors</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_batch_size</span><span class="p">)])</span>
                <span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>
                <span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">vector</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">())</span>
            <span class="p">]</span>
        <span class="c1"># all the vectors are equal in length</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">all_vectors</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">vector</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">())</span>
            <span class="p">]</span>

        <span class="c1"># gather the vectors from other processes to all_vectors</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">all_vectors</span><span class="p">,</span> <span class="n">vector</span><span class="p">)</span>

        <span class="c1"># remove the padding</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">all_vectors</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">all_batch_size</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">all_vectors</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span> <span class="n">all_batch_size</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_vectors</span><span class="p">))]</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">gather_matrices</span><span class="p">(</span>
        <span class="n">matrix</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">all_batch_size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">curr_batch_size</span> <span class="o">=</span> <span class="n">all_batch_size</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">max_batch_size</span> <span class="o">=</span> <span class="n">all_batch_size</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="c1"># padding the matrix if necessary</span>
        <span class="k">if</span> <span class="n">curr_batch_size</span> <span class="o">&lt;</span> <span class="n">max_batch_size</span><span class="p">:</span>
            <span class="n">matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="n">matrix</span><span class="p">,</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                        <span class="n">max_batch_size</span> <span class="o">-</span> <span class="n">curr_batch_size</span><span class="p">,</span>
                        <span class="n">matrix</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                        <span class="n">device</span><span class="o">=</span><span class="n">matrix</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># gather the matrices from other processes to all_matrices</span>
        <span class="n">all_matrices</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">matrix</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">())</span>
        <span class="p">]</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">all_matrices</span><span class="p">,</span> <span class="n">matrix</span><span class="p">)</span>

        <span class="c1"># remove the padding</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">all_matrices</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span> <span class="n">all_batch_size</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_matrices</span><span class="p">))]</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">sort_data_by_group</span><span class="p">(</span><span class="n">raw_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            raw_data:</span>
<span class="sd">            group_ids:</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">raw_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">group_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="c1"># loop each group id</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">group_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
                <span class="n">curr_group</span> <span class="o">=</span> <span class="n">group_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="c1"># initialize the group list if not existed</span>
                <span class="k">if</span> <span class="n">curr_group</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">group_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">group_dict</span><span class="p">[</span><span class="n">curr_group</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">group_dict</span><span class="p">[</span><span class="n">curr_group</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">raw_data</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="c1"># turn each group list into a 2d tensor</span>
            <span class="k">return</span> <span class="p">{</span>
                <span class="n">group_id</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">group_list</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">group_id</span><span class="p">,</span> <span class="n">group_list</span> <span class="ow">in</span> <span class="n">group_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>

    <span class="k">def</span> <span class="nf">register_mean_std_batch</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">curr_aver_mean</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">curr_aver_std</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            curr_aver_mean:</span>
<span class="sd">            curr_aver_std:</span>
<span class="sd">            prefix:</span>
<span class="sd">            epoch:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># update the observed global batch number</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_batch&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_batch&quot;</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">curr_aver_mean</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">epoch</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epoch_num</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_batch&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_batch&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="p">)</span>

        <span class="c1"># update the observed global mean &amp; std only in the predefined batch number</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epoch_num</span><span class="p">:</span>
            <span class="c1"># get the weight of the global average values</span>
            <span class="n">curr_weight</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_batch&quot;</span><span class="p">)</span>

            <span class="c1"># update the observed global mean</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">,</span> <span class="n">curr_aver_mean</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">prev_aver_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">,</span>
                        <span class="n">curr_weight</span> <span class="o">*</span> <span class="n">curr_aver_mean</span>
                        <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">curr_weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">prev_aver_mean</span><span class="p">,</span>
                    <span class="p">)</span>

            <span class="c1"># update the observed global std</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">,</span> <span class="n">curr_aver_std</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">prev_aver_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">,</span>
                        <span class="n">curr_weight</span> <span class="o">*</span> <span class="n">curr_aver_std</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">curr_weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">prev_aver_std</span><span class="p">,</span>
                    <span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_aver_mean_std</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            epoch:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epoch_num</span><span class="p">:</span>
            <span class="n">_group_mean_num</span><span class="p">,</span> <span class="n">_group_std_num</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
            <span class="n">_aver_mean</span><span class="p">,</span> <span class="n">_aver_std</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buff</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_mean&quot;</span><span class="p">):</span>
                    <span class="n">_group_mean_num</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">_aver_mean</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">buff</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="n">_aver_mean</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">_aver_mean</span> <span class="o">+</span> <span class="n">buff</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_std&quot;</span><span class="p">):</span>
                    <span class="n">_group_std_num</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">_aver_std</span> <span class="o">=</span> <span class="n">buff</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="n">_aver_std</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">_aver_std</span> <span class="o">+</span> <span class="n">buff</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;aver_mean&quot;</span><span class="p">,</span> <span class="n">_aver_mean</span> <span class="o">/</span> <span class="n">_group_mean_num</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;aver_std&quot;</span><span class="p">,</span> <span class="n">_aver_std</span> <span class="o">/</span> <span class="n">_group_std_num</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">recover</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">str</span> <span class="ow">or</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            feat:</span>
<span class="sd">            group_ids:</span>

<span class="sd">        Returns:</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="s2">&quot;utterance&quot;</span><span class="p">,</span>
            <span class="s2">&quot;batch&quot;</span><span class="p">,</span>
        <span class="p">],</span> <span class="s2">&quot;If norm_type is either &#39;utterance&#39; or &#39;batch&#39;, the normalized features cannot be recovered.&quot;</span>

        <span class="c1"># global normalization or</span>
        <span class="c1"># group-level normalization with str or int group_ids (input utterances belong to the same group)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;global&quot;</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;group&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">group_ids</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span>
        <span class="p">):</span>
            <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;global&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;global&quot;</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">group_ids</span><span class="p">)</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span> <span class="k">else</span> <span class="n">feat</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span> <span class="k">else</span> <span class="n">feat</span>
        <span class="c1"># group-level normalization with tensor group_ids (input utterances belong to different groups)</span>
        <span class="c1"># recover by the average mean &amp; std when meeting an unknown group during inference</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;group&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">group_ids</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">feat</span>
                <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g_id</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span>
                            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g_id</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span>
                            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="s2">&quot;aver_std&quot;</span><span class="p">)</span>
                        <span class="p">)</span>
                        <span class="k">for</span> <span class="n">g_id</span> <span class="ow">in</span> <span class="n">group_ids</span>
                    <span class="p">],</span>
                    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span>
                <span class="k">else</span> <span class="n">feat</span>
            <span class="p">)</span>

            <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">feat</span>
                <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g_id</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span>
                            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g_id</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span>
                            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="s2">&quot;aver_mean&quot;</span><span class="p">)</span>
                        <span class="p">)</span>
                        <span class="k">for</span> <span class="n">g_id</span> <span class="ow">in</span> <span class="n">group_ids</span>
                    <span class="p">],</span>
                    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span>
                <span class="k">else</span> <span class="n">feat</span>
            <span class="p">)</span>
        <span class="c1"># group-level normalization with None group_ids, recover by the average mean &amp; std</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;group&quot;</span> <span class="ow">and</span> <span class="n">group_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">feat</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="s2">&quot;aver_std&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span>
                <span class="k">else</span> <span class="n">feat</span>
            <span class="p">)</span>
            <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">feat</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="s2">&quot;aver_mean&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span>
                <span class="k">else</span> <span class="n">feat</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span>

        <span class="k">return</span> <span class="n">feat</span>

    <span class="k">def</span> <span class="nf">_load_from_state_dict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">state_dict</span><span class="p">,</span>
        <span class="n">prefix</span><span class="p">,</span>
        <span class="n">local_metadata</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">,</span>
        <span class="n">missing_keys</span><span class="p">,</span>
        <span class="n">unexpected_keys</span><span class="p">,</span>
        <span class="n">error_msgs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Lazily register all the buffer variables ending with &#39;_batch&#39;, &#39;_std&#39;, or &#39;_mean&#39; from state_dict to self.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">prefix</span><span class="p">):</span>
                <span class="n">input_name</span> <span class="o">=</span> <span class="n">key</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span> <span class="p">:]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

                <span class="k">if</span> <span class="s2">&quot;_&quot;</span> <span class="ow">in</span> <span class="n">input_name</span> <span class="ow">and</span> <span class="n">input_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">in</span> <span class="p">[</span>
                    <span class="s2">&quot;batch&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;std&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;mean&quot;</span><span class="p">,</span>
                <span class="p">]:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="n">input_name</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">unexpected_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;norm_type=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span><span class="si">}</span><span class="s2">, mean_norm=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span><span class="si">}</span><span class="s2">, std_norm=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span><span class="si">}</span><span class="s2">&quot;</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="module.norm.feat_norm.FeatureNormalization.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span><span class="p">,</span> <span class="n">group_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>feat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch, length, channel) or (batch, length)
The normalization will be done on the channel dimension.
If the feat is in the shape of (batch, length), it will be extended to (batch, length, 1)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>feat_len</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch)</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>group_ids</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span> or str or int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(batch)</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epoch</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Returns:</p>

            <details class="quote">
              <summary>Source code in <code>speechain/module/norm/feat_norm.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">feat_len</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">group_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">str</span> <span class="ow">or</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        feat: (batch, length, channel) or (batch, length)</span>
<span class="sd">            The normalization will be done on the channel dimension.</span>
<span class="sd">            If the feat is in the shape of (batch, length), it will be extended to (batch, length, 1)</span>
<span class="sd">        feat_len: (batch)</span>
<span class="sd">        group_ids: (batch)</span>
<span class="sd">        epoch:</span>

<span class="sd">    Returns:</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;group&quot;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">group_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="p">(</span>
            <span class="s2">&quot;You are using group-level feature normalization, but group_ids is not given. &quot;</span>
            <span class="s2">&quot;Please check &#39;data_cfg&#39; in your configuration.&quot;</span>
        <span class="p">)</span>
    <span class="c1"># para preparation</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="n">squeeze_flag</span> <span class="o">=</span> <span class="n">feat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">feat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">feat</span><span class="p">,</span> <span class="n">squeeze_flag</span> <span class="o">=</span> <span class="n">feat</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">feat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> only accepts the input vectors in the shape of &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;(batch, length, channel) or (batch, length), but got shape=</span><span class="si">{</span><span class="n">feat</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">!&quot;</span>
        <span class="p">)</span>

    <span class="c1"># --- Mean and Standard Variance Initialization --- #</span>
    <span class="c1"># calculate the mean values of all channels of all the input utterances</span>
    <span class="n">curr_means</span> <span class="o">=</span> <span class="p">(</span>
        <span class="kc">None</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span>
        <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
            <span class="p">[</span><span class="n">feat</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span> <span class="n">feat_len</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># calculate the std values of all channels of all the input utterances</span>
    <span class="n">curr_stds</span> <span class="o">=</span> <span class="p">(</span>
        <span class="kc">None</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span>
        <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
            <span class="nb">input</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span><span class="n">feat</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span> <span class="n">feat_len</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)]</span>
            <span class="p">),</span>
            <span class="nb">min</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clamp</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># --- Perform Normalization based on Different branches --- #</span>
    <span class="c1"># utterance-level normalization or group-level normalization without group_ids</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;utterance&quot;</span><span class="p">:</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span> <span class="o">-</span> <span class="n">curr_means</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">curr_means</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">feat</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span> <span class="o">/</span> <span class="n">curr_stds</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">curr_stds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">feat</span>

    <span class="c1"># global-level &amp; batch-level &amp; group-level normalization (with group_ids)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># only gather the batch sizes from other processes in the DDP model of training</span>
        <span class="n">all_batch_size</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="n">all_batch_size</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">gather_scalars</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">feat</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span>
                <span class="k">else</span> <span class="n">batch_size</span>
            <span class="p">)</span>

        <span class="c1"># group-level normalization with tensor group_ids (input utterances belong to different groups)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;group&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">group_ids</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># only update the mean and std of the specific group during training</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="c1"># DDP mode</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
                    <span class="c1"># gather all the group ids from other processes</span>
                    <span class="n">all_group_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gather_vectors</span><span class="p">(</span><span class="n">group_ids</span><span class="p">,</span> <span class="n">all_batch_size</span><span class="p">)</span>
                    <span class="c1"># gather all the mean vectors from other processes</span>
                    <span class="n">all_curr_means</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="kc">None</span>
                        <span class="k">if</span> <span class="n">curr_means</span> <span class="ow">is</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">gather_matrices</span><span class="p">(</span><span class="n">curr_means</span><span class="p">,</span> <span class="n">all_batch_size</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="c1"># gather all the std vectors from other processes</span>
                    <span class="n">all_curr_stds</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="kc">None</span>
                        <span class="k">if</span> <span class="n">curr_stds</span> <span class="ow">is</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">gather_matrices</span><span class="p">(</span><span class="n">curr_stds</span><span class="p">,</span> <span class="n">all_batch_size</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="c1"># single-GPU mode</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># not perform gathering</span>
                    <span class="n">all_group_ids</span> <span class="o">=</span> <span class="n">group_ids</span>
                    <span class="n">all_curr_means</span> <span class="o">=</span> <span class="n">curr_means</span>
                    <span class="n">all_curr_stds</span> <span class="o">=</span> <span class="n">curr_stds</span>

                <span class="c1"># record the mean of all groups in the current batch</span>
                <span class="n">group_mean_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sort_data_by_group</span><span class="p">(</span>
                    <span class="n">raw_data</span><span class="o">=</span><span class="n">all_curr_means</span><span class="p">,</span> <span class="n">group_ids</span><span class="o">=</span><span class="n">all_group_ids</span>
                <span class="p">)</span>

                <span class="c1"># record the std of all groups in the current batch</span>
                <span class="n">group_std_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sort_data_by_group</span><span class="p">(</span>
                    <span class="n">raw_data</span><span class="o">=</span><span class="n">all_curr_stds</span><span class="p">,</span> <span class="n">group_ids</span><span class="o">=</span><span class="n">all_group_ids</span>
                <span class="p">)</span>

                <span class="c1"># register the mean, std, and batch numbers into the buffer</span>
                <span class="n">group_keys</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="nb">list</span><span class="p">(</span><span class="n">group_mean_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
                    <span class="k">if</span> <span class="n">group_mean_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="nb">list</span><span class="p">(</span><span class="n">group_std_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">group_id</span> <span class="ow">in</span> <span class="n">group_keys</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">register_mean_std_batch</span><span class="p">(</span>
                        <span class="n">curr_aver_mean</span><span class="o">=</span><span class="p">(</span>
                            <span class="n">group_mean_dict</span><span class="p">[</span><span class="n">group_id</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">group_mean_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                            <span class="k">else</span> <span class="kc">None</span>
                        <span class="p">),</span>
                        <span class="n">curr_aver_std</span><span class="o">=</span><span class="p">(</span>
                            <span class="n">group_std_dict</span><span class="p">[</span><span class="n">group_id</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">group_std_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                            <span class="k">else</span> <span class="kc">None</span>
                        <span class="p">),</span>
                        <span class="n">prefix</span><span class="o">=</span><span class="n">group_id</span><span class="p">,</span>
                        <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="c1"># update the average mean &amp; std of all the groups</span>
                <span class="c1"># (i.e. the average distribution for unknown samples during inference)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_aver_mean_std</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

            <span class="c1"># During training, normalize the known features by the group mean &amp; std</span>
            <span class="c1"># During inference, normalize the unknown features by the average mean &amp; std of all groups</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
                <span class="n">group_id</span> <span class="o">=</span> <span class="n">group_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="n">group_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span><span class="p">:</span>
                    <span class="n">feat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="s2">&quot;aver_mean&quot;</span><span class="p">)</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">group_id</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span>
                        <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">group_id</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span><span class="p">:</span>
                    <span class="n">feat</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/=</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="s2">&quot;aver_std&quot;</span><span class="p">)</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">group_id</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span>
                        <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">group_id</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span>
                    <span class="p">)</span>

        <span class="c1"># batch-level &amp; global-level normalization (these two scenarios share the batch-level mean &amp; std)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># only calculate the batch-level mean and std during training</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="c1"># gather the mean and std from the other processes in the DDP mode</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
                    <span class="c1"># gather the sums of batch means from all the processes</span>
                    <span class="n">batch_mean_sum</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">curr_means</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">curr_means</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
                    <span class="p">)</span>
                    <span class="n">all_batch_mean_sums</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">gather_vectors</span><span class="p">(</span><span class="n">batch_mean_sum</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">batch_mean_sum</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="kc">None</span>
                    <span class="p">)</span>
                    <span class="n">batch_mean</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="kc">None</span>
                        <span class="k">if</span> <span class="n">all_batch_mean_sums</span> <span class="ow">is</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="n">all_batch_mean_sums</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">all_batch_size</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                    <span class="p">)</span>

                    <span class="c1"># gather the sums of batch stds from all the processes</span>
                    <span class="n">batch_std_sum</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">curr_stds</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">curr_stds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
                    <span class="p">)</span>
                    <span class="n">all_batch_std_sums</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">gather_vectors</span><span class="p">(</span><span class="n">batch_std_sum</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">batch_std_sum</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="kc">None</span>
                    <span class="p">)</span>
                    <span class="n">batch_std</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="kc">None</span>
                        <span class="k">if</span> <span class="n">all_batch_std_sums</span> <span class="ow">is</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="n">all_batch_std_sums</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">all_batch_size</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                    <span class="p">)</span>

                <span class="c1"># single-GPU mode</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">batch_mean</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">curr_means</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">curr_means</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
                    <span class="p">)</span>
                    <span class="n">batch_std</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">curr_stds</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">curr_stds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
                    <span class="p">)</span>

            <span class="c1"># do nothing for batch-level mean and std during evaluation</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch_mean</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">batch_std</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># batch-level normalization</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;batch&quot;</span><span class="p">:</span>
                <span class="c1"># normalize the input utterances by the batch mean and std during training</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                    <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span> <span class="o">-</span> <span class="n">batch_mean</span> <span class="k">if</span> <span class="n">batch_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">feat</span>
                    <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span> <span class="o">/</span> <span class="n">batch_std</span> <span class="k">if</span> <span class="n">batch_std</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">feat</span>
                <span class="c1"># normalize the input utterances by the utterance-specific mean and std during evaluation</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">feat</span> <span class="o">-</span> <span class="n">curr_means</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">curr_means</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="n">feat</span>
                    <span class="p">)</span>
                    <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">feat</span> <span class="o">/</span> <span class="n">curr_stds</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">curr_stds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="k">else</span> <span class="n">feat</span>
                    <span class="p">)</span>

            <span class="c1"># global-level normalization or</span>
            <span class="c1"># group-level normalization with str or int group_ids (input utterances belong to the same group)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;global&quot;</span><span class="p">,</span> <span class="s2">&quot;group&quot;</span><span class="p">],</span> <span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;norm_type can only be one of &#39;utterance&#39;, &#39;batch&#39;, &#39;group&#39;, &#39;global&#39;, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;but got norm_type=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span><span class="si">}</span><span class="s2">!&quot;</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;group&quot;</span><span class="p">:</span>
                    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">group_ids</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">)),</span> <span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;If all the utterances in a single batch belong to the same group, &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;you should give group_ids as a string or integer. &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;But got type(group_ids)=</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">group_ids</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>

                <span class="c1"># only update the mean and std during training</span>
                <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;global&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;global&quot;</span> <span class="k">else</span> <span class="n">group_ids</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">register_mean_std_batch</span><span class="p">(</span>
                        <span class="n">curr_aver_mean</span><span class="o">=</span><span class="n">batch_mean</span><span class="p">,</span>
                        <span class="n">curr_aver_std</span><span class="o">=</span><span class="n">batch_std</span><span class="p">,</span>
                        <span class="n">prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">,</span>
                        <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                    <span class="p">)</span>

                <span class="c1"># if the group_ids is given as a string or int,</span>
                <span class="c1"># we assume that there are no unknown testing samples during inference</span>
                <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">feat</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">curr_means</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="n">feat</span>
                <span class="p">)</span>
                <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">feat</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">curr_stds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="k">else</span> <span class="n">feat</span>
                <span class="p">)</span>

    <span class="k">return</span> <span class="n">feat</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">squeeze_flag</span> <span class="k">else</span> <span class="n">feat</span><span class="p">,</span> <span class="n">feat_len</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="module.norm.feat_norm.FeatureNormalization.module_init" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">module_init</span><span class="p">(</span><span class="n">norm_type</span><span class="o">=</span><span class="s1">&#39;global&#39;</span><span class="p">,</span> <span class="n">mean_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">std_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">clamp</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">max_epoch_num</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>norm_type</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>str
The type of feature normalization.
The type must be one of 'utterance', 'batch', 'group', and 'global'</p>
              </div>
            </td>
            <td>
                  <code>&#39;global&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mean_norm</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool
Controls whether the feature vectors will be normalized by their means</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>std_norm</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>bool
Controls whether the feature vectors will be normalized by their standard variance</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>clamp</code>
            </td>
            <td>
                  <code>float</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>float
Clamping threshold for the standard variance before division.</p>
              </div>
            </td>
            <td>
                  <code>1e-10</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_epoch_num</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>int
The maximum number of epochs used to calculate the moving average.
Usually, the value of this argument is lower than a half of the number of warmup epochs.</p>
              </div>
            </td>
            <td>
                  <code>4</code>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/module/norm/feat_norm.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">module_init</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">norm_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;global&quot;</span><span class="p">,</span>
    <span class="n">mean_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">std_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">clamp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-10</span><span class="p">,</span>
    <span class="n">max_epoch_num</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        norm_type: str</span>
<span class="sd">            The type of feature normalization.</span>
<span class="sd">            The type must be one of &#39;utterance&#39;, &#39;batch&#39;, &#39;group&#39;, and &#39;global&#39;</span>
<span class="sd">        mean_norm: bool</span>
<span class="sd">            Controls whether the feature vectors will be normalized by their means</span>
<span class="sd">        std_norm: bool</span>
<span class="sd">            Controls whether the feature vectors will be normalized by their standard variance</span>
<span class="sd">        clamp: float</span>
<span class="sd">            Clamping threshold for the standard variance before division.</span>
<span class="sd">        max_epoch_num: int</span>
<span class="sd">            The maximum number of epochs used to calculate the moving average.</span>
<span class="sd">            Usually, the value of this argument is lower than a half of the number of warmup epochs.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">=</span> <span class="n">norm_type</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span> <span class="o">=</span> <span class="n">mean_norm</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span> <span class="o">=</span> <span class="n">std_norm</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">clamp</span> <span class="o">=</span> <span class="n">clamp</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_epoch_num</span> <span class="o">=</span> <span class="n">max_epoch_num</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="module.norm.feat_norm.FeatureNormalization.recover" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">recover</span><span class="p">(</span><span class="n">feat</span><span class="p">,</span> <span class="n">group_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>feat</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>group_ids</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span> or str or int</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Returns:</p>

            <details class="quote">
              <summary>Source code in <code>speechain/module/norm/feat_norm.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">recover</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">str</span> <span class="ow">or</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        feat:</span>
<span class="sd">        group_ids:</span>

<span class="sd">    Returns:</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span>
        <span class="s2">&quot;utterance&quot;</span><span class="p">,</span>
        <span class="s2">&quot;batch&quot;</span><span class="p">,</span>
    <span class="p">],</span> <span class="s2">&quot;If norm_type is either &#39;utterance&#39; or &#39;batch&#39;, the normalized features cannot be recovered.&quot;</span>

    <span class="c1"># global normalization or</span>
    <span class="c1"># group-level normalization with str or int group_ids (input utterances belong to the same group)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;global&quot;</span> <span class="ow">or</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;group&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">group_ids</span><span class="p">,</span> <span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span>
    <span class="p">):</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="s2">&quot;global&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;global&quot;</span> <span class="k">else</span> <span class="nb">str</span><span class="p">(</span><span class="n">group_ids</span><span class="p">)</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span> <span class="k">else</span> <span class="n">feat</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="n">feat</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span> <span class="k">else</span> <span class="n">feat</span>
    <span class="c1"># group-level normalization with tensor group_ids (input utterances belong to different groups)</span>
    <span class="c1"># recover by the average mean &amp; std when meeting an unknown group during inference</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;group&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">group_ids</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">feat</span>
            <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g_id</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g_id</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span>
                        <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="s2">&quot;aver_std&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">g_id</span> <span class="ow">in</span> <span class="n">group_ids</span>
                <span class="p">],</span>
                <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span>
            <span class="k">else</span> <span class="n">feat</span>
        <span class="p">)</span>

        <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">feat</span>
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g_id</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">g_id</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">d</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span>
                        <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="s2">&quot;aver_mean&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">g_id</span> <span class="ow">in</span> <span class="n">group_ids</span>
                <span class="p">],</span>
                <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span>
            <span class="k">else</span> <span class="n">feat</span>
        <span class="p">)</span>
    <span class="c1"># group-level normalization with None group_ids, recover by the average mean &amp; std</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_type</span> <span class="o">==</span> <span class="s2">&quot;group&quot;</span> <span class="ow">and</span> <span class="n">group_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">feat</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="s2">&quot;aver_std&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span>
            <span class="k">else</span> <span class="n">feat</span>
        <span class="p">)</span>
        <span class="n">feat</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">feat</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="s2">&quot;aver_mean&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span>
            <span class="k">else</span> <span class="n">feat</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span>

    <span class="k">return</span> <span class="n">feat</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="module.norm.feat_norm.FeatureNormalization.register_mean_std_batch" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">register_mean_std_batch</span><span class="p">(</span><span class="n">curr_aver_mean</span><span class="p">,</span> <span class="n">curr_aver_std</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>curr_aver_mean</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>curr_aver_std</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>prefix</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>epoch</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/module/norm/feat_norm.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">register_mean_std_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">curr_aver_mean</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">curr_aver_std</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">prefix</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        curr_aver_mean:</span>
<span class="sd">        curr_aver_std:</span>
<span class="sd">        prefix:</span>
<span class="sd">        epoch:</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># update the observed global batch number</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_batch&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_batch&quot;</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">curr_aver_mean</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">epoch</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epoch_num</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_batch&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_batch&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="p">)</span>

    <span class="c1"># update the observed global mean &amp; std only in the predefined batch number</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epoch_num</span><span class="p">:</span>
        <span class="c1"># get the weight of the global average values</span>
        <span class="n">curr_weight</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_batch&quot;</span><span class="p">)</span>

        <span class="c1"># update the observed global mean</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_norm</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">,</span> <span class="n">curr_aver_mean</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">prev_aver_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">,</span>
                    <span class="n">curr_weight</span> <span class="o">*</span> <span class="n">curr_aver_mean</span>
                    <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">curr_weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">prev_aver_mean</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># update the observed global std</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_norm</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">,</span> <span class="n">curr_aver_std</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">prev_aver_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">,</span>
                    <span class="n">curr_weight</span> <span class="o">*</span> <span class="n">curr_aver_std</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">curr_weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">prev_aver_std</span><span class="p">,</span>
                <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="module.norm.feat_norm.FeatureNormalization.sort_data_by_group" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">sort_data_by_group</span><span class="p">(</span><span class="n">raw_data</span><span class="p">,</span> <span class="n">group_ids</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>raw_data</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>group_ids</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>
        <p>Returns:</p>

            <details class="quote">
              <summary>Source code in <code>speechain/module/norm/feat_norm.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">sort_data_by_group</span><span class="p">(</span><span class="n">raw_data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">group_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        raw_data:</span>
<span class="sd">        group_ids:</span>

<span class="sd">    Returns:</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">raw_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">group_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="c1"># loop each group id</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">group_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)):</span>
            <span class="n">curr_group</span> <span class="o">=</span> <span class="n">group_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="c1"># initialize the group list if not existed</span>
            <span class="k">if</span> <span class="n">curr_group</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">group_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">group_dict</span><span class="p">[</span><span class="n">curr_group</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">group_dict</span><span class="p">[</span><span class="n">curr_group</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">raw_data</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="c1"># turn each group list into a 2d tensor</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">group_id</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">group_list</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">group_id</span><span class="p">,</span> <span class="n">group_list</span> <span class="ow">in</span> <span class="n">group_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="module.norm.feat_norm.FeatureNormalization.update_aver_mean_std" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">update_aver_mean_std</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents ">



<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>epoch</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>speechain/module/norm/feat_norm.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">update_aver_mean_std</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        epoch:</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epoch_num</span><span class="p">:</span>
        <span class="n">_group_mean_num</span><span class="p">,</span> <span class="n">_group_std_num</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
        <span class="n">_aver_mean</span><span class="p">,</span> <span class="n">_aver_std</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buff</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_mean&quot;</span><span class="p">):</span>
                <span class="n">_group_mean_num</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">_aver_mean</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">buff</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="n">_aver_mean</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">_aver_mean</span> <span class="o">+</span> <span class="n">buff</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_std&quot;</span><span class="p">):</span>
                <span class="n">_group_std_num</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">_aver_std</span> <span class="o">=</span> <span class="n">buff</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="n">_aver_std</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">_aver_std</span> <span class="o">+</span> <span class="n">buff</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;aver_mean&quot;</span><span class="p">,</span> <span class="n">_aver_mean</span> <span class="o">/</span> <span class="n">_group_mean_num</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;aver_std&quot;</span><span class="p">,</span> <span class="n">_aver_std</span> <span class="o">/</span> <span class="n">_group_std_num</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": [], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>